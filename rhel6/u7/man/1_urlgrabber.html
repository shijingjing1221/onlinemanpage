<!-- Creator     : groff version 1.18.1.4 -->
<!-- CreationDate: Tue Nov  8 21:31:46 2016 -->
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta name="Content-Style" content="text/css">
<title></title>
</head>
<body>

<hr>

<p>URLGRABBER(1) URLGRABBER(1)</p>

<p>NAME urlgrabber - a high-level cross-protocol
url-grabber.</p>

<p>SYNOPSIS urlgrabber [OPTIONS] URL [FILE]</p>

<p>DESCRIPTION urlgrabber is a binary program and python
module for fetching files. It is designed to be used in
programs that need common (but not necessarily simple)
url-fetching features.</p>

<p>OPTIONS --help, -h help page specifying available
options to the binary program.</p>

<p>--copy-local ignored except for file:// urls, in which
case it specifies whether urlgrab should still make a copy
of the file, or simply point to the existing copy.</p>

<p>--throttle=NUMBER if its an int, its the bytes/second
throttle limit. If its a float, it is first multiplied by
bandwidth. If throttle == 0, throttling is disabled. If
None, the module-level default (which can be set with
set_throttle) is used.</p>

<p>--bandwidth=NUMBER the nominal max bandwidth in
bytes/second. If throttle is a float and bandwidth == 0,
throttling is disabled. If None, the module-level default
(which can be set with set_bandwidth) is used.</p>

<p>--range=RANGE a tuple of the form first_byte,last_byte
describing a byte range to retrieve. Either or both of the
values may be specified. If first_byte is None, byte offset
0 is assumed. If last_byte is None, the last byte available
is assumed. Note that both first and last_byte values are
inclusive so a range of (10,11) would return the 10th and
11th bytes of the resource.</p>

<p>--user-agent=STR the user-agent string provide if the
url is HTTP.</p>

<p>--retry=NUMBER the number of times to retry the grab
before bailing. If this is zero, it will retry forever. This
was intentional... really, it was :). If this value is not
supplied or is supplied but is None retrying does not
occur.</p>

<p>--retrycodes a sequence of errorcodes (values of
e.errno) for which it should retry. See the doc on
URLGrabError for more details on this. retrycodes defaults
to -1,2,4,5,6,7 if not specified explicitly.</p>

<p>MODULE USE EXAMPLES In its simplest form, urlgrabber can
be a replacement for urllib2s open, or even pythons file if
youre just reading:</p>

<p>from urlgrabber import urlopen fo = urlopen(url) data =
fo.read() fo.close()</p>

<p>Here, the url can be http, https, ftp, or file. Its also
pretty smart so if you just give it something like /tmp/foo,
it will figure it out. For even more fun, you can also
do:</p>

<p>from urlgrabber import urlopen local_filename =
urlgrab(url) # grab a local copy of the file data =
urlread(url) # just read the data into a string</p>

<p>Now, like urllib2, whats really happening here is that
you re using a module-level object (called a grabber) that
kind of serves as a default. That s just fine, but you might
want to get your own private version for a couple of
reasons:</p>

<p>* its a little ugly to modify the default grabber
because you have to reach into the module to do it * you
could run into conflicts if different parts of the code
modify the default grabber and therefore expect different
behavior</p>

<p>Therefore, youre probably better off making your own.
This also gives you lots of flexibility for later, as youll
see:</p>

<p>from urlgrabber.grabber import URLGrabber g =
URLGrabber() data = g.urlread(url)</p>

<p>This is nice because you can specify options when you
create the grabber. For example, lets turn on simple reget
mode so that if we have part of a file, we only need to
fetch the rest:</p>

<p>from urlgrabber.grabber import URLGrabber g =
URLGrabber(reget=simple) local_filename = g.urlgrab(url)</p>

<p>The available options are listed in the module
documentation, and can usually be specified as a default at
the grabber-level or as options to the method:</p>

<p>from urlgrabber.grabber import URLGrabber g =
URLGrabber(reget=simple) local_filename = g.urlgrab(url,
filename=None, reget=None)</p>

<p>AUTHORS Written by: Michael D. Stenner
&lt;mstenner@linux.duke.edu&gt; Ryan Tomayko
&lt;rtomayko@naeblis.cx&gt;</p>

<p>This manual page was written by Kevin Coyner
&lt;kevin@rustybear.com&gt; for the Debian system (but may
be used by others). It borrows heavily on the documentation
included in the urlgrabber module. Permission is granted to
copy, distribute and/or modify this document under the terms
of the GNU General Public License, Version 2 any later
version published by the Free Software Foundation.</p>

<p>RESOURCES Main web site:
http://linux.duke.edu/projects/urlgrabber/</p>

<p>04/09/2007 URLGRABBER(1)</p>
<hr>
</body>
</html>

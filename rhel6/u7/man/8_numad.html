<!-- Creator     : groff version 1.18.1.4 -->
<!-- CreationDate: Sat Nov 12 06:24:33 2016 -->
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta name="Content-Style" content="text/css">
<title></title>
</head>
<body>

<hr>

<p>numad(8) Administration numad(8)</p>

<p>NAME numad - A user-level daemon that provides placement
advice and process management for efficient use of CPUs and
memory on systems with NUMA topology.</p>

<p>SYNOPSIS numad [-dhvV]</p>

<p>numad [-C 0|1]</p>

<p>numad [-H THP_hugepage_scan_sleep_ms]</p>

<p>numad [-i [min_interval:]max_interval]</p>

<p>numad [-K 0|1]</p>

<p>numad [-l log_level]</p>

<p>numad [-m target_memory_locality]</p>

<p>numad [-p PID]</p>

<p>numad [-r PID]</p>

<p>numad [-R reserved-CPU-list]</p>

<p>numad [-S 0|1]</p>

<p>numad [-t logical_CPU_percent]</p>

<p>numad [-u target_utilization]</p>

<p>numad [-w NCPUS[:MB]]</p>

<p>numad [-x PID]</p>

<p>DESCRIPTION Numad is a system daemon that monitors NUMA
topology and resource usage. It will attempt to locate
processes for efficient NUMA locality and affinity,
dynamically adjusting to changing system conditions. Numad
also provides guidance to assist management applications
with initial manual binding of CPU and memory resources for
their processes. Note that numad is primarily intended for
server consolidation environ- ments, where there might be
multiple applications or multiple virtual guests running on
the same server system. Numad is most likely to have a
positive effect when processes can be localized in a subset
of the system s NUMA nodes. If the entire system is
dedicated to a large in- memory database application, for
example -- especially if memory accesses will likely remain
unpredictable -- numad will probably not improve
performance.</p>

<p>OPTIONS -C &lt;0|1&gt; This option controls whether or
not numad treats inactive file cache as available memory. By
default, numad assumes it can count inactive file cache as
&quot;free&quot; memory when considering resources to match
with processes. Specify -C 0 if numad should instead
consider inactive file cache as a consumed resource.</p>

<p>-d Debug output in log, sets the log level to LOG_DEBUG.
Same effect as -l 7.</p>

<p>-h Display usage help information and then exit.</p>

<p>-H &lt;THP_scan_sleep_ms&gt; Set the desired transparent
hugepage scan interval in ms. The
/sys/kernel/mm/tranparent_hugepage/khugepaged/scan_sleep_mil-
lisecs tunable is usually set to 10000ms by the operating
sys- tem. The default is changed by numad to be 1000ms since
it is helpful for the hugepage daemon to be more aggressive
when mem- ory moves between nodes. Specifying (-H 0) will
cause numad to retain the system default value. You can also
make the hugepage daemon more or less aggressive by
specifying an alternate value with this option. For example,
setting this value to 100ms (-H 100) might improve the
performance of workloads which use many transparent
hugepages.</p>

<p>-i &lt;[min_interval:]max_interval&gt; Sets the time
interval that numad waits between system scans, in seconds
to &lt;max_interval&gt;. Default &lt;max_interval&gt; is 15
seconds, default &lt;min_interval&gt; is 5 seconds. Setting
a &lt;max_interval&gt; of zero will cause the daemon to
exit. (This is the normal mechanism to terminate the
daemon.) A bigger &lt;max_interval&gt; will decrease numad
overhead but also decrease responsiveness to changing loads.
The default numad max_interval can be changed in the
numad.conf file.</p>

<p>-K &lt;0|1&gt; This option controls whether numad keeps
interleaved memory spread across NUMA nodes, or attempts to
merge interleaved mem- ory to local NUMA nodes. The default
is to merge interleaved memory. This is the appropriate
setting to localize processes in a subset of the systems
NUMA nodes. If you are running a large, single-instance
application that allocates interleaved memory because the
workload will have continuous unpredictable memory access
patterns (e.g. a large in-memory database), you might get
better results by specifying -K 1 to instruct numad to keep
interleaved memory distributed.</p>

<p>-l &lt;log_level&gt; Sets the log level to
&lt;log_level&gt;. Reasonable choices are 5, 6, or 7. The
default value is 5. Note that CPU values are scaled by a
factor of 100 internally and in the numad log files.
Unfortunately, you don t actually have that many CPUs.</p>

<p>-m &lt;target_memory_locality&gt; Set the desired memory
locality threshold to stop moving process memory. Numad
might stop retrying to coalesce process memory when more
than this percentage of the processs memory is already
localized in the target node(s). The default is 90%. Numad
will frequently localize more than the localization
threshold percent, but it will not necessarily do so.
Decrease the threshold to allow numad to leave more process
memory dis- tributed on various nodes. Increase the
threshold to instruct numad to try to localize more memory.
Acceptable values are between 50 and 100 percent. Note that
setting the target memory locality to 100% might cause numad
to continually retry to move memory that the kernel will
never succesfully move.</p>

<p>-p &lt;PID&gt; Add PID to explicit inclusion list of
processes to consider for managing, if the process also uses
significant resources. Mul- tiple -p PID options can be
specified at daemon start, but after daemon start, only one
PID can be added to the inclusion list per subsequent numad
invocation. Use with -S to precisely con- trol the scope of
processes numad can manage. Note that the specified process
will not necessarily be actively managed unless it also
meets numads significance threshold -- which is currently
300MB and half of a CPU.</p>

<p>-r &lt;PID&gt; Remove PID from both the explicit
inclusion and the exclusion lists of processes. After daemon
start, only one PID can be removed from the explicit process
lists per subsequent numad invocation. Use with -S and -p
and -x to precisely control the scope of processes numad can
manage.</p>

<p>-R &lt;CPU_LIST&gt; Specify a list of CPUs that numad
should assume are reserved for non-numad use. No processes
will be bound to the specified CPUs by numad. This option is
effective only when starting numad. You cannot change
reserved CPUs dynamically while numad is already
running.</p>

<p>-S &lt;0|1&gt; This option controls whether numad scans
all system processes or only the processes on the explicit
inclusion PID list. The default is to scan all processes.
Use -S 0 to scan only the explicit inclusion PID list. Use
-S 1 to again scan all system processes (excepting those on
the explicit exclusion list). Starting numad as numad -S 0
-p &lt;PID-1&gt; -p &lt;PID-2&gt; -p &lt;PID-3&gt; will
limit scanning, and thus also automatic NUMA management, to
only those three explicitly specified processes.</p>

<p>-t &lt;logical_CPU_percent&gt; Specify the resource
value of logical CPUs. Hardware threads typically share most
core resources, and so logical CPUs add only a fraction of
CPU power for many workloads. By default numad considers
logical CPUs to be only 20 percent of a dedi- cated hardware
core.</p>

<p>-u &lt;target_utilization&gt; Set the desired maximum
consumption percentage of a node. Default is 85%. Decrease
the target value to maintain more available resource margin
on each node. Increase the target value to more exhaustively
consume node resources. If you have sized your workloads to
precisely fit inside a NUMA node, speci- fying (-u 100)
might improve system performance by telling numad to go
ahead and consume all the resources in each node. It is
possible to specify values up to 130 percent to
oversubscribe CPUs in the nodes, but memory utilization is
always capped at 100%. Use oversubscription values very
carefully.</p>

<p>-v Verbose output in log, sets the log level to
LOG_INFO. Same effect as -l 6.</p>

<p>-V Display version information and exit.</p>

<p>-w &lt;NCPUS[:MB]&gt; Queries numad for the best NUMA
nodes to bind an entity that needs &lt;NCPUS&gt;. The amount
of memory (in MBs) is optional, but should normally be
specified as well &lt;:MB&gt; so numad can recom- mend NUMA
nodes with available CPU capacity and adequate free memory.
This query option can be used regardless of whether numad is
running as a daemon. (An invocation using this option when
numad is not running as a daemon, will not cause the daemon
to start.) Output of this option is a string that contains a
NUMA node list. For example: 2-3,6. The recommended node
list could be saved in a shell variable (e.g., NODES) and
then used as the node list parameter in a numactl -m $NODES
-N $NODES ... command. See numactl(8).</p>

<p>-x &lt;PID&gt; Add PID to explicit exclusion list of
processes to blacklist from managing. Multiple -x PID
options can be specified at dae- mon start, but after daemon
start, only one PID can be added to the exclusion list per
subsequent numad invocation. Use with -S to precisely
control the scope of processes numad can manage.</p>

<p>FILES /usr/bin/numad /etc/numad.conf /var/log/numad.log
/var/run/numad.pid</p>

<p>ENVIRONMENT VARIABLES None.</p>

<p>EXAMPLES Numad can be run as a system daemon and can be
managed by the standard init mechanisms of the host.</p>

<p>If interactive (manual) control is desired, you can
start the daemon manually by typing:</p>

<p>/usr/bin/numad</p>

<p>Subsequent numad invocations while the daemon is running
can be used to dynamically change most run-time options.</p>

<p>You can terminate numad from running by typing:</p>

<p>/usr/bin/numad -i0</p>

<p>AUTHORS Bill Gray &lt;bgray@redhat.com&gt;</p>

<p>SEE ALSO numactl(8)</p>

<p>Bill Gray 1.0.0 numad(8)</p>
<hr>
</body>
</html>

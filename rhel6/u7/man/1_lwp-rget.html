<!-- Creator     : groff version 1.18.1.4 -->
<!-- CreationDate: Sat Nov 12 06:22:15 2016 -->
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta name="Content-Style" content="text/css">
<title></title>
</head>
<body>

<hr>

<p>LWP-RGET(1) User Contributed Perl Documentation
LWP-RGET(1)</p>

<p>NAME lwp-rget - Retrieve web documents recursively</p>

<p>SYNOPSIS lwp-rget [--verbose] [--auth=USER:PASS]
[--depth=N] [--hier] [--iis]
[--keepext=mime/type[,mime/type]] [--limit=N] [--nospace]
[--prefix=URL] [--referer=URL] [--sleep=N] [--tolower]
&lt;URL&gt; lwp-rget --version</p>

<p>DESCRIPTION This program will retrieve a document and
store it in a local file. It will follow any links found in
the document and store these documents as well, patching
links so that they refer to these local copies. This process
continues until there are no more unvisited links or the
process is stopped by the one or more of the limits which
can be controlled by the command line arguments.</p>

<p>This program is useful if you want to make a local copy
of a collection of documents or want to do web reading
off-line.</p>

<p>All documents are stored as plain files in the current
directory. The file names chosen are derived from the last
component of URL paths.</p>

<p>The options are:</p>

<p>--auth=USER:PASn Set the authentication credentials to
user &quot;USER&quot; and password &quot;PASS&quot; if any
restricted parts of the web site are hit. If there are
restricted parts of the web site and authentication
credentials are not available, those pages will not be
downloaded.</p>

<p>--depth=n Limit the recursive level. Embedded images are
always loaded, even if they fall outside the --depth. This
means that one can use --depth=0 in order to fetch a single
document together with all inline graphics.</p>

<p>The default depth is 5.</p>

<p>--hier Download files into a hierarchy that mimics the
web site structure. The default is to put all files in the
current directory.</p>

<p>--referer=URI Set the value of the Referer header for
the initial request. The special value &quot;NONE&quot; can
be used to suppress the Referer header in any of subsequent
requests. The Referer header will always be suppressed in
all normal &quot;http&quot; requests if the referring page
was transmitted over &quot;https&quot; as recommended in RFC
2616.</p>

<p>--iis Sends an &quot;Accept: */*&quot; on all URL
requests as a workaround for a bug in IIS 2.0. If no Accept
MIME header is present, IIS 2.0 returns with a &quot;406 No
acceptable objects were found&quot; error. Also converts any
back slashes (\) in URLs to forward slashes (/).</p>

<p>--keepext=mime/type[,mime/type] Keeps the current
extension for the list MIME types. Useful when downloading
text/plain documents that shouldnt all be translated to
*.txt files.</p>

<p>--limit=n Limit the number of documents to get. The
default limit is 50.</p>

<p>--nospace Changes spaces in all URLs to underscore
characters (_). Useful when downloading files from sites
serving URLs with spaces in them. Does not remove spaces
from fragments, e.g., &quot;file.html#somewhere in
here&quot;.</p>

<p>--prefix=url_prefix Limit the links to follow. Only URLs
that start the prefix string are followed.</p>

<p>The default prefix is set as the &quot;directory&quot;
of the initial URL to follow. For instance if we start
lwp-rget with the URL
&quot;http://www.sn.no/foo/bar.html&quot;, then prefix will
be set to &quot;http://www.sn.no/foo/&quot;.</p>

<p>Use &quot;--prefix=&rsquo;&rsquo;&quot; if you dont want
the fetching to be limited by any prefix.</p>

<p>--sleep=n Sleep n seconds before retrieving each
document. This options allows you to go slowly, not loading
the server you visiting too much.</p>

<p>--tolower Translates all links to lowercase. Useful when
downloading files from IIS since it does not serve files in
a case sensitive manner.</p>

<p>--verbose Make more noise while running.</p>

<p>--quiet Dont make any noise.</p>

<p>--version Print program version number and quit.</p>

<p>--help Print the usage message and quit.</p>

<p>Before the program exits the name of the file, where the
initial URL is stored, is printed on stdout. All used
filenames are also printed on stderr as they are loaded.
This printing can be suppressed with the --quiet option.</p>

<p>SEE ALSO lwp-request, LWP</p>

<p>AUTHOR Gisle Aas &lt;aas@sn.no&gt;</p>

<p>perl v5.10.1 2009-06-15 LWP-RGET(1)</p>
<hr>
</body>
</html>

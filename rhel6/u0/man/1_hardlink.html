<!-- Creator     : groff version 1.18.1.4 -->
<!-- CreationDate: Sat Nov 12 22:03:23 2016 -->
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta name="Content-Style" content="text/css">
<title></title>
</head>
<body>

<hr>

<p>hardlink(1) hardlink(1)</p>

<p>NAME hardlink - Consolidate duplicate files via
hardlinks</p>

<p>SYNOPSIS hardlink [-c] [-n] [-v] [-vv] [-h] directory1 [
directory2 ... ]</p>

<p>DESCRIPTION This manual page documents hardlink, a
program which consolidates duplicate files in one or more
directories using hardlinks.</p>

<p>hardlink traverses one or more directories searching for
duplicate files. When it finds duplicate files, it uses one
of them as the mas- ter. It then removes all other
duplicates and places a hardlink for each one pointing to
the master file. This allows for conservation of disk space
where multiple directories on a single filesystem contain
many duplicate files.</p>

<p>Since hard links can only span a single filesystem,
hardlink is only useful when all directories specified are
on the same filesystem.</p>

<p>OPTIONS -c Compare only the contents of the files being
considered for consolidation. Disregards permission,
ownership and other differences.</p>

<p>-n Do not perform the consolidation; only print what
would be changed.</p>

<p>-v Print summary after hardlinking.</p>

<p>-vv Print every hardlinked file and bytes saved. Also
print sum- mary after hardlinking.</p>

<p>-h Show help.</p>

<p>AUTHOR hardlink was written by Jakub Jelinek
&lt;jakub@redhat.com&gt;.</p>

<p>Man page written by Brian Long.</p>

<p>Man page updated by Jindrich Novy
&lt;jnovy@redhat.com&gt;</p>

<p>hardlink(1)</p>
<hr>
</body>
</html>

<!-- Creator     : groff version 1.18.1.4 -->
<!-- CreationDate: Sat Nov 12 06:27:53 2016 -->
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta name="Content-Style" content="text/css">
<title></title>
</head>
<body>

<hr>

<p>PERLUNIINTRO(1) Perl Programmers Reference Guide
PERLUNIINTRO(1)</p>

<p>NAME perluniintro - Perl Unicode introduction</p>

<p>DESCRIPTION This document gives a general idea of
Unicode and how to use Unicode in Perl.</p>

<p>Unicode Unicode is a character set standard which plans
to codify all of the writing systems of the world, plus many
other symbols.</p>

<p>Unicode and ISO/IEC 10646 are coordinated standards that
provide code points for characters in almost all modern
character set standards, covering more than 30 writing
systems and hundreds of languages, including all
commercially-important modern languages. All characters in
the largest Chinese, Japanese, and Korean dictionaries are
also encoded. The standards will eventually cover almost all
characters in more than 250 writing systems and thousands of
languages. Unicode 1.0 was released in October 1991, and 4.0
in April 2003.</p>

<p>A Unicode character is an abstract entity. It is not
bound to any particular integer width, especially not to the
C language &quot;char&quot;. Unicode is language-neutral and
display-neutral: it does not encode the language of the text
and it does not generally define fonts or other graphical
layout details. Unicode operates on characters and on text
built from those characters.</p>

<p>Unicode defines characters like &quot;LATIN CAPITAL
LETTER A&quot; or &quot;GREEK SMALL LETTER ALPHA&quot; and
unique numbers for the characters, in this case 0x0041 and
0x03B1, respectively. These unique numbers are called code
points.</p>

<p>The Unicode standard prefers using hexadecimal notation
for the code points. If numbers like 0x0041 are unfamiliar
to you, take a peek at a later section, &quot;Hexadecimal
Notation&quot;. The Unicode standard uses the notation
&quot;U+0041 LATIN CAPITAL LETTER A&quot;, to give the
hexadecimal code point and the normative name of the
character.</p>

<p>Unicode also defines various properties for the
characters, like &quot;uppercase&quot; or
&quot;lowercase&quot;, &quot;decimal digit&quot;, or
&quot;punctuation&quot;; these properties are independent of
the names of the characters. Furthermore, various operations
on the characters like uppercasing, lowercasing, and
collating (sorting) are defined.</p>

<p>A Unicode character consists either of a single code
point, or a base character (like &quot;LATIN CAPITAL LETTER
A&quot;), followed by one or more modifiers (like
&quot;COMBINING ACUTE ACCENT&quot;). This sequence of base
character and modifiers is called a combining character
sequence.</p>

<p>Whether to call these combining character sequences
&quot;characters&quot; depends on your point of view. If you
are a programmer, you probably would tend towards seeing
each element in the sequences as one unit, or
&quot;character&quot;. The whole sequence could be seen as
one &quot;character&quot;, however, from the user s point of
view, since thats probably what it looks like in the context
of the users language.</p>

<p>With this &quot;whole sequence&quot; view of characters,
the total number of characters is open-ended. But in the
programmers &quot;one unit is one character&quot; point of
view, the concept of &quot;characters&quot; is more
deterministic. In this document, we take that second point
of view: one &quot;character&quot; is one Unicode code
point, be it a base character or a combining character.</p>

<p>For some combinations, there are precomposed characters.
&quot;LATIN CAPITAL LETTER A WITH ACUTE&quot;, for example,
is defined as a single code point. These precomposed
characters are, however, only available for some
combinations, and are mainly meant to support round-trip
conversions between Unicode and legacy standards (like the
ISO 8859). In the general case, the composing method is more
extensible. To support conversion between different
compositions of the characters, various normalization forms
to standardize representations are also defined.</p>

<p>Because of backward compatibility with legacy encodings,
the &quot;a unique number for every character&quot; idea
breaks down a bit: instead, there is &quot;at least one
number for every character&quot;. The same character could
be represented differently in several legacy encodings. The
converse is also not true: some code points do not have an
assigned character. Firstly, there are unallocated code
points within otherwise used blocks. Secondly, there are
special Unicode control characters that do not represent
true characters.</p>

<p>A common myth about Unicode is that it would be
&quot;16-bit&quot;, that is, Unicode is only represented as
0x10000 (or 65536) characters from 0x0000 to 0xFFFF. This is
untrue. Since Unicode 2.0 (July 1996), Unicode has been
defined all the way up to 21 bits (0x10FFFF), and since
Unicode 3.1 (March 2001), characters have been defined
beyond 0xFFFF. The first 0x10000 characters are called the
Plane 0, or the Basic Multilingual Plane (BMP). With Unicode
3.1, 17 (yes, seventeen) planes in all were defined--but
they are nowhere near full of defined characters, yet.</p>

<p>Another myth is that the 256-character blocks have
something to do with languages--that each block would define
the characters used by a language or a set of languages.
This is also untrue. The division into blocks exists, but it
is almost completely accidental--an artifact of how the
characters have been and still are allocated. Instead, there
is a concept called scripts, which is more useful: there is
&quot;Latin&quot; script, &quot;Greek&quot; script, and so
on. Scripts usually span varied parts of several blocks. For
further information see Unicode::UCD.</p>

<p>The Unicode code points are just abstract numbers. To
input and output these abstract numbers, the numbers must be
encoded or serialised somehow. Unicode defines several
character encoding forms, of which UTF-8 is perhaps the most
popular. UTF-8 is a variable length encoding that encodes
Unicode characters as 1 to 6 bytes (only 4 with the
currently defined characters). Other encodings include
UTF-16 and UTF-32 and their big- and little-endian variants
(UTF-8 is byte-order independent) The ISO/IEC 10646 defines
the UCS-2 and UCS-4 encoding forms.</p>

<p>For more information about encodings--for instance, to
learn what surrogates and byte order marks (BOMs) are--see
perlunicode.</p>

<p>Pers Unicode Support Starting from Perl 5.6.0, Perl has
had the capacity to handle Unicode natively. Perl 5.8.0,
however, is the first recommended release for serious
Unicode work. The maintenance release 5.6.1 fixed many of
the problems of the initial Unicode implementation, but for
example regular expressions still do not work with Unicode
in 5.6.1.</p>

<p>Starting from Perl 5.8.0, the use of &quot;use
utf8&quot; is needed only in much more restricted
circumstances. In earlier releases the &quot;utf8&quot;
pragma was used to declare that operations in the current
block or file would be Unicode-aware. This model was found
to be wrong, or at least clumsy: the &quot;Unicodeness&quot;
is now carried with the data, instead of being attached to
the operations. Only one case remains where an explicit
&quot;use utf8&quot; is needed: if your Perl script itself
is encoded in UTF-8, you can use UTF-8 in your identifier
names, and in string and regular expression literals, by
saying &quot;use utf8&quot;. This is not the default because
scripts with legacy 8-bit data in them would break. See
utf8.</p>

<p>Pers Unicode Model Perl supports both pre-5.6 strings of
eight-bit native bytes, and strings of Unicode characters.
The principle is that Perl tries to keep its data as
eight-bit bytes for as long as possible, but as soon as
Unicodeness cannot be avoided, the data is transparently
upgraded to Unicode.</p>

<p>Internally, Perl currently uses either whatever the
native eight-bit character set of the platform (for example
Latin-1) is, defaulting to UTF-8, to encode Unicode strings.
Specifically, if all code points in the string are 0xFF or
less, Perl uses the native eight-bit character set.
Otherwise, it uses UTF-8.</p>

<p>A user of Perl does not normally need to know nor care
how Perl happens to encode its internal strings, but it
becomes relevant when outputting Unicode strings to a stream
without a PerlIO layer -- one with the &quot;default&quot;
encoding. In such a case, the raw bytes used internally (the
native character set or UTF-8, as appropriate for each
string) will be used, and a &quot;Wide character&quot;
warning will be issued if those strings contain a character
beyond 0x00FF.</p>

<p>For example,</p>

<p>perl -e &rsquo;print &quot;F}0, &quot;F}0&rsquo;</p>

<p>produces a fairly useless mixture of native bytes and
UTF-8, as well as a warning:</p>

<p>Wide character in print at ...</p>

<p>To output UTF-8, use the &quot;:encoding&quot; or
&quot;:utf8&quot; output layer. Prepending</p>

<p>binmode(STDOUT, &quot;:utf8&quot;);</p>

<p>to this sample program ensures that the output is
completely UTF-8, and removes the programs warning.</p>

<p>You can enable automatic UTF-8-ification of your
standard file handles, default &quot;open()&quot; layer, and
@ARGV by using either the &quot;-C&quot; command line switch
or the &quot;PERL_UNICODE&quot; environment variable, see
perlrun for the documentation of the &quot;-C&quot;
switch.</p>

<p>Note that this means that Perl expects other software to
work, too: if Perl has been led to believe that STDIN should
be UTF-8, but then STDIN coming in from another command is
not UTF-8, Perl will complain about the malformed UTF-8.</p>

<p>All features that combine Unicode and I/O also require
using the new PerlIO feature. Almost all Perl 5.8 platforms
do use PerlIO, though: you can see whether yours is by
running &quot;perl -V&quot; and looking for
&quot;useperlio=define&quot;.</p>

<p>Unicode and EBCDIC Perl 5.8.0 also supports Unicode on
EBCDIC platforms. There, Unicode support is somewhat more
complex to implement since additional conversions are needed
at every step. Some problems remain, see perlebcdic for
details.</p>

<p>In any case, the Unicode support on EBCDIC platforms is
better than in the 5.6 series, which didnt work much at all
for EBCDIC platform. On EBCDIC platforms, the internal
Unicode encoding form is UTF-EBCDIC instead of UTF-8. The
difference is that as UTF-8 is &quot;ASCII-safe&quot; in
that ASCII characters encode to UTF-8 as-is, while
UTF-EBCDIC is &quot;EBCDIC-safe&quot;.</p>

<p>Creating Unicode To create Unicode characters in
literals for code points above 0xFF, use the &quot;.}&quot;
notation in double-quoted strings:</p>

<p>my $smiley = &quot;}&quot;;</p>

<p>Similarly, it can be used in regular expression
literals</p>

<p>$smiley =~ /}/;</p>

<p>At run-time you can use &quot;chr()&quot;:</p>

<p>my $hebrew_alef = chr(0x05d0);</p>

<p>See &quot;Further Resources&quot; for how to find all
these numeric codes.</p>

<p>Naturally, &quot;ord()&quot; will do the reverse: it
turns a character into a code point.</p>

<p>Note that &quot;.&quot; (no &quot;{}&quot; and only two
hexadecimal digits), &quot;.}&quot;, and
&quot;chr(...)&quot; for arguments less than 0x100 (decimal
256) generate an eight-bit character for backward
compatibility with older Perls. For arguments of 0x100 or
more, Unicode characters are always produced. If you want to
force the production of Unicode characters regardless of the
numeric value, use &quot;pack(&quot;U&quot;, ...)&quot;
instead of &quot;.&quot;, &quot;.}&quot;, or
&quot;chr()&quot;.</p>

<p>You can also use the &quot;charnames&quot; pragma to
invoke characters by name in double-quoted strings:</p>

<p>use charnames &rsquo;:full&rsquo;; my $arabic_alef =
&quot;RABIC LETTER ALEF}&quot;;</p>

<p>And, as mentioned above, you can also &quot;pack()&quot;
numbers into Unicode characters:</p>

<p>my $georgian_an = pack(&quot;U&quot;, 0x10a0);</p>

<p>Note that both &quot;.}&quot; and &quot;.}&quot; are
compile-time string constants: you cannot use variables in
them. if you want similar run- time functionality, use
&quot;chr()&quot; and &quot;charnames::vianame()&quot;.</p>

<p>If you want to force the result to Unicode characters,
use the special &quot;U0&quot; prefix. It consumes no
arguments but causes the following bytes to be interpreted
as the UTF-8 encoding of Unicode characters:</p>

<p>my $chars = pack(&quot;U0W*&quot;, 0x80, 0x42);</p>

<p>Likewise, you can stop such UTF-8 interpretation by
using the special &quot;C0&quot; prefix.</p>

<p>Handling Unicode Handling Unicode is for the most part
transparent: just use the strings as usual. Functions like
&quot;index()&quot;, &quot;length()&quot;, and
&quot;substr()&quot; will work on the Unicode characters;
regular expressions will work on the Unicode characters (see
perlunicode and perlretut).</p>

<p>Note that Perl considers combining character sequences
to be separate characters, so for example</p>

<p>use charnames &rsquo;:full&rsquo;; print
length(&quot;ATIN CAPITAL LETTER A}OMBINING ACUTE
ACCENT}&quot;), &quot;0;</p>

<p>will print 2, not 1. The only exception is that regular
expressions have &quot;</p>

<p>Life is not quite so transparent, however, when working
with legacy encodings, I/O, and certain special cases:</p>

<p>Legacy Encodings When you combine legacy data and
Unicode the legacy data needs to be upgraded to Unicode.
Normally ISO 8859-1 (or EBCDIC, if applicable) is
assumed.</p>

<p>The &quot;Encode&quot; module knows about many encodings
and has interfaces for doing conversions between those
encodings:</p>

<p>use Encode &rsquo;decode&rsquo;; $data =
decode(&quot;iso-8859-3&quot;, $data); # convert from legacy
to utf-8</p>

<p>Unicode I/O Normally, writing out Unicode data</p>

<p>print FH $some_string_with_unicode, &quot;0;</p>

<p>produces raw bytes that Perl happens to use to
internally encode the Unicode string. Perl s internal
encoding depends on the system as well as what characters
happen to be in the string at the time. If any of the
characters are at code points 0x100 or above, you will get a
warning. To ensure that the output is explicitly rendered in
the encoding you desire--and to avoid the warning--open the
stream with the desired encoding. Some examples:</p>

<p>open FH, &quot;&gt;:utf8&quot;, &quot;file&quot;;</p>

<p>open FH, &quot;&gt;:encoding(ucs2)&quot;,
&quot;file&quot;; open FH, &quot;&gt;:encoding(UTF-8)&quot;,
&quot;file&quot;; open FH,
&quot;&gt;:encoding(shift_jis)&quot;, &quot;file&quot;;</p>

<p>and on already open streams, use
&quot;binmode()&quot;:</p>

<p>binmode(STDOUT, &quot;:utf8&quot;);</p>

<p>binmode(STDOUT, &quot;:encoding(ucs2)&quot;);
binmode(STDOUT, &quot;:encoding(UTF-8)&quot;);
binmode(STDOUT, &quot;:encoding(shift_jis)&quot;);</p>

<p>The matching of encoding names is loose: case does not
matter, and many encodings have several aliases. Note that
the &quot;:utf8&quot; layer must always be specified exactly
like that; it is not subject to the loose matching of
encoding names. Also note that &quot;:utf8&quot; is unsafe
for input, because it accepts the data without validating
that it is indeed valid UTF8.</p>

<p>See PerlIO for the &quot;:utf8&quot; layer,
PerlIO::encoding and Encode::PerlIO for the
&quot;:encoding()&quot; layer, and Encode::Supported for
many encodings supported by the &quot;Encode&quot;
module.</p>

<p>Reading in a file that you know happens to be encoded in
one of the Unicode or legacy encodings does not magically
turn the data into Unicode in Perl s eyes. To do that,
specify the appropriate layer when opening files</p>

<p>open(my $fh,&rsquo;&lt;:encoding(utf8)&rsquo;,
&rsquo;anything&rsquo;); my $line_of_unicode =
&lt;$fh&gt;;</p>

<p>open(my $fh,&rsquo;&lt;:encoding(Big5)&rsquo;,
&rsquo;anything&rsquo;); my $line_of_unicode =
&lt;$fh&gt;;</p>

<p>The I/O layers can also be specified more flexibly with
the &quot;open&quot; pragma. See open, or look at the
following example.</p>

<p>use open &rsquo;:encoding(utf8)&rsquo;; # input/output
default encoding will be UTF-8 open X, &quot;&gt;file&quot;;
print X chr(0x100), &quot;0; close X; open Y,
&quot;&lt;file&quot;; printf &quot;%#x0, ord(&lt;Y&gt;); #
this should print 0x100 close Y;</p>

<p>With the &quot;open&quot; pragma you can use the
&quot;:locale&quot; layer</p>

<p>BEGIN { $ENV{LC_ALL} = $ENV{LANG} =
&rsquo;ru_RU.KOI8-R&rsquo; } # the :locale will probe the
locale environment variables like LC_ALL use open OUT =&gt;
&rsquo;:locale&rsquo;; # russki parusski open(O,
&quot;&gt;koi8&quot;); print O chr(0x430); # Unicode
CYRILLIC SMALL LETTER A = KOI8-R 0xc1 close O; open(I,
&quot;&lt;koi8&quot;); printf &quot;%#x0, ord(&lt;I&gt;),
&quot;0; # this should print 0xc1 close I;</p>

<p>These methods install a transparent filter on the I/O
stream that converts data from the specified encoding when
it is read in from the stream. The result is always
Unicode.</p>

<p>The open pragma affects all the &quot;open()&quot; calls
after the pragma by setting default layers. If you want to
affect only certain streams, use explicit layers directly in
the &quot;open()&quot; call.</p>

<p>You can switch encodings on an already opened stream by
using &quot;binmode()&quot;; see &quot;binmode&quot; in
perlfunc.</p>

<p>The &quot;:locale&quot; does not currently (as of Perl
5.8.0) work with &quot;open()&quot; and
&quot;binmode()&quot;, only with the &quot;open&quot;
pragma. The &quot;:utf8&quot; and &quot;:encoding(...)&quot;
methods do work with all of &quot;open()&quot;,
&quot;binmode()&quot;, and the &quot;open&quot; pragma.</p>

<p>Similarly, you may use these I/O layers on output
streams to automatically convert Unicode to the specified
encoding when it is written to the stream. For example, the
following snippet copies the contents of the file
&quot;text.jis&quot; (encoded as ISO-2022-JP, aka JIS) to
the file &quot;text.utf8&quot;, encoded as UTF-8:</p>

<p>open(my $nihongo,
&rsquo;&lt;:encoding(iso-2022-jp)&rsquo;,
&rsquo;text.jis&rsquo;); open(my $unicode,
&rsquo;&gt;:utf8&rsquo;, &rsquo;text.utf8&rsquo;); while
(&lt;$nihongo&gt;) { print $unicode $_ }</p>

<p>The naming of encodings, both by the &quot;open()&quot;
and by the &quot;open&quot; pragma allows for flexible
names: &quot;koi8-r&quot; and &quot;KOI8R&quot; will both be
understood.</p>

<p>Common encodings recognized by ISO, MIME, IANA, and
various other standardisation organisations are recognised;
for a more detailed list see Encode::Supported.</p>

<p>&quot;read()&quot; reads characters and returns the
number of characters. &quot;seek()&quot; and
&quot;tell()&quot; operate on byte counts, as do
&quot;sysread()&quot; and &quot;sysseek()&quot;.</p>

<p>Notice that because of the default behaviour of not
doing any conversion upon input if there is no default
layer, it is easy to mistakenly write code that keeps on
expanding a file by repeatedly encoding the data:</p>

<p># BAD CODE WARNING open F, &quot;file&quot;; local $/;
## read in the whole file of 8-bit characters $t =
&lt;F&gt;; close F; open F, &quot;&gt;:encoding(utf8)&quot;,
&quot;file&quot;; print F $t; ## convert to UTF-8 on output
close F;</p>

<p>If you run this code twice, the contents of the file
will be twice UTF-8 encoded. A &quot;use open
&rsquo;:encoding(utf8)&rsquo;&quot; would have avoided the
bug, or explicitly opening also the file for input as
UTF-8.</p>

<p>NOTE: the &quot;:utf8&quot; and &quot;:encoding&quot;
features work only if your Perl has been built with the new
PerlIO feature (which is the default on most systems).</p>

<p>Displaying Unicode As Text Sometimes you might want to
display Perl scalars containing Unicode as simple ASCII (or
EBCDIC) text. The following subroutine converts its argument
so that Unicode characters with code points greater than 255
are displayed as &quot;.}&quot;, control characters (like
&quot;0) are displayed as &quot;.&quot;, and the rest of the
characters as themselves:</p>

<p>sub nice_string { join(&quot;&quot;, map { $_ &gt; 255 ?
# if wide character... sprintf(&quot;\x{%04X}&quot;, $_) : #
.} chr($_) =~ /[[:cntrl:]]/ ? # else if control character
... sprintf(&quot;\x%02X&quot;, $_) : # . quotemeta(chr($_))
# else quoted or as themselves } unpack(&quot;W*&quot;,
$_[0])); # unpack Unicode characters }</p>

<p>For example,</p>

<p>nice_string(&quot;foobar0)</p>

<p>returns the string</p>

<p>&rsquo;foobarA&rsquo;</p>

<p>which is ready to be printed.</p>

<p>Special Cases &middot; Bit Complement Operator ~ And
vec()</p>

<p>The bit complement operator &quot;~&quot; may produce
surprising results if used on strings containing characters
with ordinal values above 255. In such a case, the results
are consistent with the internal encoding of the characters,
but not with much else. So dont do that. Similarly for
&quot;vec()&quot;: you will be operating on the
internally-encoded bit patterns of the Unicode characters,
not on the code point values, which is very probably not
what you want.</p>

<p>&middot; Peeking At Perls Internal Encoding</p>

<p>Normal users of Perl should never care how Perl encodes
any particular Unicode string (because the normal ways to
get at the contents of a string with Unicode--via input and
output--should always be via explicitly-defined I/O layers).
But if you must, there are two ways of looking behind the
scenes.</p>

<p>One way of peeking inside the internal encoding of
Unicode characters is to use &quot;unpack(&quot;C*&quot;,
...&quot; to get the bytes of whatever the string encoding
happens to be, or &quot;unpack(&quot;U0..&quot;, ...)&quot;
to get the bytes of the UTF-8 encoding:</p>

<p># this prints c4 80 for the UTF-8 bytes 0xc4 0x80 print
join(&quot; &quot;, unpack(&quot;U0(H2)*&quot;,
pack(&quot;U&quot;, 0x100))), &quot;0;</p>

<p>Yet another way would be to use the Devel::Peek
module:</p>

<p>perl -MDevel::Peek -e &rsquo;Dump(chr(0x100))&rsquo;</p>

<p>That shows the &quot;UTF8&quot; flag in FLAGS and both
the UTF-8 bytes and Unicode characters in &quot;PV&quot;.
See also later in this document the discussion about the
&quot;utf8::is_utf8()&quot; function.</p>

<p>Advanced Topics &middot; String Equivalence</p>

<p>The question of string equivalence turns somewhat
complicated in Unicode: what do you mean by
&quot;equal&quot;?</p>

<p>(Is &quot;LATIN CAPITAL LETTER A WITH ACUTE&quot; equal
to &quot;LATIN CAPITAL LETTER A&quot;?)</p>

<p>The short answer is that by default Perl compares
equivalence (&quot;eq&quot;, &quot;ne&quot;) based only on
code points of the characters. In the above case, the answer
is no (because 0x00C1 != 0x0041). But sometimes, any CAPITAL
LETTER As should be considered equal, or even As of any
case.</p>

<p>The long answer is that you need to consider character
normalization and casing issues: see Unicode::Normalize,
Unicode Technical Reports #15 and #21, Unicode Normalization
Forms and Case Mappings,
&lt;http://www.unicode.org/unicode/reports/tr15/&gt; and
&lt;http://www.unicode.org/unicode/reports/tr21/&gt;</p>

<p>As of Perl 5.8.0, the &quot;Full&quot; case-folding of
Case Mappings/SpecialCasing is implemented.</p>

<p>&middot; String Collation</p>

<p>People like to see their strings nicely sorted--or as
Unicode parlance goes, collated. But again, what do you mean
by collate?</p>

<p>(Does &quot;LATIN CAPITAL LETTER A WITH ACUTE&quot; come
before or after &quot;LATIN CAPITAL LETTER A WITH
GRAVE&quot;?)</p>

<p>The short answer is that by default, Perl compares
strings (&quot;lt&quot;, &quot;le&quot;, &quot;cmp&quot;,
&quot;ge&quot;, &quot;gt&quot;) based only on the code
points of the characters. In the above case, the answer is
&quot;after&quot;, since 0x00C1 &gt; 0x00C0.</p>

<p>The long answer is that &quot;it depends&quot;, and a
good answer cannot be given without knowing (at the very
least) the language context. See Unicode::Collate, and
Unicode Collation Algorithm
&lt;http://www.unicode.org/unicode/reports/tr10/&gt;</p>

<p>Miscellaneous &middot; Character Ranges and Classes</p>

<p>Character ranges in regular expression character classes
(&quot;/[a-z]/&quot;) and in the &quot;tr///&quot; (also
known as &quot;y///&quot;) operator are not magically
Unicode-aware. What this means is that &quot;[A-Za-z]&quot;
will not magically start to mean &quot;all alphabetic
letters&quot;; not that it does mean that even for 8-bit
characters, you should be using &quot;/[[:alpha:]]/&quot; in
that case.</p>

<p>For specifying character classes like that in regular
expressions, you can use the various Unicode
properties--&quot;L&quot;, or perhaps
&quot;{Alphabetic}&quot;, in this particular case. You can
use Unicode code points as the end points of character
ranges, but there is no magic associated with specifying a
certain range. For further information--there are dozens of
Unicode character classes--see perlunicode.</p>

<p>&middot; String-To-Number Conversions</p>

<p>Unicode does define several other decimal--and
numeric--characters besides the familiar 0 to 9, such as the
Arabic and Indic digits. Perl does not support
string-to-number conversion for digits other than ASCII 0 to
9 (and ASCII a to f for hexadecimal).</p>

<p>Questions With Answers &middot; Will My Old Scripts
Break?</p>

<p>Very probably not. Unless you are generating Unicode
characters somehow, old behaviour should be preserved. About
the only behaviour that has changed and which could start
generating Unicode is the old behaviour of &quot;chr()&quot;
where supplying an argument more than 255 produced a
character modulo 255. &quot;chr(300)&quot;, for example, was
equal to &quot;chr(45)&quot; or &quot;-&quot; (in ASCII),
now it is LATIN CAPITAL LETTER I WITH BREVE.</p>

<p>&middot; How Do I Make My Scripts Work With Unicode?</p>

<p>Very little work should be needed since nothing changes
until you generate Unicode data. The most important thing is
getting input as Unicode; for that, see the earlier I/O
discussion.</p>

<p>&middot; How Do I Know Whether My String Is In
Unicode?</p>

<p>You shouldnt have to care. But you may, because
currently the semantics of the characters whose ordinals are
in the range 128 to 255 is different depending on whether
the string they are contained within is in Unicode or not.
(See perlunicode.)</p>

<p>To determine if a string is in Unicode, use:</p>

<p>print utf8::is_utf8($string) ? 1 : 0, &quot;0;</p>

<p>But note that this doesn t mean that any of the
characters in the string are necessary UTF-8 encoded, or
that any of the characters have code points greater than
0xFF (255) or even 0x80 (128), or that the string has any
characters at all. All the &quot;is_utf8()&quot; does is to
return the value of the internal &quot;utf8ness&quot; flag
attached to the $string. If the flag is off, the bytes in
the scalar are interpreted as a single byte encoding. If the
flag is on, the bytes in the scalar are interpreted as the
(multi-byte, variable-length) UTF-8 encoded code points of
the characters. Bytes added to an UTF-8 encoded string are
automatically upgraded to UTF-8. If mixed non-UTF-8 and
UTF-8 scalars are merged (double- quoted interpolation,
explicit concatenation, and printf/sprintf parameter
substitution), the result will be UTF-8 encoded as if copies
of the byte strings were upgraded to UTF-8: for example,</p>

<p>$a = &quot;ab0c&quot;; $b = &quot;&quot;; print &quot;$a
= $b0;</p>

<p>the output string will be UTF-8-encoded &quot;ab0c = 0,
but $a will stay byte-encoded.</p>

<p>Sometimes you might really need to know the byte length
of a string instead of the character length. For that use
either the &quot;Encode::encode_utf8()&quot; function or the
&quot;bytes&quot; pragma and the &quot;length()&quot;
function:</p>

<p>my $unicode = chr(0x100); print length($unicode),
&quot;0; # will print 1 require Encode; print
length(Encode::encode_utf8($unicode)), &quot;0; # will print
2 use bytes; print length($unicode), &quot;0; # will also
print 2 # (the 0xC4 0x80 of the UTF-8)</p>

<p>&middot; How Do I Detect Data Thats Not Valid In a
Particular Encoding?</p>

<p>Use the &quot;Encode&quot; package to try converting it.
For example,</p>

<p>use Encode &rsquo;decode_utf8&rsquo;;</p>

<p>if (eval { decode_utf8($string, Encode::FB_CROAK); 1 })
{ # $string is valid utf8 } else { # $string is not valid
utf8 }</p>

<p>Or use &quot;unpack&quot; to try decoding it:</p>

<p>use warnings; @chars = unpack(&quot;C0U*&quot;,
$string_of_bytes_that_I_think_is_utf8);</p>

<p>If invalid, a &quot;Malformed UTF-8 character&quot;
warning is produced. The &quot;C0&quot; means &quot;process
the string character per character&quot;. Without that, the
&quot;unpack(&quot;U*&quot;, ...)&quot; would work in
&quot;U0&quot; mode (the default if the format string starts
with &quot;U&quot;) and it would return the bytes making up
the UTF-8 encoding of the target string, something that will
always work.</p>

<p>&middot; How Do I Convert Binary Data Into a Particular
Encoding, Or Vice Versa?</p>

<p>This probably isn t as useful as you might think.
Normally, you shouldnt need to.</p>

<p>In one sense, what you are asking doesn t make much
sense: encodings are for characters, and binary data are not
&quot;characters&quot;, so converting &quot;data&quot; into
some encoding isn t meaningful unless you know in what
character set and encoding the binary data is in, in which
case its not just binary data, now is it?</p>

<p>If you have a raw sequence of bytes that you know should
be interpreted via a particular encoding, you can use
&quot;Encode&quot;:</p>

<p>use Encode &rsquo;from_to&rsquo;; from_to($data,
&quot;iso-8859-1&quot;, &quot;utf-8&quot;); # from latin-1
to utf-8</p>

<p>The call to &quot;from_to()&quot; changes the bytes in
$data, but nothing material about the nature of the string
has changed as far as Perl is concerned. Both before and
after the call, the string $data contains just a bunch of
8-bit bytes. As far as Perl is concerned, the encoding of
the string remains as &quot;system-native 8-bit
bytes&quot;.</p>

<p>You might relate this to a fictional Translate
module:</p>

<p>use Translate; my $phrase = &quot;Yes&quot;;
Translate::from_to($phrase, &rsquo;english&rsquo;,
&rsquo;deutsch&rsquo;); ## phrase now contains
&quot;Ja&quot;</p>

<p>The contents of the string changes, but not the nature
of the string. Perl doesnt know any more after the call than
before that the contents of the string indicates the
affirmative.</p>

<p>Back to converting data. If you have (or want) data in
your system s native 8-bit encoding (e.g. Latin-1, EBCDIC,
etc.), you can use pack/unpack to convert to/from
Unicode.</p>

<p>$native_string = pack(&quot;W*&quot;,
unpack(&quot;U*&quot;, $Unicode_string)); $Unicode_string =
pack(&quot;U*&quot;, unpack(&quot;W*&quot;,
$native_string));</p>

<p>If you have a sequence of bytes you know is valid UTF-8,
but Perl doesnt know it yet, you can make Perl a believer,
too:</p>

<p>use Encode &rsquo;decode_utf8&rsquo;; $Unicode =
decode_utf8($bytes);</p>

<p>or:</p>

<p>$Unicode = pack(&quot;U0a*&quot;, $bytes);</p>

<p>You can find the bytes that make up a UTF-8 sequence
with</p>

<p>@bytes = unpack(&quot;C*&quot;, $Unicode_string)</p>

<p>and you can create well-formed Unicode with</p>

<p>$Unicode_string = pack(&quot;U*&quot;, 0xff, ...)</p>

<p>&middot; How Do I Display Unicode? How Do I Input
Unicode?</p>

<p>See &lt;http://www.alanwood.net/unicode/&gt; and
&lt;http://www.cl.cam.ac.uk/~mgk25/unicode.html&gt;</p>

<p>&middot; How Does Unicode Work With Traditional
Locales?</p>

<p>In Perl, not very well. Avoid using locales through the
&quot;locale&quot; pragma. Use only one or the other. But
see perlrun for the description of the &quot;-C&quot; switch
and its environment counterpart, $ENV{PERL_UNICODE} to see
how to enable various Unicode features, for example by using
locale settings.</p>

<p>Hexadecimal Notation The Unicode standard prefers using
hexadecimal notation because that more clearly shows the
division of Unicode into blocks of 256 characters.
Hexadecimal is also simply shorter than decimal. You can use
decimal notation, too, but learning to use hexadecimal just
makes life easier with the Unicode standard. The
&quot;U+HHHH&quot; notation uses hexadecimal, for
example.</p>

<p>The &quot;0x&quot; prefix means a hexadecimal number,
the digits are 0-9 and a-f (or A-F, case doesn t matter).
Each hexadecimal digit represents four bits, or half a byte.
&quot;print 0x..., &quot;0&quot; will show a hexadecimal
number in decimal, and &quot;printf &quot;%x0,
$decimal&quot; will show a decimal number in hexadecimal. If
you have just the &quot;hex digits&quot; of a hexadecimal
number, you can use the &quot;hex()&quot; function.</p>

<p>print 0x0009, &quot;0; # 9 print 0x000a, &quot;0; # 10
print 0x000f, &quot;0; # 15 print 0x0010, &quot;0; # 16
print 0x0011, &quot;0; # 17 print 0x0100, &quot;0; # 256</p>

<p>print 0x0041, &quot;0; # 65</p>

<p>printf &quot;%x0, 65; # 41 printf &quot;%#x0, 65; #
0x41</p>

<p>print hex(&quot;41&quot;), &quot;0; # 65</p>

<p>Further Resources &middot; Unicode Consortium</p>

<p>&lt;http://www.unicode.org/&gt;</p>

<p>&middot; Unicode FAQ</p>

<p>&lt;http://www.unicode.org/unicode/faq/&gt;</p>

<p>&middot; Unicode Glossary</p>

<p>&lt;http://www.unicode.org/glossary/&gt;</p>

<p>&middot; Unicode Useful Resources</p>


<p>&lt;http://www.unicode.org/unicode/onlinedat/resources.html&gt;</p>

<p>&middot; Unicode and Multilingual Support in HTML,
Fonts, Web Browsers and Other Applications</p>

<p>&lt;http://www.alanwood.net/unicode/&gt;</p>

<p>&middot; UTF-8 and Unicode FAQ for Unix/Linux</p>

<p>&lt;http://www.cl.cam.ac.uk/~mgk25/unicode.html&gt;</p>

<p>&middot; Legacy Character Sets</p>

<p>&lt;http://www.czyborra.com/&gt;
&lt;http://www.eki.ee/letter/&gt;</p>

<p>&middot; The Unicode support files live within the Perl
installation in the directory</p>

<p>$Config{installprivlib}/unicore</p>

<p>in Perl 5.8.0 or newer, and</p>

<p>$Config{installprivlib}/unicode</p>

<p>in the Perl 5.6 series. (The renaming to lib/unicore was
done to avoid naming conflicts with lib/Unicode in
case-insensitive filesystems.) The main Unicode data file is
UnicodeData.txt (or Unicode.301 in Perl 5.6.1.) You can find
the $Config{installprivlib} by</p>

<p>perl &quot;-V:installprivlib&quot;</p>

<p>You can explore various information from the Unicode
data files using the &quot;Unicode::UCD&quot; module.</p>

<p>UNICODE IN OLDER PERLS If you cannot upgrade your Perl
to 5.8.0 or later, you can still do some Unicode processing
by using the modules &quot;Unicode::String&quot;,
&quot;Unicode::Map8&quot;, and &quot;Unicode::Map&quot;,
available from CPAN. If you have the GNU recode installed,
you can also use the Perl front-end
&quot;Convert::Recode&quot; for character conversions.</p>

<p>The following are fast conversions from ISO 8859-1
(Latin-1) bytes to UTF-8 bytes and back, the code works even
with older Perl 5 versions.</p>

<p># ISO 8859-1 to UTF-8
s/([0-])/chr(0xC0|ord($1)&gt;&gt;6).chr(0x80|ord($1)&amp;0x3F)/eg;</p>

<p># UTF-8 to ISO 8859-1
s/([)([0-])/chr(ord($1)&lt;&lt;6&amp;0xC0|ord($2)&amp;0x3F)/eg;</p>

<p>SEE ALSO perlunitut, perlunicode, Encode, open, utf8,
bytes, perlretut, perlrun, Unicode::Collate,
Unicode::Normalize, Unicode::UCD</p>

<p>ACKNOWLEDGMENTS Thanks to the kind readers of the
perl5-porters@perl.org, perl-unicode@perl.org,
linux-utf8@nl.linux.org, and unicore@unicode.org mailing
lists for their valuable feedback.</p>

<p>AUTHOR, COPYRIGHT, AND LICENSE Copyright 2001-2002
Jarkko Hietaniemi &lt;jhi@iki.fi&gt;</p>

<p>This document may be distributed under the same terms as
Perl itself.</p>

<p>perl v5.10.1 2009-02-25 PERLUNIINTRO(1)</p>
<hr>
</body>
</html>

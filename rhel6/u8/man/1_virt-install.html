<!-- Creator     : groff version 1.18.1.4 -->
<!-- CreationDate: Sat Nov 12 06:43:53 2016 -->
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta name="Content-Style" content="text/css">
<title></title>
</head>
<body>

<hr>

<p>VIRT-INSTALL(1) Virtual Machine Install Tools
VIRT-INSTALL(1)</p>

<p>NAME virt-install - provision new virtual machines</p>

<p>SYNOPSIS virt-install [OPTION]...</p>

<p>DESCRIPTION virt-install is a command line tool for
creating new KVM, Xen, or Linux container guests using the
&quot;libvirt&quot; hypervisor management library. See the
EXAMPLES section at the end of this document to quickly get
started.</p>

<p>virt-install tool supports graphical installations using
(for example) VNC or SPICE, as well as text mode installs
over serial console. The guest can be configured to use one
or more virtual disks, network interfaces, audio devices,
physical USB or PCI devices, among others.</p>

<p>The installation media can be held locally or remotely
on NFS, HTTP, FTP servers. In the latter case
&quot;virt-install&quot; will fetch the minimal files
necessary to kick off the installation process, allowing the
guest to fetch the rest of the OS distribution as needed.
PXE booting, and importing an existing disk image (thus
skipping the install phase) are also supported.</p>

<p>Given suitable command line arguments,
&quot;virt-install&quot; is capable of running completely
unattended, with the guest kickstarting itself too. This
allows for easy automation of guest installs. An interactive
mode is also available with the --prompt option, but this
will only ask for the minimum required options.</p>

<p>OPTIONS Most options are not required. Minimum
requirements are --name, --ram, guest storage (--disk,
--filesystem or --nodisks), and an install option.</p>

<p>-h, --help Show the help message and exit</p>

<p>--connect=CONNECT Connect to a non-default hypervisor.
The default connection is chosen based on the following
rules:</p>

<p>xen If running on a host with the Xen kernel (checks
against /proc/xen)</p>

<p>qemu:///system If running on a bare metal kernel as root
(needed for KVM installs)</p>

<p>qemu:///session If running on a bare metal kernel as
non-root</p>

<p>It is only necessary to provide the
&quot;--connect&quot; argument if this default
prioritization is incorrect, eg if wanting to use QEMU while
on a Xen kernel.</p>

<p>General Options General configuration parameters that
apply to all types of guest installs.</p>

<p>-n NAME, --name=NAME Name of the new guest virtual
machine instance. This must be unique amongst all guests
known to the hypervisor on the connection, including those
not currently active. To re-define an existing guest, use
the virsh(1) tool to shut it down (virsh shutdown) &amp;
delete (virsh undefine) it prior to running
&quot;virt-install&quot;.</p>

<p>-r MEMORY, --ram=MEMORY Memory to allocate for guest
instance in megabytes. If the hypervisor does not have
enough free memory, it is usual for it to automatically take
memory away from the host operating system to satisfy this
allocation.</p>

<p>--arch=ARCH Request a non-native CPU architecture for
the guest virtual machine. If omitted, the host CPU
architecture will be used in the guest.</p>

<p>--machine=MACHINE The machine type to emulate. This will
typically not need to be specified for Xen or KVM, but is
useful for choosing machine types of more exotic
architectures.</p>

<p>-u UUID, --uuid=UUID UUID for the guest; if none is
given a random UUID will be generated. If you specify UUID,
you should use a 32-digit hexadecimal number. UUID are
intended to be unique across the entire data center, and
indeed world. Bear this in mind if manually specifying a
UUID</p>


<p>--vcpus=VCPUS[,maxvcpus=MAX][,sockets=#][,cores=#][,threads=#]
Number of virtual cpus to configure for the guest. If
maxvcpus is specified, the guest will be able to hotplug up
to MAX vcpus while the guest is running, but will startup
with VCPUS.</p>

<p>CPU topology can additionally be specified with sockets,
cores, and threads. If values are omitted, the rest will be
autofilled prefering sockets over cores over threads.</p>

<p>--cpuset=CPUSET Set which physical cpus the guest can
use. &quot;CPUSET&quot; is a comma separated list of
numbers, which can also be specified in ranges or cpus to
exclude. Example:</p>

<p>0,2,3,5 : Use processors 0,2,3 and 5 1-5,^3,8 : Use
processors 1,2,4,5 and 8</p>

<p>If the value auto is passed, virt-install attempts to
automatically determine an optimal cpu pinning using NUMA
data, if available.</p>

<p>--numatune=NODESET,[mode=MODE] Tune NUMA policy for the
domain process. Example invocations</p>

<p>--numatune 1,2,3,4-7 --numatune</p>

<p>Specifies the numa nodes to allocate memory from. This
has the same syntax as &quot;--cpuset&quot; option. mode can
be one of interleave, preferred , or strict (the default).
See man 8 numactl for information about each mode.</p>

<p>The nodeset string must use escaped-quotes if specifying
any other option.</p>

<p>--cpu
MODEL[,+feature][,-feature][,match=MATCH][,vendor=VENDOR]
Configure the CPU model and CPU features exposed to the
guest. The only required value is MODEL, which is a valid
CPU model as listed in libvirts cpu_map.xml file.</p>

<p>Specific CPU features can be specified in a number of
ways: using one of libvirt s feature policy values force,
require, optional, disable, or forbid, or with the shorthand
+feature and -feature , which equal force=feature and
disable=feature respectively</p>

<p>Some examples:</p>

<p>--cpu core2duo,+x2apic,disable=vmx Expose the core2duo
CPU model, force enable x2apic, but do not expose vmx</p>

<p>--cpu host Expose the host CPUs configuration to the
guest. This enables the guest to take advantage of many of
the host CPUs features (better performance), but may cause
issues if migrating the guest to a host without an identical
CPU.</p>

<p>--description Human readable text description of the
virtual machine. This will be stored in the guests XML
configuration for access by other applications.</p>

<p>--security type=TYPE[,label=LABEL][,relabel=yes|no]
Configure domain security driver settings. Type can be
either static or dynamic . static configuration requires a
security LABEL. Specifying LABEL without TYPE implies static
configuration. To have libvirt automatically apply your
static label, you must specify relabel=yes.</p>

<p>Installation Method options -c CDROM, --cdrom=CDROM File
or device use as a virtual CD-ROM device for fully
virtualized guests. It can be path to an ISO image, or to a
CDROM device. It can also be a URL from which to
fetch/access a minimal boot ISO image. The URLs take the
same format as described for the &quot;--location&quot;
argument. If a cdrom has been specified via the
&quot;--disk&quot; option, and neither &quot;--cdrom&quot;
nor any other install option is specified, the
&quot;--disk&quot; cdrom is used as the install media.</p>

<p>-l LOCATION, --location=LOCATION Distribution tree
installtion source. virt-install can recognize certain
distribution trees and fetches a bootable kernel/initrd pair
to launch the install.</p>

<p>With libvirt 0.9.4 or later, network URL installs work
for remote connections. virt-install will download
kernel/initrd to the local machine, and then upload the
media to the remote host. This option requires the URL to be
accessible by both the local and remote host.</p>

<p>The &quot;LOCATION&quot; can take one of the following
forms:</p>

<p>DIRECTORY Path to a local directory containing an
installable distribution image</p>

<p>nfs:host:/path or nfs://host/path An NFS server location
containing an installable distribution image</p>

<p>http://host/path An HTTP server location containing an
installable distribution image</p>

<p>ftp://host/path An FTP server location containing an
installable distribution image</p>

<p>Some distro specific url samples:</p>

<p>Fedora/Red Hat Based
http://download.fedoraproject.org/pub/fedora/linux/releases/10/Fedora/i386/os/</p>

<p>Debian/Ubuntu
http://ftp.us.debian.org/debian/dists/etch/main/installer-amd64/</p>

<p>Suse
http://download.opensuse.org/distribution/11.0/repo/oss/</p>

<p>Mandriva
ftp://ftp.uwsg.indiana.edu/linux/mandrake/official/2009.0/i586/</p>

<p>--pxe Use the PXE boot protocol to load the initial
ramdisk and kernel for starting the guest installation
process.</p>

<p>--import Skip the OS installation process, and build a
guest around an existing disk image. The device used for
booting is the first device specified via &quot;--disk&quot;
or &quot;--filesystem&quot;.</p>

<p>--init=INITPATH Path to a binary that the container
guest will init. If a root &quot;--filesystem&quot; is has
been specified, virt-install will default to /sbin/init,
otherwise will default to /bin/sh.</p>

<p>--livecd Specify that the installation media is a live
CD and thus the guest needs to be configured to boot off the
CDROM device permanently. It may be desirable to also use
the &quot;--nodisks&quot; flag in combination.</p>

<p>-x EXTRA, --extra-args=EXTRA Additional kernel command
line arguments to pass to the installer when performing a
guest install from &quot;--location&quot;. One common usage
is specifying an anaconda kickstart file for automated
installs, such as --extra-args
&quot;ks=http://myserver/my.ks&quot;</p>

<p>--initrd-inject=PATH Add PATH to the root of the initrd
fetched with &quot;--location&quot;. This can be used to run
an automated install without requiring a network hosted
kickstart file:</p>

<p>--initrd-inject=/path/to/my.ks --extra-args
&quot;ks=file:/my.ks&quot;</p>

<p>--os-type=OS_TYPE Optimize the guest configuration for a
type of operating system (ex. linux, windows). This will
attempt to pick the most suitable ACPI &amp; APIC settings,
optimally supported mouse drivers, virtio, and generally
accommodate other operating system quirks.</p>

<p>By default, virt-install will attempt to auto detect
this value from the install media (currently only supported
for URL installs). Autodetection can be disabled with the
special value none</p>

<p>See &quot;--os-variant&quot; for valid options.</p>

<p>--os-variant=OS_VARIANT Further optimize the guest
configuration for a specific operating system variant (ex.
fedora8, winxp). This parameter is optional, and does not
require an &quot;--os-type&quot; to be specified.</p>

<p>By default, virt-install will attempt to auto detect
this value from the install media (currently only supported
for URL installs). Autodetection can be disabled with the
special value none.</p>

<p>If the special value list is passed, virt-install will
print the full list of variant values and exit. The printed
format is not a stable interface, DO NOT PARSE IT.</p>

<p>If the special value none is passed, no os variant is
recorded and OS autodetection is disabled.</p>

<p>Values for some recent OS options are:</p>

<p>win7 : Microsoft Windows 7 and later vista : Microsoft
Windows Vista winxp64 : Microsoft Windows XP (x86_64) winxp
: Microsoft Windows XP win2k8 : Microsoft Windows Server
2008 and later win2k3 : Microsoft Windows Server 2003
freebsd8 : FreeBSD 8.x and later generic : Generic
debianwheezy : Debian Wheezy and later debiansqueeze :
Debian Squeeze debianlenny : Debian Lenny fedora18 : Fedora
18 and later fedora17 : Fedora 17 fedora16 : Fedora 16
fedora15 : Fedora 15 mageia1 : Mageia 1 and later mes5.1 :
Mandriva Enterprise Server 5.1 and later rhel6 : Red Hat
Enterprise Linux 6 rhel5.4 : Red Hat Enterprise Linux 5.4 or
later rhel4 : Red Hat Enterprise Linux 4 sles11 : Suse Linux
Enterprise Server 11 and later sles10 : Suse Linux
Enterprise Server opensuse12 : openSuse 12 and later
opensuse11 : openSuse 11 ubuntuquantal : Ubuntu 12.10
(Quantal Quetzal) and later ubuntuprecise : Ubuntu 12.04 LTS
(Precise Pangolin) ubuntuoneiric : Ubuntu 11.10 (Oneiric
Ocelot) ubuntunatty : Ubuntu 11.04 (Natty Narwhal)
ubuntulucid : Ubuntu 10.04 LTS (Lucid Lynx) ubuntuhardy :
Ubuntu 8.04 LTS (Hardy Heron)</p>

<p>Use --os-variant list to see the full OS list</p>

<p>--boot=BOOTOPTS Optionally specify the post-install VM
boot configuration. This option allows specifying a boot
device order, permanently booting off kernel/initrd with
option kernel arguments, and enabling a BIOS boot menu
(requires libvirt 0.8.3 or later)</p>

<p>--boot can be specified in addition to other install
options (such as --location, --cdrom, etc.) or can be
specified on its own. In the latter case, behavior is
similar to the --import install option: there is no install
phase, the guest is just created and launched as
specified.</p>

<p>Some examples:</p>

<p>--boot cdrom,fd,hd,network,menu=on Set the boot device
priority as first cdrom, first floppy, first harddisk,
network PXE boot. Additionally enable BIOS boot menu
prompt.</p>

<p>--boot
kernel=KERNEL,initrd=INITRD,kernel_args=&quot;console=/dev/ttyS0&quot;
Have guest permanently boot off a local kernel/initrd pair,
with the specified kernel options.</p>

<p>Storage Configuration --disk=DISKOPTS Specifies media to
use as storage for the guest, with various options. The
general format of a disk string is</p>

<p>--disk opt1=val1,opt2=val2,...</p>

<p>To specify media, the command can either be:</p>

<p>--disk /some/storage/path,opt1=val1</p>

<p>or explicitly specify one of the following
arguments:</p>

<p>path A path to some storage media to use, existing or
not. Existing media can be a file or block device. If
installing on a remote host, the existing media must be
shared as a libvirt storage volume.</p>

<p>Specifying a non-existent path implies attempting to
create the new storage, and will require specifyng a size
value. If the base directory of the path is a libvirt
storage pool on the host, the new storage will be created as
a libvirt storage volume. For remote hosts, the base
directory is required to be a storage pool if using this
method.</p>

<p>pool An existing libvirt storage pool name to create new
storage on. Requires specifying a size value.</p>

<p>vol An existing libvirt storage volume to use. This is
specified as poolname/volname.</p>

<p>Other available options:</p>

<p>device Disk device type. Value can be cdrom, disk, lun
or floppy . Default is disk. If a cdrom is specified, and no
install method is chosen, the cdrom is used as the install
media.</p>

<p>bus Disk bus type. Value can be ide, scsi, usb, virtio
or xen. The default is hypervisor dependent since not all
hypervisors support all bus types.</p>

<p>perms Disk permissions. Value can be rw (Read/Write), ro
(Readonly), or sh (Shared Read/Write). Default is rw</p>

<p>size size (in GB) to use if creating new storage</p>

<p>sparse whether to skip fully allocating newly created
storage. Value is true or false . Default is true (do not
fully allocate) unless it isnt supported by the underlying
storage type.</p>

<p>The initial time taken to fully-allocate the guest
virtual disk (sparse=false) will be usually balanced by
faster install times inside the guest. Thus use of this
option is recommended to ensure consistently high
performance and to avoid I/O errors in the guest should the
host filesystem fill up.</p>

<p>cache The cache mode to be used. The host pagecache
provides cache memory. The cache value can be none,
writethrough , or writeback . writethrough provides read
caching. writeback provides read and write caching.</p>

<p>format Image format to be used if creating managed
storage. For file volumes, this can be raw, qcow2, vmdk,
etc. See format types in
&lt;http://libvirt.org/storage.html&gt; for possible values.
This is often mapped to the driver_type value as well.</p>

<p>With libvirt 0.8.3 and later, this option should be
specified if reusing an existing disk image, since libvirt
does not autodetect storage format as it is a potential
security issue. For example, if reusing an existing qcow2
image, you will want to specify format=qcow2, otherwise the
hypervisor may not be able to read your disk image.</p>

<p>driver_name Driver name the hypervisor should use when
accessing the specified storage. Typically does not need to
be set by the user.</p>

<p>driver_type Driver format/type the hypervisor should use
when accessing the specified storage. Typically does not
need to be set by the user.</p>

<p>io Disk IO backend. Can be either &quot;threads&quot; or
&quot;native&quot;.</p>

<p>error_policy How guest should react if a write error is
encountered. Can be one of &quot;stop&quot;,
&quot;none&quot;, or &quot;enospace&quot;</p>

<p>serial Serial number of the emulated disk device. This
is used in linux guests to set /dev/disk/by-id symlinks. An
example serial number might be: WD-WMAP9A966149</p>

<p>startup_policy It defines what to do with the disk if
the source file is not accessible. See possible values in
&lt;http://www.libvirt.org/formatdomain.html#elementsDisks&gt;</p>

<p>See the examples section for some uses. This option
deprecates &quot;--file&quot;, &quot;--file-size&quot;, and
&quot;--nonsparse&quot;.</p>

<p>--filesystem Specifies a directory on the host to export
to the guest. The most simple invocation is:</p>

<p>--filesystem /source/on/host,/target/point/in/guest</p>

<p>Which will work for recent QEMU and linux guest OS or
LXC containers. For QEMU, the target point is just a
mounting hint in sysfs, so will not be automatically
mounted.</p>

<p>The following explicit options can be specified:</p>

<p>type The type or the source directory. Valid values are
mount (the default) or template for OpenVZ templates.</p>

<p>mode The access mode for the source directory from the
guest OS. Only used with QEMU and type=mount. Valid modes
are passthrough (the default), mapped, or squash. See
libvirt domain XML documentation for more info.</p>

<p>source The directory on the host to share.</p>

<p>target The mount location to use in the guest.</p>

<p>--nodisks Request a virtual machine without any local
disk storage, typically used for running Live CD images or
installing to network storage (iSCSI or NFS root).</p>

<p>-f DISKFILE, --file=DISKFILE This option is deprecated
in favor of &quot;--disk path=DISKFILE&quot;.</p>

<p>-s DISKSIZE, --file-size=DISKSIZE This option is
deprecated in favor of &quot;--disk
...,size=DISKSIZE,...&quot;</p>

<p>--nonsparse This option is deprecated in favor of
&quot;--disk ...,sparse=false,...&quot;</p>

<p>Networking Configuration -w NETWORK,
--network=NETWORK,opt1=val1,opt2=val2 Connect the guest to
the host network. The value for &quot;NETWORK&quot; can take
one of 4 formats:</p>

<p>bridge=BRIDGE Connect to a bridge device in the host
called &quot;BRIDGE&quot;. Use this option if the host has
static networking config &amp; the guest requires full
outbound and inbound connectivity to/from the LAN. Also use
this if live migration will be used with this guest.</p>

<p>network=NAME Connect to a virtual network in the host
called &quot;NAME&quot;. Virtual networks can be listed,
created, deleted using the &quot;virsh&quot; command line
tool. In an unmodified install of &quot;libvirt&quot; there
is usually a virtual network with a name of
&quot;default&quot;. Use a virtual network if the host has
dynamic networking (eg NetworkManager), or using wireless.
The guest will be NATed to the LAN by whichever connection
is active.</p>

<p>type=direct,source=IFACE[,source_mode=MODE] Direct
connect to host interface IFACE using macvtap.</p>

<p>user Connect to the LAN using SLIRP. Only use this if
running a QEMU guest as an unprivileged user. This provides
a very limited form of NAT.</p>

<p>If this option is omitted a single NIC will be created
in the guest. If there is a bridge device in the host with a
physical interface enslaved, that will be used for
connectivity. Failing that, the virtual network called
&quot;default&quot; will be used. This option can be
specified multiple times to setup more than one NIC.</p>

<p>Other available options are:</p>

<p>model Network device model as seen by the guest. Value
can be any nic model supported by the hypervisor, e.g.:
e1000 , rtl8139, virtio, ...</p>

<p>mac Fixed MAC address for the guest; If this parameter
is omitted, or the value &quot;RANDOM&quot; is specified a
suitable address will be randomly generated. For Xen virtual
machines it is required that the first 3 pairs in the MAC
address be the sequence 00:16:3e, while for QEMU or KVM
virtual machines it must be 52:54:00.</p>

<p>--nonetworks Request a virtual machine without any
network interfaces.</p>

<p>-b BRIDGE, --bridge=BRIDGE This parameter is deprecated
in favour of &quot;--network bridge=bridge_name&quot;.</p>

<p>-m MAC, --mac=MAC This parameter is deprecated in favour
of &quot;--network NETWORK,mac=12:34...&quot;</p>

<p>Graphics Configuration If no graphics option is
specified, &quot;virt-install&quot; will default to
--graphics vnc if the DISPLAY environment variable is set,
otherwise --graphics none is used.</p>

<p>--graphics TYPE,opt1=arg1,opt2=arg2,... Specifies the
graphical display configuration. This does not configure any
virtual hardware, just how the guest s graphical display can
be accessed. Typically the user does not need to specify
this option, virt-install will try and choose a useful
default, and launch a suitable connection.</p>

<p>General format of a graphical string is</p>

<p>--graphics TYPE,opt1=arg1,opt2=arg2,...</p>

<p>For example:</p>

<p>--graphics vnc,password=foobar</p>

<p>The supported options are:</p>

<p>type The display type. This is one of:</p>

<p>vnc</p>

<p>Setup a virtual console in the guest and export it as a
VNC server in the host. Unless the &quot;port&quot;
parameter is also provided, the VNC server will run on the
first free port number at 5900 or above. The actual VNC
display allocated can be obtained using the
&quot;vncdisplay&quot; command to &quot;virsh&quot; (or
virt-viewer(1) can be used which handles this detail for the
use).</p>

<p>spice</p>

<p>Export the guests console using the Spice protocol.
Spice allows advanced features like audio and USB device
streaming, as well as improved graphical performance.</p>

<p>Using spice graphic type will work as if those arguments
were given:</p>

<p>--video qxl --channel spicevmc</p>

<p>none</p>

<p>No graphical console will be allocated for the guest.
Fully virtualized guests (Xen FV or QEmu/KVM) will need to
have a text console configured on the first serial port in
the guest (this can be done via the --extra-args option).
Xen PV will set this up automatically. The command virsh
console NAME can be used to connect to the serial
device.</p>

<p>port Request a permanent, statically assigned port
number for the guest console. This is used by vnc and
spice</p>

<p>tlsport Specify the spice tlsport.</p>

<p>listen Address to listen on for VNC/Spice connections.
Default is typically 127.0.0.1 (localhost only), but some
hypervisors allow changing this globally (for example, the
qemu driver default can be changed in
/etc/libvirt/qemu.conf). Use 0.0.0.0 to allow access from
other machines. This is use by vnc and spice</p>

<p>keymap Request that the virtual VNC console be
configured to run with a specific keyboard layout. If the
special value local is specified, virt-install will attempt
to configure to use the same keymap as the local system. A
value of none specifically defers to the hypervisor. Default
behavior is hypervisor specific, but typically is the same
as local. This is used by vnc</p>

<p>password Request a VNC password, required at connection
time. Beware, this info may end up in virt-install log
files, so don t use an important password. This is used by
vnc and spice</p>

<p>passwordvalidto Set an expiration date for password.
After the date/time has passed, all new graphical
connections are denyed until a new password is set. This is
used by vnc and spice</p>

<p>The format for this value is YYYY-MM-DDTHH:MM:SS, for
example 2011-04-01T14:30:15</p>

<p>--vnc This option is deprecated in favor of
&quot;--graphics vnc,...&quot;</p>

<p>--vncport=VNCPORT This option is deprecated in favor of
&quot;--graphics vnc,port=PORT,...&quot;</p>

<p>--vnclisten=VNCLISTEN This option is deprecated in favor
of &quot;--graphics vnc,listen=LISTEN,...&quot;</p>

<p>-k KEYMAP, --keymap=KEYMAP This option is deprecated in
favor of &quot;--graphics vnc,keymap=KEYMAP,...&quot;</p>

<p>--nographics This option is deprecated in favor of
&quot;--graphics none&quot;</p>

<p>--noautoconsole Dont automatically try to connect to the
guest console. The default behaviour is to launch a VNC
client to display the graphical console, or to run the
&quot;virsh&quot; &quot;console&quot; command to display the
text console. Use of this parameter will disable this
behaviour.</p>

<p>Virtualization Type options Options to override the
default virtualization type choices.</p>

<p>-v, --hvm Request the use of full virtualization, if
both para &amp; full virtualization are available on the
host. This parameter may not be available if connecting to a
Xen hypervisor on a machine without hardware virtualization
support. This parameter is implied if connecting to a QEMU
based hypervisor.</p>

<p>-p, --paravirt This guest should be a paravirtualized
guest. If the host supports both para &amp; full
virtualization, and neither this parameter nor the
&quot;--hvm&quot; are specified, this will be assumed.</p>

<p>--container This guest should be a container type guest.
This option is only required if the hypervisor supports
other guest types as well (so for example this option is the
default behavior for LXC and OpenVZ, but is provided for
completeness).</p>

<p>--virt-type The hypervisor to install on. Example
choices are kvm, qemu, xen, or kqemu. Availabile options are
listed via virsh capabilities in the &lt;domain&gt;
tags.</p>

<p>--accelerate Prefer KVM or KQEMU (in that order) if
installing a QEMU guest. This behavior is now the default,
and this option is deprecated. To install a plain QEMU
guest, use --virt-type qemu</p>

<p>--noapic Force disable APIC for the guest.</p>

<p>--noacpi Force disable ACPI for the guest.</p>

<p>Device Options --host-device=HOSTDEV Attach a physical
host device to the guest. Some example values for
HOSTDEV:</p>

<p>--host-device pci_0000_00_1b_0 A node device name via
libvirt, as shown by virsh nodedev-list</p>

<p>--host-device 001.003 USB by bus, device (via
lsusb).</p>

<p>--host-device 0x1234:0x5678 USB by vendor, product (via
lsusb).</p>

<p>--host-device 1f.01.02 PCI device (via lspci).</p>

<p>--soundhw MODEL Attach a virtual audio device to the
guest. MODEL specifies the emulated sound card model.
Possible values are ich6, ac97, es1370, sb16, pcspk, or
default. default will be AC97 if the hypervisor supports it,
otherwise it will be ES1370.</p>

<p>This deprecates the old boolean --sound model (which
still works the same as a single --soundhw default)</p>

<p>--watchdog MODEL[,action=ACTION] Attach a virtual
hardware watchdog device to the guest. This requires a
daemon and device driver in the guest. The watchdog fires a
signal when the virtual machine appears to hung. ACTION
specifies what libvirt will do when the watchdog fires.
Values are</p>

<p>reset Forcefully reset the guest (the default)</p>

<p>poweroff Forcefully power off the guest</p>

<p>pause Pause the guest</p>

<p>none Do nothing</p>

<p>shutdown Gracefully shutdown the guest (not recommended,
since a hung guest probably wont respond to a graceful
shutdown)</p>

<p>MODEL is the emulated device model: either i6300esb (the
default) or ib700. Some examples:</p>

<p>Use the recommended settings:</p>

<p>--watchdog default</p>

<p>Use the i6300esb with the poweroff action</p>

<p>--watchdog i6300esb,action=poweroff</p>

<p>--parallel=CHAROPTS --serial=CHAROPTS Specifies a serial
device to attach to the guest, with various options. The
general format of a serial string is</p>

<p>--serial type,opt1=val1,opt2=val2,...</p>

<p>--serial and --parallel devices share all the same
options, unless otherwise noted. Some of the types of
character device redirection are:</p>

<p>--serial pty Pseudo TTY. The allocated pty will be
listed in the running guests XML description.</p>

<p>--serial dev,path=HOSTPATH Host device. For serial
devices, this could be /dev/ttyS0. For parallel devices,
this could be /dev/parport0.</p>

<p>--serial file,path=FILENAME Write output to
FILENAME.</p>

<p>--serial pipe,path=PIPEPATH Named pipe (see pipe(7))</p>

<p>--serial tcp,host=HOST:PORT,mode=MODE,protocol=PROTOCOL
TCP net console. MODE is either bind (wait for connections
on HOST:PORT) or connect (send output to HOST:PORT), default
is connect . HOST defaults to 127.0.0.1, but PORT is
required. PROTOCOL can be either raw or telnet (default raw
). If telnet , the port acts like a telnet server or client.
Some examples:</p>

<p>Connect to localhost, port 1234:</p>

<p>--serial tcp,host=:1234</p>

<p>Wait for connections on any address, port 4567:</p>

<p>--serial tcp,host=0.0.0.0:4567,mode=bind</p>

<p>Wait for telnet connection on localhost, port 2222. The
user could then connect interactively to this console via
telnet localhost 2222:</p>

<p>--serial tcp,host=:2222,mode=bind,protocol=telnet</p>

<p>--serial
udp,host=CONNECT_HOST:PORT,bind_host=BIND_HOST:BIND_PORT UDP
net console. HOST:PORT is the destination to send output to
(default HOST is 127.0.0.1, PORT is required).
BIND_HOST:BIND_PORT is the optional local address to bind to
(default BIND_HOST is 127.0.0.1, but is only set if
BIND_PORT is specified). Some examples:</p>

<p>Send output to default syslog port (may need to edit
/etc/rsyslog.conf accordingly):</p>

<p>--serial udp,host=:514</p>

<p>Send output to remote host 192.168.10.20, port 4444
(this output can be read on the remote host using nc -u -l
4444):</p>

<p>--serial udp,host=192.168.10.20:4444</p>

<p>--serial unix,path=UNIXPATH,mode=MODE Unix socket, see
unix(7). MODE has similar behavior and defaults as --serial
tcp,mode=MODE</p>

<p>--channel Specifies a communication channel device to
connect the guest and host machine. This option uses the
same options as --serial and --parallel for specifying the
host/source end of the channel. Extra target options are
used to specify how the guest machine sees the channel.</p>

<p>Some of the types of character device redirection
are:</p>

<p>--channel
SOURCE,target_type=guestfwd,target_address=HOST:PORT
Communication channel using QEMU usermode networking stack.
The guest can connect to the channel using the specified
HOST:PORT combination.</p>

<p>--channel SOURCE,target_type=virtio[,name=NAME]
Communication channel using virtio serial (requires 2.6.34
or later host and guest). Each instance of a virtio
--channel line is exposed in the guest as /dev/vport0p1,
/dev/vport0p2, etc. NAME is optional metadata, and can be
any string, such as org.linux-kvm.virtioport1. If specified,
this will be exposed in the guest at
/sys/class/virtio-ports/vport0p1/NAME</p>

<p>--channel spicevmc,target_type=virtio[,name=NAME]
Communication channel for QEMU spice agent, using virtio
serial (requires 2.6.34 or later host and guest). NAME is
optional metadata, and can be any string, such as the
default com.redhat.spice.0 that specifies how the guest will
see the channel.</p>

<p>--console Connect a text console between the guest and
host. Certain guest and hypervisor combinations can
automatically set up a getty in the guest, so an out of the
box text login can be provided (target_type=xen for xen
paravirt guests, and possibly target_type=virtio in the
future).</p>

<p>Example:</p>

<p>--console pty,target_type=virtio Connect a virtio
console to the guest, redirected to a PTY on the host. For
supported guests, this exposes /dev/hvc0 in the guest. See
http://fedoraproject.org/wiki/Features/VirtioSerial for more
info. virtio console requires libvirt 0.8.3 or later.</p>

<p>--video=VIDEO Specify what video device model will be
attached to the guest. Valid values for VIDEO are hypervisor
specific, but some options for recent kvm are cirrus, vga,
qxl, or vmvga (vmware).</p>

<p>--smartcard=MODE[,OPTS] Configure a virtual smartcard
device.</p>

<p>Mode is one of host, host-certificates, or passthrough.
Additional options are:</p>

<p>type Character device type to connect to on the host.
This is only applicable for passthrough mode.</p>

<p>An example invocation:</p>

<p>--smartcard passthrough,type=spicevmc Use the smartcard
channel of a SPICE graphics device to pass smartcard info to
the guest</p>

<p>See
&quot;http://libvirt.org/formatdomain.html#elementsSmartcard&quot;
for complete details.</p>

<p>--redirdev=BUS[,OPTS] Add a redirected device.</p>

<p>type The redirection type, currently supported is tcp or
spicevmc.</p>

<p>server The TCP server connection details, of the form
server:port.</p>

<p>Examples of invocation:</p>

<p>--redirdev usb,type=tcp,server=localhost:4000 Add a USB
redirected device provided by the TCP server on localhost
port 4000.</p>

<p>--redirdev usb,type=spicevmc Add a USB device redirected
via a dedicated Spice channel.</p>

<p>--panic OPTS Attach a panic notifier device to the
guest. For the recommended settings, use:</p>

<p>--panic default</p>

<p>See
&quot;http://libvirt.org/formatdomain.html#elementsPanic&quot;
for complete details.</p>

<p>Miscellaneous Options --autostart Set the autostart flag
for a domain. This causes the domain to be started on host
boot up.</p>

<p>--print-xml If the requested guest has no install phase
(--import, --boot), print the generated XML instead of
defining the guest. By default this WILL do storage creation
(can be disabled with --dry-run).</p>

<p>If the guest has an install phase, you will need to use
--print-step to specify exactly what XML output you want.
This option implies --quiet.</p>

<p>--print-step Acts similarly to --print-xml, except
requires specifying which install step to print XML for.
Possible values are 1, 2, 3, or all. Stage 1 is typically
booting from the install media, and stage 2 is typically the
final guest config booting off hardisk. Stage 3 is only
relevant for windows installs, which by default have a
second install stage. This option implies --quiet.</p>

<p>--noreboot Prevent the domain from automatically
rebooting after the install has completed.</p>

<p>--wait=WAIT Amount of time to wait (in minutes) for a VM
to complete its install. Without this option, virt-install
will wait for the console to close (not neccessarily
indicating the guest has shutdown), or in the case of
--noautoconsole, simply kick off the install and exit. Any
negative value will make virt-install wait indefinitely, a
value of 0 triggers the same results as noautoconsole. If
the time limit is exceeded, virt-install simply exits,
leaving the virtual machine in its current state.</p>

<p>--force Prevent interactive prompts. If the intended
prompt was a yes/no prompt, always say yes. For any other
prompts, the application will exit.</p>

<p>--dry-run Proceed through the guest creation process,
but do NOT create storage devices, change host device
configuration, or actually teach libvirt about the guest.
virt-install may still fetch install media, since this is
required to properly detect the OS to install.</p>

<p>--prompt Specifically enable prompting for required
information. Default prompting is off (as of virtinst
0.400.0)</p>

<p>--check-cpu Check that the number virtual cpus requested
does not exceed physical CPUs and warn if they do.</p>

<p>-q, --quiet Only print fatal error messages.</p>

<p>-d, --debug Print debugging information to the terminal
when running the install process. The debugging information
is also stored in
&quot;$HOME/.virtinst/virt-install.log&quot; even if this
parameter is omitted.</p>

<p>EXAMPLES Install a Fedora 13 KVM guest with virtio
accelerated disk/network, creating a new 8GB storage file,
installing from media in the hosts CDROM drive, auto
launching a graphical VNC viewer</p>

<p># virt-install --connect qemu:///system --virt-type kvm
--name demo --ram 500 --disk
path=/var/lib/libvirt/images/demo.img,size=8 --graphics vnc
--cdrom /dev/cdrom --os-variant fedora13</p>

<p>Install a Fedora 9 plain QEMU guest, using LVM
partition, virtual networking, booting from PXE, using VNC
server/viewer</p>

<p># virt-install --connect qemu:///system --name demo
--ram 500 --disk path=/dev/HostVG/DemoVM --network
network=default --virt-type qemu --graphics vnc --os-variant
fedora9</p>

<p>Run a Live CD image under Xen fullyvirt, in diskless
environment</p>

<p># virt-install --hvm --name demo --ram 500 --nodisks
--livecd --graphics vnc --cdrom /root/fedora7live.iso</p>

<p>Run /usr/bin/httpd in a linux container guest (LXC).
Resource usage is capped at 512 MB of ram and 2 host
cpus:</p>

<p># virt-install --connect lxc:/// --name httpd_guest
--ram 512 --vcpus 2 --init /usr/bin/httpd</p>

<p>Install a paravirtualized Xen guest, 500 MB of RAM, a 5
GB of disk, and Fedora Core 6 from a web server, in
text-only mode, with old style --file options:</p>

<p># virt-install --paravirt --name demo --ram 500 --file
/var/lib/xen/images/demo.img --file-size 6 --graphics none
--location
http://download.fedora.redhat.com/pub/fedora/linux/core/6/x86_64/os/</p>

<p>Create a guest from an existing disk image mydisk.img
using defaults for the rest of the options.</p>

<p># virt-install --name demo --ram 512 --disk
/home/user/VMs/mydisk.img --import</p>

<p>Test a custom kernel/initrd using an existing disk
image, manually specifying a serial device hooked to a PTY
on the host machine.</p>

<p># virt-install --name mykernel --ram 512 --disk
/home/user/VMs/mydisk.img --boot
kernel=/tmp/mykernel,initrd=/tmp/myinitrd,kernel_args=&quot;console=ttyS0&quot;
--serial pty</p>

<p>AUTHORS Written by Daniel P. Berrange, Hugh Brock,
Jeremy Katz, Cole Robinson and a team of many other
contributors. See the AUTHORS file in the source
distribution for the complete list of credits.</p>

<p>BUGS Please see
http://virt-manager.org/page/BugReporting</p>

<p>COPYRIGHT Copyright (C) 2006-2011 Red Hat, Inc, and
various contributors. This is free software. You may
redistribute copies of it under the terms of the GNU General
Public License
&quot;http://www.gnu.org/licenses/gpl.html&quot;. There is
NO WARRANTY, to the extent permitted by law.</p>

<p>SEE ALSO virsh(1), &quot;virt-clone(1)&quot;,
&quot;virt-manager(1)&quot;, the project website
&quot;http://virt-manager.org&quot;</p>

<p>2015-06-03 VIRT-INSTALL(1)</p>
<hr>
</body>
</html>

<!-- Creator     : groff version 1.22.2 -->
<!-- CreationDate: Sat Nov 12 01:03:29 2016 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title>LVCREATE</title>

</head>
<body>

<h1 align="center">LVCREATE</h1>

<a href="#NAME">NAME</a><br>
<a href="#SYNOPSIS">SYNOPSIS</a><br>
<a href="#DESCRIPTION">DESCRIPTION</a><br>
<a href="#OPTIONS">OPTIONS</a><br>
<a href="#Examples">Examples</a><br>
<a href="#SEE ALSO">SEE ALSO</a><br>

<hr>


<h2>NAME
<a name="NAME"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">lvcreate
&minus; create a logical volume in an existing volume
group</p>

<h2>SYNOPSIS
<a name="SYNOPSIS"></a>
</h2>



<p style="margin-left:11%; margin-top: 1em"><b>lvcreate</b>
[<b>&minus;a</b>|<b>&minus;&minus;activate</b>
[<i>a</i>|<i>e</i>|<i>l</i>]{<i>y</i>|<i>n</i>}]
[<b>&minus;&minus;addtag</b> <i>Tag</i>]
[<b>&minus;&minus;alloc</b> <i>AllocationPolicy</i>]
[<b>&minus;A</b>|<b>&minus;&minus;autobackup</b>
{<i>y</i>|<i>n</i>}]
[<b>&minus;H</b>|<b>&minus;&minus;cache</b>]
[<b>&minus;&minus;cachemode</b>
{<i>writeback</i>|<i>writethrough</i>}]
[<b>&minus;&minus;cachepool</b>
<i>CachePoolLogicalVolume</i>{<i>Name</i>|<i>Path</i>}
[<b>&minus;c</b>|<b>&minus;&minus;chunksize</b>
<i>ChunkSize</i>[<i>bBsSkKmMgG</i>]]
[<b>&minus;&minus;commandprofile</b> <i>ProfileName</i>]
[<b>&minus;C</b>|<b>&minus;&minus;contiguous</b>
{<i>y</i>|<i>n</i>}]
[<b>&minus;d</b>|<b>&minus;&minus;debug</b>]
[<b>&minus;&minus;discards</b>
{<i>ignore</i>|<i>nopassdown</i>|<i>passdown</i>}]
[<b>&minus;&minus;errorwhenfull</b> {<i>y</i>|<i>n</i>}]
[{<b>&minus;l</b>|<b>&minus;&minus;extents</b>
<i>LogicalExtentsNumber</i>[<i>%</i>{<i>FREE</i>|<i>PVS</i>|<i>VG</i>}]
| <b>&minus;L</b>|<b>&minus;&minus;size</b>
<i>LogicalVolumeSize</i>[<i>bBsSkKmMgGtTpPeE</i>]}
[<b>&minus;i</b>|<b>&minus;&minus;stripes</b> <i>Stripes</i>
[<b>&minus;I</b>|<b>&minus;&minus;stripesize</b>
<i>StripeSize</i>]]]
[<b>&minus;h</b>|<b>&minus;?</b>|<b>&minus;&minus;help</b>]
[<b>&minus;K</b>|<b>&minus;&minus;ignoreactivationskip</b>]
[<b>&minus;&minus;ignoremonitoring</b>]
[<b>&minus;&minus;minor</b> <i>minor</i>
[<b>&minus;j</b>|<b>&minus;&minus;major</b> <i>major</i>]]
[<b>&minus;&minus;metadataprofile</b> <i>ProfileName</i>]
[<b>&minus;m</b>|<b>&minus;&minus;mirrors</b> <i>Mirrors</i>
[{<b>&minus;&minus;corelog</b> |
<b>&minus;&minus;mirrorlog</b>
{<i>disk</i>|<i>core</i>|<i>mirrored</i>}}]
[<b>&minus;&minus;nosync</b>]
[<b>&minus;R</b>|<b>&minus;&minus;regionsize</b>
<i>MirrorLogRegionSize</i>[<i>bBsSkKmMgG</i>]]]
[<b>&minus;&minus;monitor</b> {<i>y</i>|<i>n</i>}]
[<b>&minus;n</b>|<b>&minus;&minus;name</b>
<i>LogicalVolume</i>{<i>Name</i>|<i>Path</i>}]
[<b>&minus;&minus;noudevsync</b>]
[<b>&minus;p</b>|<b>&minus;&minus;permission</b>
{<i>r</i>|<i>rw</i>}]
[<b>&minus;M</b>|<b>&minus;&minus;persistent</b>
{<i>y</i>|<i>n</i>}] [<b>&minus;&minus;poolmetadatasize</b>
<i>MetadataVolumeSize</i>[<i>bBsSkKmMgG</i>]]
[<b>&minus;&minus;poolmetadataspare</b> {<i>y</i>|<i>n</i>}]
[<b>&minus;&minus;</b>[<b>raid</b>]<b>maxrecoveryrate</b>
<i>Rate</i>]
[<b>&minus;&minus;</b>[<b>raid</b>]<b>minrecoveryrate</b>
<i>Rate</i>] [<b>&minus;r</b>|<b>&minus;&minus;readahead</b>
{<i>ReadAheadSectors</i>|<i>auto</i>|<i>none</i>}]
[<b>&minus;k</b>|<b>&minus;&minus;setactivationskip</b>
{<i>y</i>|<i>n</i>}]
[<b>&minus;s</b>|<b>&minus;&minus;snapshot</b>
[<b>&minus;V</b>|<b>&minus;&minus;virtualsize</b>
<i>VirtualSize</i>[<i>bBsSkKmMgGtTpPeE</i>]]
[<b>&minus;t</b>|<b>&minus;&minus;test</b>]
[<b>&minus;T</b>|<b>&minus;&minus;thin</b>]
[<b>&minus;&minus;thinpool</b>
<i>ThinPoolLogicalVolume</i>{<i>Name</i>|<i>Path</i>}]
[<b>&minus;&minus;type</b> <i>SegmentType</i>]
[<b>&minus;v</b>|<b>&minus;&minus;verbose</b>]
[<b>&minus;W</b>|<b>&minus;&minus;wipesignatures</b>]
[<b>&minus;Z</b>|<b>&minus;&minus;zero</b>
{<i>y</i>|<i>n</i>}]
[<i>VolumeGroup</i>{<i>Name</i>|<i>Path</i>}
[/<i>ExternalOrigin</i> | <i>Origin</i> |
<i>Pool</i>}<i>LogicalVolumeName</i>]
[<i>PhysicalVolumePath</i>[<i>:PE</i>[<i>&minus;PE</i>]]...]</p>


<p style="margin-left:11%; margin-top: 1em"><b>lvcreate</b>
[<b>&minus;l</b>|<b>&minus;&minus;extents</b>
<i>LogicalExtentsNumber</i>[<i>%</i>{<i>FREE</i>|<i>ORIGIN</i>|<i>PVS</i>|<i>VG</i>}]
| <b>&minus;L</b>|<b>&minus;&minus;size</b>
<i>LogicalVolumeSize</i>[<i>bBsSkKmMgGtTpPeE</i>]]
[<b>&minus;c</b>|<b>&minus;&minus;chunksize</b>
<i>ChunkSize</i>[<i>bBsSkKmMgG</i>]]
[<b>&minus;&minus;commandprofile</b> <i>Profilename</i>]
[<b>&minus;&minus;noudevsync</b>]
[<b>&minus;&minus;ignoremonitoring</b>]
[<b>&minus;&minus;metadataProfile</b> <i>ProfileName</i>]
[<b>&minus;&minus;monitor</b> {<i>y</i>|<i>n</i>}]
[<b>&minus;n</b>|<b>&minus;&minus;name</b>
<i>SnapshotLogicalVolume</i>{<i>Name</i>|<i>Path</i>}]
<b>&minus;s</b>|<b>&minus;&minus;snapshot</b>|<b>&minus;H</b>|<b>&minus;&minus;cache</b>
{[<i>VolumeGroup</i>{<i>Name</i>|<i>Path</i>}/]<i>OriginalLogicalVolumeName</i>
<b>&minus;V</b>|<b>&minus;&minus;virtualsize</b>
<i>VirtualSize</i>[<i>bBsSkKmMgGtTpPeE</i>]}</p>

<h2>DESCRIPTION
<a name="DESCRIPTION"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">lvcreate
creates a new logical volume in a volume group (see
<b>vgcreate</b>(8), <b>vgchange</b>(8)) by allocating
logical extents from the free physical extent pool of that
volume group. If there are not enough free physical extents
then the volume group can be extended (see
<b>vgextend</b>(8)) with other physical volumes or by
reducing existing logical volumes of this volume group in
size (see <b>lvreduce</b>(8)). If you specify one or more
PhysicalVolumes, allocation of physical extents will be
restricted to these volumes. <br>
The second form supports the creation of snapshot logical
volumes which keep the contents of the original logical
volume for backup purposes.</p>

<h2>OPTIONS
<a name="OPTIONS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">See
<b>lvm</b>(8) for common options. <b><br>
&minus;a</b>, <b>&minus;&minus;activate</b>
{<i>y</i>|<i>ay</i>|<i>n</i>|<i>ey</i>|<i>en</i>|<i>ly</i>|<i>ln</i>}</p>

<p style="margin-left:22%;">Controls the availability of
the Logical Volumes for immediate use after the command
finishes running. By default, new Logical Volumes are
activated (<b>&minus;a</b><i>y</i>). If it is possible
technically, <b>&minus;a</b><i>n</i> will leave the new
Logical Volume inactive. But for example, snapshots of
active origin can only be created in the active state so
<b>&minus;a</b><i>n</i> cannot be used with
<b>-&minus;type</b> <i>snapshot</i>. This does not apply to
thin volume snapshots, which are by default created with
flag to skip their activation (<b>-k</b><i>y</i>). Normally
the <b>&minus;&minus;zero</b> <i>n</i> argument has to be
supplied too because zeroing (the default behaviour) also
requires activation. If autoactivation option is used
(<b>&minus;a</b><i>ay</i>), the logical volume is activated
only if it matches an item in the
<i>activation</i>/<i>auto_activation_volume_list</i> set in
<b>lvm.conf</b>(5). For autoactivated logical volumes,
<b>&minus;&minus;zero</b> <i>n</i> and
<b>&minus;&minus;wipesignatures</b> <i>n</i> is always
assumed and it can&rsquo;t be overridden. If the clustered
locking is enabled, <b>&minus;a</b><i>ey</i> will activate
exclusively on one node and
<b>&minus;a</b>{<i>a</i>|<i>l</i>}<i>y</i> will activate
only on the local node.</p>

<p style="margin-left:11%;"><b>&minus;H</b>,
<b>&minus;&minus;cache</b></p>

<p style="margin-left:22%;">Creates cache or cache pool
logical volume or both. Specifying the optional argument
<b>&minus;&minus;size</b> will cause the creation of the
cache logical volume. Specifying both arguments will cause
the creation of cache with its cache pool volume. When the
Volume group name is specified together with existing
logical volume name which is NOT a cache pool name, such
volume is treaded as cache origin volume and cache pool is
created. In this case the <b>&minus;&minus;size</b> is used
to specify size of cache pool volume. See <b>lvmcache</b>(7)
for more info about caching support. Note that the cache
segment type requires a dm-cache kernel module version 1.3.0
or greater.</p>

<p style="margin-left:11%;"><b>&minus;&minus;cachemode</b>
{<i>writeback</i>|<i>writethrough</i>}</p>

<p style="margin-left:22%;">Specifying a cache mode
determines when the writes to a cache LV are considered
complete. When <i>writeback</i> is specified, a write is
considered complete as soon as it is stored in the cache
pool LV. If <i>writethough</i> is specified, a write is
considered complete only when it has been stored in the
cache pool LV and on the origin LV. While
<i>writethrough</i> may be slower for writes, it is more
resilient if something should happen to a device associated
with the cache pool LV.</p>

<p style="margin-left:11%;"><b>&minus;&minus;cachepool</b>
<i>CachePoolLogicalVolume</i>{<i>Name</i>|<i>Path</i>}</p>

<p style="margin-left:22%;">Specifies the name of cache
pool volume name. The other way to specify pool name is to
append name to Volume group name argument.</p>

<p style="margin-left:11%;"><b>&minus;c</b>,
<b>&minus;&minus;chunksize</b>
<i>ChunkSize</i>[<i>bBsSkKmMgG</i>]</p>

<p style="margin-left:22%;">Gives the size of chunk for
snapshot, cache pool and thin pool logical volumes. Default
unit is in kilobytes. <br>
For <i>snapshots</i> the value must be power of 2 between
4KiB and 512KiB and the default value is 4KiB. <br>
For <i>cache pools</i> the value must a multiple of 32KiB
between 32KiB and 1GiB. The default is 64KiB. <br>
For <i>thin pools</i> the value must be a multiple of 64KiB
between 64KiB and 1GiB. Default value starts with 64KiB and
grows up to fit the pool metadata size within 128MiB, if the
pool metadata size is not specified. See <b>lvm.conf</b>(5)
setting <i>allocation</i>/<i>thin_pool_chunk_size_policy</i>
to select different calculation policy. Thin pool target
version &lt;1.4 requires this value to be a power of 2. For
target version &lt;1.5 discard is not supported for non
power of 2 values.</p>

<p style="margin-left:11%;"><b>&minus;C</b>,
<b>&minus;&minus;contiguous</b> {<i>y</i>|<i>n</i>}</p>

<p style="margin-left:22%;">Sets or resets the contiguous
allocation policy for logical volumes. Default is no
contiguous allocation based on a next free principle.</p>


<p style="margin-left:11%;"><b>&minus;&minus;corelog</b></p>

<p style="margin-left:22%;">This is shortcut for option
<b>&minus;&minus;mirrorlog</b> <i>core</i>.</p>

<p style="margin-left:11%;"><b>&minus;&minus;discards</b>
{<i>ignore</i>|<i>nopassdown</i>|<i>passdown</i>}</p>

<p style="margin-left:22%;">Sets discards behavior for thin
pool. Default is <i>passdown</i>.</p>


<p style="margin-left:11%;"><b>&minus;&minus;errorwhenfull</b>
{<i>y</i>|<i>n</i><b>}</b></p>

<p style="margin-left:22%;">Configures thin pool behaviour
when data space is exhausted. Default is <i>n</i>o. Device
will queue I/O operations until target timeout (see
dm-thin-pool kernel module option <i>no_space_timeout</i>)
expires. Thus configured system has a time to i.e. extend
the size of thin pool data device. When set to <i>y</i>es,
the I/O operation is immeditelly errored.</p>

<p style="margin-left:11%;"><b>&minus;K</b>,
<b>&minus;&minus;ignoreactivationskip</b></p>

<p style="margin-left:22%;">Ignore the flag to skip Logical
Volumes during activation. Use
<b>&minus;&minus;setactivationskip</b> option to set or
reset activation skipping flag persistently for logical
volume.</p>


<p style="margin-left:11%;"><b>&minus;&minus;ignoremonitoring</b></p>

<p style="margin-left:22%;">Make no attempt to interact
with dmeventd unless <b>&minus;&minus;monitor</b> is
specified.</p>

<p style="margin-left:11%;"><b>&minus;l</b>,
<b>&minus;&minus;extents</b>
<i>LogicalExtentsNumber</i>[<i>%</i>{<i>VG</i>|<i>PVS</i>|<i>FREE</i>|<i>ORIGIN</i>}]</p>

<p style="margin-left:22%;">Gives the number of logical
extents to allocate for the new logical volume. The total
number of physical extents allocated will be greater than
this, for example, if the volume is mirrored. The number can
also be expressed as a percentage of the total space in the
Volume Group with the suffix <i>%VG</i>, as a percentage of
the remaining free space in the Volume Group with the suffix
<i>%FREE</i>, as a percentage of the remaining free space
for the specified PhysicalVolume(s) with the suffix
<i>%PVS</i>, or (for a snapshot) as a percentage of the
total space in the Origin Logical Volume with the suffix
<i>%ORIGIN</i> (i.e. <i>100%ORIGIN</i> provides space for
the whole origin). When expressed as a percentage, the
number is treated as an approximate upper limit for the
total number of physical extents to be allocated (including
extents used by any mirrors, for example).</p>

<p style="margin-left:11%;"><b>&minus;j</b>,
<b>&minus;&minus;major</b> <i>major</i></p>

<p style="margin-left:22%;">Sets the major number. Major
numbers are not supported with pool volumes. This option is
supported only on older systems (kernel version 2.4) and is
ignored on modern Linux systems where major numbers are
dynamically assigned.</p>


<p style="margin-left:11%;"><b>&minus;&minus;metadataprofile</b>
<i>ProfileName</i></p>

<p style="margin-left:22%;">Uses and attaches the
ProfileName configuration profile to the logical volume
metadata. Whenever the logical volume is processed next
time, the profile is automatically applied. If the volume
group has another profile attached, the logical volume
profile is preferred. See <b>lvm.conf</b>(5) for more
information about <b>metadata profiles</b>.</p>

<p style="margin-left:11%;"><b>&minus;&minus;minor</b>
<i>minor</i></p>

<p style="margin-left:22%;">Sets the minor number. Minor
numbers are not supported with pool volumes.</p>

<p style="margin-left:11%;"><b>&minus;m</b>,
<b>&minus;&minus;mirrors</b> <i>Mirrors</i></p>

<p style="margin-left:22%;">Creates a mirrored logical
volume with <i>Mirrors</i> copies. For example, specifying
<b>&minus;m&nbsp;</b><i>1</i> would result in a mirror with
two-sides; that is, a linear volume plus one copy.</p>

<p style="margin-left:22%; margin-top: 1em">Specifying the
optional argument <b>&minus;&minus;nosync</b> will cause the
creation of the mirror to skip the initial
resynchronization. Any data written afterwards will be
mirrored, but the original contents will not be copied. This
is useful for skipping a potentially long and resource
intensive initial sync of an empty device.</p>

<p style="margin-left:22%; margin-top: 1em">There are two
implementations of mirroring which can be used and
correspond to the &quot;<i>raid1</i>&quot; and
&quot;<i>mirror</i>&quot; segment types. The default is
&quot;<i>raid1</i>&quot;. See the <b>&minus;&minus;type</b>
option for more information if you would like to use the
legacy &quot;<i>mirror</i>&quot; segment type. See
<b>lvm.conf</b>(5) settings
<i>global</i>/<i>mirror_segtype_default</i> and
<i>global</i>/<i>raid10_segtype_default</i> to configure
default mirror segment type. The options
<b>&minus;&minus;mirrorlog</b> and
<b>&minus;&minus;corelog</b> apply to the legacy
&quot;<i>mirror</i>&quot; segment type only.</p>

<p style="margin-left:11%;"><b>&minus;&minus;mirrorlog</b>
{<i>disk</i>|<i>core</i>|<i>mirrored</i>}</p>

<p style="margin-left:22%;">Specifies the type of log to be
used for logical volumes utilizing the legacy
&quot;<i>mirror</i>&quot; segment type. <br>
The default is <i>disk</i>, which is persistent and requires
a small amount of storage space, usually on a separate
device from the data being mirrored. <br>
Using <i>core</i> means the mirror is regenerated by copying
the data from the first device each time the logical volume
is activated, like after every reboot. <br>
Using <i>mirrored</i> will create a persistent log that is
itself mirrored.</p>

<p style="margin-left:11%;"><b>&minus;&minus;monitor</b>
{<i>y</i>|<i>n</i>}</p>

<p style="margin-left:22%;">Starts or avoids monitoring a
mirrored, snapshot or thin pool logical volume with
dmeventd, if it is installed. If a device used by a
monitored mirror reports an I/O error, the failure is
handled according to
<i>activation</i>/<i>mirror_image_fault_policy</i> and
<i>activation</i>/<i>mirror_log_fault_policy</i> set in
<b>lvm.conf</b>(5).</p>

<p style="margin-left:11%;"><b>&minus;n</b>,
<b>&minus;&minus;name</b>
<i>LogicalVolume</i>{<i>Name</i>|<i>Path</i>}</p>

<p style="margin-left:22%;">Sets the name for the new
logical volume. <br>
Without this option a default name of &quot;lvol#&quot; will
be generated where # is the LVM internal number of the
logical volume.</p>


<p style="margin-left:11%;"><b>&minus;&minus;nosync</b></p>

<p style="margin-left:22%;">Causes the creation of the
mirror to skip the initial resynchronization.</p>


<p style="margin-left:11%;"><b>&minus;&minus;noudevsync</b></p>

<p style="margin-left:22%;">Disables udev synchronisation.
The process will not wait for notification from udev. It
will continue irrespective of any possible udev processing
in the background. You should only use this if udev is not
running or has rules that ignore the devices LVM2
creates.</p>

<p style="margin-left:11%;"><b>&minus;p</b>,
<b>&minus;&minus;permission</b> {<i>r</i>|<i>rw</i>}</p>

<p style="margin-left:22%;">Sets access permissions to read
only (<i>r</i>) or read and write (<i>rw</i>). <br>
Default is read and write.</p>

<p style="margin-left:11%;"><b>&minus;M</b>,
<b>&minus;&minus;persistent</b> {<i>y</i>|<i>n</i>}</p>

<p style="margin-left:22%;">Set to <i>y</i> to make the
minor number specified persistent. Pool volumes cannot have
persistent major and minor numbers. Defaults to <i>y</i>es
only when major or minor number is specified. Otherwise it
is <i>n</i>o.</p>


<p style="margin-left:11%;"><b>&minus;&minus;poolmetadatasize</b>
<i>MetadataVolumeSize</i>[<i>bBsSkKmMgG</i>]</p>

<p style="margin-left:22%;">Sets the size of pool&rsquo;s
metadata logical volume. Supported values are in range
between 2MiB and 16GiB for thin pool, and upto 16GiB for
cache pool. The minimum value is computed from pool&rsquo;s
data size. Default value for thin pool is (Pool_LV_size /
Pool_LV_chunk_size * 64b). Default unit is megabytes.</p>


<p style="margin-left:11%;"><b>&minus;&minus;poolmetadataspare</b>
{<i>y</i>|<i>n</i>}</p>

<p style="margin-left:22%;">Controls creation and
maintanence of pool metadata spare logical volume that will
be used for automated pool recovery. Only one such volume is
maintained within a volume group with the size of the
biggest pool metadata volume. Default is <i>y</i>es.</p>


<p style="margin-left:11%;"><b>&minus;&minus;</b>[<b>raid</b>]<b>maxrecoveryrate</b>
<i>Rate</i>[<i>bBsSkKmMgG</i>]</p>

<p style="margin-left:22%;">Sets the maximum recovery rate
for a RAID logical volume. <i>Rate</i> is specified as an
amount per second for each device in the array. If no suffix
is given, then KiB/sec/device is assumed. Setting the
recovery rate to 0 means it will be unbounded.</p>


<p style="margin-left:11%;"><b>&minus;&minus;</b>[<b>raid</b>]<b>minrecoveryrate</b>
<i>Rate</i>[<i>bBsSkKmMgG</i>]</p>

<p style="margin-left:22%;">Sets the minimum recovery rate
for a RAID logical volume. <i>Rate</i> is specified as an
amount per second for each device in the array. If no suffix
is given, then KiB/sec/device is assumed. Setting the
recovery rate to 0 means it will be unbounded.</p>

<p style="margin-left:11%;"><b>&minus;r</b>,
<b>&minus;&minus;readahead</b>
{<i>ReadAheadSectors</i>|<i>auto</i>|<i>none</i>}</p>

<p style="margin-left:22%;">Sets read ahead sector count of
this logical volume. For volume groups with metadata in lvm1
format, this must be a value between 2 and 120. The default
value is <i>auto</i> which allows the kernel to choose a
suitable value automatically. <i>None</i> is equivalent to
specifying zero.</p>

<p style="margin-left:11%;"><b>&minus;R</b>,
<b>&minus;&minus;regionsize</b>
<i>MirrorLogRegionSize</i>[<i>bBsSkKmMgG</i>]</p>

<p style="margin-left:22%;">A mirror is divided into
regions of this size (in MiB), and the mirror log uses this
granularity to track which regions are in sync.</p>

<p style="margin-left:11%;"><b>&minus;k</b>,
<b>&minus;&minus;setactivationskip</b>
{<i>y</i>|<i>n</i>}</p>

<p style="margin-left:22%;">Controls whether Logical
Volumes are persistently flagged to be skipped during
activation. By default, thin snapshot volumes are flagged
for activation skip. See <b>lvm.conf</b>(5)
<i>activation</i>/<i>auto_set_activation_skip</i> how to
change its default behaviour. To activate such volumes, an
extra
<b>&minus;K</b>|<b>&minus;&minus;ignoreactivationskip</b>
option must be used. The flag is not applied during
deactivation. Use <b>lvchange
&minus;&minus;setactivationskip {y|n}</b> command to change
the skip flag for existing volumes. To see whether the flag
is attached, use <b>lvs</b> command where the state of the
flag is reported within <b>lv_attr</b> bits.</p>

<p style="margin-left:11%;"><b>&minus;L</b>,
<b>&minus;&minus;size</b>
<i>LogicalVolumeSize</i>[<i>bBsSkKmMgGtTpPeE</i>]</p>

<p style="margin-left:22%;">Gives the size to allocate for
the new logical volume. A size suffix of <i>B</i> for bytes,
<i>S</i> for sectors as 512 bytes, <i>K</i> for kilobytes,
<i>M</i> for megabytes, <i>G</i> for gigabytes, <i>T</i> for
terabytes, <i>P</i> for petabytes or <i>E</i> for exabytes
is optional. <br>
Default unit is megabytes.</p>

<p style="margin-left:11%;"><b>&minus;s</b>,
<b>&minus;&minus;snapshot</b>
<i>OriginalLogicalVolume</i>{<i>Name</i>|<i>Path</i>}</p>

<p style="margin-left:22%;">Creates a snapshot logical
volume (or snapshot) for an existing, so called original
logical volume (or origin). Snapshots provide a
&rsquo;frozen image&rsquo; of the contents of the origin
while the origin can still be updated. They enable
consistent backups and online recovery of
removed/overwritten data/files. <br>
Thin snapshot is created when the origin is a thin volume
and the size IS NOT specified. Thin snapshot shares same
blocks within the thin pool volume. The non thin volume
snapshot with the specified size does not need the same
amount of storage the origin has. In a typical scenario,
15-20% might be enough. In case the snapshot runs out of
storage, use <b>lvextend</b>(8) to grow it. Shrinking a
snapshot is supported by <b>lvreduce</b>(8) as well. Run
<b>lvs</b>(8) on the snapshot in order to check how much
data is allocated to it. Note: a small amount of the space
you allocate to the snapshot is used to track the locations
of the chunks of data, so you should allocate slightly more
space than you actually need and monitor
(<b>&minus;&minus;monitor</b>) the rate at which the
snapshot data is growing so you can <b>avoid</b> running out
of space. If <b>&minus;&minus;thinpool</b> is specified,
thin volume is created that will use given original logical
volume as an external origin that serves unprovisioned
blocks. Only read-only volumes can be used as external
origins. To make the volume external origin, lvm expects the
volume to be inactive. External origin volume can be
used/shared for many thin volumes even from different thin
pools. See <b>lvconvert</b>(8) for online conversion to thin
volumes with external origin.</p>

<p style="margin-left:11%;"><b>&minus;i</b>,
<b>&minus;&minus;stripes</b> <i>Stripes</i></p>

<p style="margin-left:22%;">Gives the number of stripes.
This is equal to the number of physical volumes to scatter
the logical volume. When creating a RAID 4/5/6 logical
volume, the extra devices which are necessary for parity are
internally accounted for. Specifying <b>&minus;i</b><i>3</i>
would use 3 devices for striped logical volumes, 4 devices
for RAID 4/5, and 5 devices for RAID 6. Alternatively, RAID
4/5/6 will stripe across all PVs in the volume group or all
of the PVs specified if the <b>&minus;i</b> argument is
omitted.</p>

<p style="margin-left:11%;"><b>&minus;I</b>,
<b>&minus;&minus;stripesize</b> <i>StripeSize</i></p>

<p style="margin-left:22%;">Gives the number of kilobytes
for the granularity of the stripes. <br>
StripeSize must be 2^n (n = 2 to 9) for metadata in LVM1
format. For metadata in LVM2 format, the stripe size may be
a larger power of 2 but must not exceed the physical extent
size.</p>

<p style="margin-left:11%;"><b>&minus;T</b>,
<b>&minus;&minus;thin</b></p>

<p style="margin-left:22%;">Creates thin pool or thin
logical volume or both. Specifying the optional argument
<b>&minus;&minus;size</b> or <b>&minus;&minus;extents</b>
will cause the creation of the thin pool logical volume.
Specifying the optional argument
<b>&minus;&minus;virtualsize</b> will cause the creation of
the thin logical volume from given thin pool volume.
Specifying both arguments will cause the creation of both
thin pool and thin volume using this pool. See
<b>lvmthin</b>(7) for more info about thin provisioning
support. Thin provisioning requires device mapper kernel
driver from kernel 3.2 or greater.</p>

<p style="margin-left:11%;"><b>&minus;&minus;thinpool</b>
<i>ThinPoolLogicalVolume</i>{<i>Name</i>|<i>Path</i>}</p>

<p style="margin-left:22%;">Specifies the name of thin pool
volume name. The other way to specify pool name is to append
name to Volume group name argument.</p>

<p style="margin-left:11%;"><b>&minus;&minus;type</b>
<i>SegmentType</i></p>

<p style="margin-left:22%;">Creates a logical volume with
the specified segment type. Supported types are:
<i>cache</i>, <i>cache-pool</i>, <i>error</i>,
<i>linear</i>, <i>mirror, raid1</i>, <i>raid4</i>,
<i>raid5_la</i>, <i>raid5_ls</i> (= <i>raid5</i>),
<i>raid5_ra</i>, <i>raid5_rs</i>, <i>raid6_nc</i>,
<i>raid6_nr</i>, <i>raid6_zr</i> (= <i>raid6</i>)<i>,
raid10</i>, <i>snapshot</i>, <i>striped, thin</i>,
<i>thin-pool</i> or <i>zero</i>. Segment type may have a
commandline switch alias that will enable its use. When the
type is not explicitly specified an implicit type is
selected from combination of options:
<b>&minus;H</b>|<b>&minus;&minus;cache</b>|<b>&minus;&minus;cachepool</b>
(<i>cache</i> or <i>cachepool</i>),
<b>&minus;T</b>|<b>&minus;&minus;thin</b>|<b>&minus;&minus;thinpool</b>
(<i>thin</i> or <i>thinpool</i>),
<b>&minus;m</b>|<b>&minus;&minus;mirrors</b> (<i>raid1</i>
or <i>mirror</i>),
<b>&minus;s</b>|<b>&minus;&minus;snapshot</b>|<b>&minus;V</b>|<b>&minus;&minus;virtualsize</b>
(<i>snapshot</i> or <i>thin</i>),
<b>&minus;i</b>|<b>&minus;&minus;stripes</b>
(<i>striped</i>). Default type is <i>linear</i>.</p>

<p style="margin-left:11%;"><b>&minus;V</b>,
<b>&minus;&minus;virtualsize</b>
<i>VirtualSize</i>[<i>bBsSkKmMgGtTpPeE</i>]</p>

<p style="margin-left:22%;">Creates a thinly provisioned
device or a sparse device of the given size (in MiB by
default). See <b>lvm.conf</b>(5) settings
<i>global</i>/<i>sparse_segtype_default</i> to configure
default sparse segment type. See <b>lvmthin</b>(7) for more
info about thin provisioning support. Anything written to a
sparse snapshot will be returned when reading from it.
Reading from other areas of the device will return blocks of
zeros. Virtual snapshot is implemented by creating a hidden
virtual device of the requested size using the zero target.
A suffix of _vorigin is used for this device. Note: using
sparse snapshots is not efficient for larger device sizes
(GiB), thin provisioning should be used for this case.</p>

<p style="margin-left:11%;"><b>&minus;W</b>,
<b>&minus;&minus;wipesignatures</b> {<i>y</i>|<i>n</i>}</p>

<p style="margin-left:22%;">Controls wiping of detected
signatures on newly created Logical Volume. If this option
is not specified, then by default signature wiping is done
each time the zeroing
(<b>&minus;Z</b>/<b>&minus;&minus;zero</b>) is done. This
default behaviour can be controlled by
<i>allocation</i>/<i>wipe_signatures_when_zeroing_new_lvs</i>
setting found in <b>lvm.conf</b>(5). <br>
If blkid wiping is used
<i>allocation</i>/<i>use_blkid_wiping</i> setting in
<b>lvm.conf</b>(5)) and LVM2 is compiled with blkid wiping
support, then <b>blkid</b>(8) library is used to detect the
signatures (use <b>blkid -k</b> command to list the
signatures that are recognized). Otherwise, native LVM2 code
is used to detect signatures (MD RAID, swap and LUKS
signatures are detected only in this case). <br>
Logical volume is not wiped if the read only flag is
set.</p>

<p style="margin-left:11%;"><b>&minus;Z</b>,
<b>&minus;&minus;zero</b> {<i>y</i>|<i>n</i>}</p>

<p style="margin-left:22%;">Controls zeroing of the first
4KiB of data in the new logical volume. Default is
<i>y</i>es. Snapshot COW volumes are always zeroed. Logical
volume is not zeroed if the read only flag is set.</p>

<p style="margin-left:22%; margin-top: 1em">Warning: trying
to mount an unzeroed logical volume can cause the system to
hang.</p>

<h2>Examples
<a name="Examples"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Creates a
striped logical volume with 3 stripes, a stripe size of 8KiB
and a size of 100MiB in the volume group named vg00. The
logical volume name will be chosen by lvcreate:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;i 3 &minus;I 8 &minus;L 100M vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
mirror logical volume with 2 sides with a useable size of
500 MiB. This operation would require 3 devices (or option
<b>&minus;&minus;alloc&nbsp;</b><i>anywhere</i> ) - two for
the mirror devices and one for the disk log:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;m1 &minus;L 500M vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
mirror logical volume with 2 sides with a useable size of
500 MiB. This operation would require 2 devices - the log is
&quot;in-memory&quot;:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;m1 &minus;&minus;mirrorlog core &minus;L 500M
vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
snapshot logical volume named &quot;vg00/snap&quot; which
has access to the contents of the original logical volume
named &quot;vg00/lvol1&quot; at snapshot logical volume
creation time. If the original logical volume contains a
file system, you can mount the snapshot logical volume on an
arbitrary directory in order to access the contents of the
filesystem to run a backup while the original filesystem
continues to get updated:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;size 100m &minus;&minus;snapshot
&minus;&minus;name snap /dev/vg00/lvol1</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
snapshot logical volume named &quot;vg00/snap&quot; with
size for overwriting 20% of the original logical volume
named &quot;vg00/lvol1&quot;.:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;s &minus;l 20%ORIGIN &minus;&minus;name snap
vg00/lvol1</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
sparse device named /dev/vg1/sparse of size 1TiB with space
for just under 100MiB of actual data on it:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;virtualsize 1T &minus;&minus;size 100M
&minus;&minus;snapshot &minus;&minus;name sparse vg1</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
linear logical volume &quot;vg00/lvol1&quot; using physical
extents /dev/sda:0&minus;7 and /dev/sdb:0&minus;7 for
allocation of extents:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;L 64M &minus;n lvol1 vg00 /dev/sda:0&minus;7
/dev/sdb:0&minus;7</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a 5GiB
RAID5 logical volume &quot;vg00/my_lv&quot;, with 3 stripes
(plus a parity drive for a total of 4 devices) and a
stripesize of 64KiB:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;type raid5 &minus;L 5G &minus;i 3 &minus;I 64
&minus;n my_lv vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a RAID5
logical volume &quot;vg00/my_lv&quot;, using all of the free
space in the VG and spanning all the PVs in the VG:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;type raid5 &minus;l 100%FREE &minus;n my_lv
vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a 5GiB
RAID10 logical volume &quot;vg00/my_lv&quot;, with 2 stripes
on 2 2-way mirrors. Note that the <b>-i</b> and <b>-m</b>
arguments behave differently. The <b>-i</b> specifies the
number of stripes. The <b>-m</b> specifies the number of
<b>additional</b> copies:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;type raid10 &minus;L 5G &minus;i 2 &minus;m 1
&minus;n my_lv vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates 100MiB
pool logical volume for thin provisioning build with 2
stripes 64KiB and chunk size 256KiB together with 1TiB thin
provisioned logical volume &quot;vg00/thin_lv&quot;:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;i 2 &minus;I 64 &minus;c 256 &minus;L100M &minus;T
vg00/pool &minus;V 1T &minus;&minus;name thin_lv</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a thin
snapshot volume &quot;thinsnap&quot; of thin volume
&quot;thinvol&quot; that will share the same blocks within
the thin pool. Note: the size MUST NOT be specified,
otherwise the non-thin snapshot is created instead:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;s vg00/thinvol &minus;&minus;name thinsnap</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a thin
snapshot volume of read-only inactive volume
&quot;origin&quot; which then becomes the thin external
origin for the thin snapshot volume in vg00 that will use an
existing thin pool &quot;vg00/pool&quot;:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;s &minus;&minus;thinpool vg00/pool origin</b></p>

<p style="margin-left:11%; margin-top: 1em">Create a cache
pool LV that can later be used to cache one logical
volume.</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;type cache-pool &minus;L 1G &minus;n
my_lv_cachepool vg /dev/fast1</b></p>

<p style="margin-left:11%; margin-top: 1em">If there is an
existing cache pool LV, create the large slow device (i.e.
the origin LV) and link it to the supplied cache pool LV,
creating a cache LV.</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;cache &minus;L 100G &minus;n my_lv
vg/my_lv_cachepool /dev/slow1</b></p>

<p style="margin-left:11%; margin-top: 1em">If there is an
existing logical volume, create the small and fast cache
pool LV and link it to the supplied existing logical volume
(i.e. the origin LV), creating a cache LV.</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;type cache &minus;L 1G &minus;n
my_lv_cachepool vg/my_lv /dev/fast1</b></p>

<h2>SEE ALSO
<a name="SEE ALSO"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><b>lvm</b>(8),
<b>lvm.conf</b>(5), <b>lvmcache</b>(7), <b>lvmthin</b>(7),
<b>lvconvert</b>(8), <b>lvchange</b>(8), <b>lvextend</b>(8),
<b>lvreduce</b>(8), <b>lvremove</b>(8), <b>lvrename</b>(8)
<b>lvs</b>(8), <b>lvscan</b>(8), <b>vgcreate</b>(8),
<b>blkid</b>(8)</p>
<hr>
</body>
</html>

<!-- Creator     : groff version 1.22.2 -->
<!-- CreationDate: Sat Nov 12 01:33:06 2016 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title>bzip2</title>

</head>
<body>

<h1 align="center">bzip2</h1>

<a href="#NAME">NAME</a><br>
<a href="#SYNOPSIS">SYNOPSIS</a><br>
<a href="#DESCRIPTION">DESCRIPTION</a><br>
<a href="#OPTIONS">OPTIONS</a><br>
<a href="#MEMORY MANAGEMENT">MEMORY MANAGEMENT</a><br>
<a href="#RECOVERING DATA FROM DAMAGED FILES">RECOVERING DATA FROM DAMAGED FILES</a><br>
<a href="#PERFORMANCE NOTES">PERFORMANCE NOTES</a><br>
<a href="#CAVEATS">CAVEATS</a><br>
<a href="#AUTHOR">AUTHOR</a><br>

<hr>


<h2>NAME
<a name="NAME"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">bzip2, bunzip2
&minus; a block-sorting file compressor, v1.0.6 <br>
bzcat &minus; decompresses files to stdout <br>
bzip2recover &minus; recovers data from damaged bzip2
files</p>

<h2>SYNOPSIS
<a name="SYNOPSIS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><b>bzip2</b> [
<b>&minus;cdfkqstvzVL123456789</b> ] [ <i>filenames ...</i>
] <b><br>
bunzip2</b> [ <b>&minus;fkvsVL</b> ] [ <i>filenames ...</i>
] <b><br>
bzcat</b> [ <b>&minus;s</b> ] [ <i>filenames ...</i> ]
<b><br>
bzip2recover</b> <i>filename</i></p>

<h2>DESCRIPTION
<a name="DESCRIPTION"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><i>bzip2</i>
compresses files using the Burrows-Wheeler block sorting
text compression algorithm, and Huffman coding. Compression
is generally considerably better than that achieved by more
conventional LZ77/LZ78-based compressors, and approaches the
performance of the PPM family of statistical
compressors.</p>

<p style="margin-left:11%; margin-top: 1em">The
command-line options are deliberately very similar to those
of <i>GNU gzip,</i> but they are not identical.</p>

<p style="margin-left:11%; margin-top: 1em"><i>bzip2</i>
expects a list of file names to accompany the command-line
flags. Each file is replaced by a compressed version of
itself, with the name &quot;original_name.bz2&quot;. Each
compressed file has the same modification date, permissions,
and, when possible, ownership as the corresponding original,
so that these properties can be correctly restored at
decompression time. File name handling is naive in the sense
that there is no mechanism for preserving original file
names, permissions, ownerships or dates in filesystems which
lack these concepts, or have serious file name length
restrictions, such as MS-DOS.</p>

<p style="margin-left:11%; margin-top: 1em"><i>bzip2</i>
and <i>bunzip2</i> will by default not overwrite existing
files. If you want this to happen, specify the &minus;f
flag.</p>

<p style="margin-left:11%; margin-top: 1em">If no file
names are specified, <i>bzip2</i> compresses from standard
input to standard output. In this case, <i>bzip2</i> will
decline to write compressed output to a terminal, as this
would be entirely incomprehensible and therefore
pointless.</p>

<p style="margin-left:11%; margin-top: 1em"><i>bunzip2</i>
(or <i>bzip2 &minus;d)</i> decompresses all specified files.
Files which were not created by <i>bzip2</i> will be
detected and ignored, and a warning issued. <i>bzip2</i>
attempts to guess the filename for the decompressed file
from that of the compressed file as follows:</p>

<p style="margin-left:11%; margin-top: 1em">filename.bz2
becomes filename <br>
filename.bz becomes filename <br>
filename.tbz2 becomes filename.tar <br>
filename.tbz becomes filename.tar <br>
anyothername becomes anyothername.out</p>

<p style="margin-left:11%; margin-top: 1em">If the file
does not end in one of the recognised endings, <i>.bz2, .bz,
.tbz2</i> or <i>.tbz, bzip2</i> complains that it cannot
guess the name of the original file, and uses the original
name with <i>.out</i> appended.</p>

<p style="margin-left:11%; margin-top: 1em">As with
compression, supplying no filenames causes decompression
from standard input to standard output.</p>

<p style="margin-left:11%; margin-top: 1em"><i>bunzip2</i>
will correctly decompress a file which is the concatenation
of two or more compressed files. The result is the
concatenation of the corresponding uncompressed files.
Integrity testing (&minus;t) of concatenated compressed
files is also supported.</p>

<p style="margin-left:11%; margin-top: 1em">You can also
compress or decompress files to the standard output by
giving the &minus;c flag. Multiple files may be compressed
and decompressed like this. The resulting outputs are fed
sequentially to stdout. Compression of multiple files in
this manner generates a stream containing multiple
compressed file representations. Such a stream can be
decompressed correctly only by <i>bzip2</i> version 0.9.0 or
later. Earlier versions of <i>bzip2</i> will stop after
decompressing the first file in the stream.</p>

<p style="margin-left:11%; margin-top: 1em"><i>bzcat</i>
(or <i>bzip2 -dc)</i> decompresses all specified files to
the standard output.</p>

<p style="margin-left:11%; margin-top: 1em"><i>bzip2</i>
will read arguments from the environment variables
<i>BZIP2</i> and <i>BZIP,</i> in that order, and will
process them before any arguments read from the command
line. This gives a convenient way to supply default
arguments.</p>

<p style="margin-left:11%; margin-top: 1em">Compression is
always performed, even if the compressed file is slightly
larger than the original. Files of less than about one
hundred bytes tend to get larger, since the compression
mechanism has a constant overhead in the region of 50 bytes.
Random data (including the output of most file compressors)
is coded at about 8.05 bits per byte, giving an expansion of
around 0.5%.</p>

<p style="margin-left:11%; margin-top: 1em">As a self-check
for your protection, <i>bzip2</i> uses 32-bit CRCs to make
sure that the decompressed version of a file is identical to
the original. This guards against corruption of the
compressed data, and against undetected bugs in <i>bzip2</i>
(hopefully very unlikely). The chances of data corruption
going undetected is microscopic, about one chance in four
billion for each file processed. Be aware, though, that the
check occurs upon decompression, so it can only tell you
that something is wrong. It can&rsquo;t help you recover the
original uncompressed data. You can use <i>bzip2recover</i>
to try to recover data from damaged files.</p>

<p style="margin-left:11%; margin-top: 1em">Return values:
0 for a normal exit, 1 for environmental problems (file not
found, invalid flags, I/O errors, &amp;c), 2 to indicate a
corrupt compressed file, 3 for an internal consistency error
(eg, bug) which caused <i>bzip2</i> to panic.</p>

<h2>OPTIONS
<a name="OPTIONS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><b>&minus;c
--stdout</b></p>

<p style="margin-left:22%;">Compress or decompress to
standard output.</p>

<p style="margin-left:11%;"><b>&minus;d
--decompress</b></p>

<p style="margin-left:22%;">Force decompression. <i>bzip2,
bunzip2</i> and <i>bzcat</i> are really the same program,
and the decision about what actions to take is done on the
basis of which name is used. This flag overrides that
mechanism, and forces <i>bzip2</i> to decompress.</p>

<p style="margin-left:11%;"><b>&minus;z --compress</b></p>

<p style="margin-left:22%;">The complement to &minus;d:
forces compression, regardless of the invocation name.</p>

<p style="margin-left:11%;"><b>&minus;t --test</b></p>

<p style="margin-left:22%;">Check integrity of the
specified file(s), but don&rsquo;t decompress them. This
really performs a trial decompression and throws away the
result.</p>

<p style="margin-left:11%;"><b>&minus;f --force</b></p>

<p style="margin-left:22%;">Force overwrite of output
files. Normally, <i>bzip2</i> will not overwrite existing
output files. Also forces <i>bzip2</i> to break hard links
to files, which it otherwise wouldn&rsquo;t do.</p>

<p style="margin-left:22%; margin-top: 1em">bzip2 normally
declines to decompress files which don&rsquo;t have the
correct magic header bytes. If forced (-f), however, it will
pass such files through unmodified. This is how GNU gzip
behaves.</p>

<p style="margin-left:11%;"><b>&minus;k --keep</b></p>

<p style="margin-left:22%;">Keep (don&rsquo;t delete) input
files during compression or decompression.</p>

<p style="margin-left:11%;"><b>&minus;s --small</b></p>

<p style="margin-left:22%;">Reduce memory usage, for
compression, decompression and testing. Files are
decompressed and tested using a modified algorithm which
only requires 2.5 bytes per block byte. This means any file
can be decompressed in 2300k of memory, albeit at about half
the normal speed.</p>

<p style="margin-left:22%; margin-top: 1em">During
compression, &minus;s selects a block size of 200k, which
limits memory use to around the same figure, at the expense
of your compression ratio. In short, if your machine is low
on memory (8 megabytes or less), use &minus;s for
everything. See MEMORY MANAGEMENT below.</p>

<p style="margin-left:11%;"><b>&minus;q --quiet</b></p>

<p style="margin-left:22%;">Suppress non-essential warning
messages. Messages pertaining to I/O errors and other
critical events will not be suppressed.</p>

<p style="margin-left:11%;"><b>&minus;v --verbose</b></p>

<p style="margin-left:22%;">Verbose mode -- show the
compression ratio for each file processed. Further
&minus;v&rsquo;s increase the verbosity level, spewing out
lots of information which is primarily of interest for
diagnostic purposes.</p>

<p style="margin-left:11%;"><b>&minus;L --license -V
--version</b></p>

<p style="margin-left:22%;">Display the software version,
license terms and conditions.</p>

<p style="margin-left:11%;"><b>&minus;1 (or
&minus;&minus;fast) to &minus;9 (or
&minus;&minus;best)</b></p>

<p style="margin-left:22%;">Set the block size to 100 k,
200 k .. 900 k when compressing. Has no effect when
decompressing. See MEMORY MANAGEMENT below. The
&minus;&minus;fast and &minus;&minus;best aliases are
primarily for GNU gzip compatibility. In particular,
&minus;&minus;fast doesn&rsquo;t make things significantly
faster. And &minus;&minus;best merely selects the default
behaviour.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="3%">


<p><b>&minus;-</b></p></td>
<td width="8%"></td>
<td width="78%">


<p>Treats all subsequent arguments as file names, even if
they start with a dash. This is so you can handle files with
names beginning with a dash, for example: bzip2 &minus;-
&minus;myfilename.</p> </td></tr>
</table>

<p style="margin-left:11%;"><b>&minus;-repetitive-fast
--repetitive-best</b></p>

<p style="margin-left:22%;">These flags are redundant in
versions 0.9.5 and above. They provided some coarse control
over the behaviour of the sorting algorithm in earlier
versions, which was sometimes useful. 0.9.5 and above have
an improved algorithm which renders these flags
irrelevant.</p>

<h2>MEMORY MANAGEMENT
<a name="MEMORY MANAGEMENT"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><i>bzip2</i>
compresses large files in blocks. The block size affects
both the compression ratio achieved, and the amount of
memory needed for compression and decompression. The flags
&minus;1 through &minus;9 specify the block size to be
100,000 bytes through 900,000 bytes (the default)
respectively. At decompression time, the block size used for
compression is read from the header of the compressed file,
and <i>bunzip2</i> then allocates itself just enough memory
to decompress the file. Since block sizes are stored in
compressed files, it follows that the flags &minus;1 to
&minus;9 are irrelevant to and so ignored during
decompression.</p>

<p style="margin-left:11%; margin-top: 1em">Compression and
decompression requirements, in bytes, can be estimated
as:</p>

<p style="margin-left:11%; margin-top: 1em">Compression:
400k + ( 8 x block size )</p>

<p style="margin-left:11%; margin-top: 1em">Decompression:
100k + ( 4 x block size ), or <br>
100k + ( 2.5 x block size )</p>

<p style="margin-left:11%; margin-top: 1em">Larger block
sizes give rapidly diminishing marginal returns. Most of the
compression comes from the first two or three hundred k of
block size, a fact worth bearing in mind when using
<i>bzip2</i> on small machines. It is also important to
appreciate that the decompression memory requirement is set
at compression time by the choice of block size.</p>

<p style="margin-left:11%; margin-top: 1em">For files
compressed with the default 900k block size, <i>bunzip2</i>
will require about 3700 kbytes to decompress. To support
decompression of any file on a 4 megabyte machine,
<i>bunzip2</i> has an option to decompress using
approximately half this amount of memory, about 2300 kbytes.
Decompression speed is also halved, so you should use this
option only where necessary. The relevant flag is -s.</p>

<p style="margin-left:11%; margin-top: 1em">In general, try
and use the largest block size memory constraints allow,
since that maximises the compression achieved. Compression
and decompression speed are virtually unaffected by block
size.</p>

<p style="margin-left:11%; margin-top: 1em">Another
significant point applies to files which fit in a single
block -- that means most files you&rsquo;d encounter using a
large block size. The amount of real memory touched is
proportional to the size of the file, since the file is
smaller than a block. For example, compressing a file 20,000
bytes long with the flag -9 will cause the compressor to
allocate around 7600k of memory, but only touch 400k + 20000
* 8 = 560 kbytes of it. Similarly, the decompressor will
allocate 3700k but only touch 100k + 20000 * 4 = 180
kbytes.</p>

<p style="margin-left:11%; margin-top: 1em">Here is a table
which summarises the maximum memory usage for different
block sizes. Also recorded is the total compressed size for
14 files of the Calgary Text Compression Corpus totalling
3,141,622 bytes. This column gives some feel for how
compression varies with block size. These figures tend to
understate the advantage of larger block sizes for larger
files, since the Corpus is dominated by smaller files.</p>

<p style="margin-left:11%; margin-top: 1em">Compress
Decompress Decompress Corpus <br>
Flag usage usage -s usage Size</p>

<p style="margin-left:11%; margin-top: 1em">-1 1200k 500k
350k 914704 <br>
-2 2000k 900k 600k 877703 <br>
-3 2800k 1300k 850k 860338 <br>
-4 3600k 1700k 1100k 846899 <br>
-5 4400k 2100k 1350k 845160 <br>
-6 5200k 2500k 1600k 838626 <br>
-7 6100k 2900k 1850k 834096 <br>
-8 6800k 3300k 2100k 828642 <br>
-9 7600k 3700k 2350k 828642</p>

<h2>RECOVERING DATA FROM DAMAGED FILES
<a name="RECOVERING DATA FROM DAMAGED FILES"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><i>bzip2</i>
compresses files in blocks, usually 900kbytes long. Each
block is handled independently. If a media or transmission
error causes a multi-block .bz2 file to become damaged, it
may be possible to recover data from the undamaged blocks in
the file.</p>

<p style="margin-left:11%; margin-top: 1em">The compressed
representation of each block is delimited by a 48-bit
pattern, which makes it possible to find the block
boundaries with reasonable certainty. Each block also
carries its own 32-bit CRC, so damaged blocks can be
distinguished from undamaged ones.</p>


<p style="margin-left:11%; margin-top: 1em"><i>bzip2recover</i>
is a simple program whose purpose is to search for blocks in
.bz2 files, and write each block out into its own .bz2 file.
You can then use <i>bzip2</i> &minus;t to test the integrity
of the resulting files, and decompress those which are
undamaged.</p>


<p style="margin-left:11%; margin-top: 1em"><i>bzip2recover</i>
takes a single argument, the name of the damaged file, and
writes a number of files &quot;rec00001file.bz2&quot;,
&quot;rec00002file.bz2&quot;, etc, containing the extracted
blocks. The output filenames are designed so that the use of
wildcards in subsequent processing -- for example,
&quot;bzip2 -dc rec*file.bz2 &gt; recovered_data&quot; --
processes the files in the correct order.</p>


<p style="margin-left:11%; margin-top: 1em"><i>bzip2recover</i>
should be of most use dealing with large .bz2 files, as
these will contain many blocks. It is clearly futile to use
it on damaged single-block files, since a damaged block
cannot be recovered. If you wish to minimise any potential
data loss through media or transmission errors, you might
consider compressing with a smaller block size.</p>

<h2>PERFORMANCE NOTES
<a name="PERFORMANCE NOTES"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">The sorting
phase of compression gathers together similar strings in the
file. Because of this, files containing very long runs of
repeated symbols, like &quot;aabaabaabaab ...&quot;
(repeated several hundred times) may compress more slowly
than normal. Versions 0.9.5 and above fare much better than
previous versions in this respect. The ratio between
worst-case and average-case compression time is in the
region of 10:1. For previous versions, this figure was more
like 100:1. You can use the &minus;vvvv option to monitor
progress in great detail, if you want.</p>

<p style="margin-left:11%; margin-top: 1em">Decompression
speed is unaffected by these phenomena.</p>

<p style="margin-left:11%; margin-top: 1em"><i>bzip2</i>
usually allocates several megabytes of memory to operate in,
and then charges all over it in a fairly random fashion.
This means that performance, both for compressing and
decompressing, is largely determined by the speed at which
your machine can service cache misses. Because of this,
small changes to the code to reduce the miss rate have been
observed to give disproportionately large performance
improvements. I imagine <i>bzip2</i> will perform best on
machines with very large caches.</p>

<h2>CAVEATS
<a name="CAVEATS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">I/O error
messages are not as helpful as they could be. <i>bzip2</i>
tries hard to detect I/O errors and exit cleanly, but the
details of what the problem is sometimes seem rather
misleading.</p>

<p style="margin-left:11%; margin-top: 1em">This manual
page pertains to version 1.0.6 of <i>bzip2.</i> Compressed
data created by this version is entirely forwards and
backwards compatible with the previous public releases,
versions 0.1pl2, 0.9.0, 0.9.5, 1.0.0, 1.0.1, 1.0.2 and
above, but with the following exception: 0.9.0 and above can
correctly decompress multiple concatenated compressed files.
0.1pl2 cannot do this; it will stop after decompressing just
the first file in the stream.</p>


<p style="margin-left:11%; margin-top: 1em"><i>bzip2recover</i>
versions prior to 1.0.2 used 32-bit integers to represent
bit positions in compressed files, so they could not handle
compressed files more than 512 megabytes long. Versions
1.0.2 and above use 64-bit ints on some platforms which
support them (GNU supported targets, and Windows). To
establish whether or not bzip2recover was built with such a
limitation, run it without arguments. In any event you can
build yourself an unlimited version if you can recompile it
with MaybeUInt64 set to be an unsigned 64-bit integer.</p>

<h2>AUTHOR
<a name="AUTHOR"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Julian Seward,
jsewardbzip.org.</p>


<p style="margin-left:11%; margin-top: 1em">http://www.bzip.org</p>

<p style="margin-left:11%; margin-top: 1em">The ideas
embodied in <i>bzip2</i> are due to (at least) the following
people: Michael Burrows and David Wheeler (for the block
sorting transformation), David Wheeler (again, for the
Huffman coder), Peter Fenwick (for the structured coding
model in the original <i>bzip,</i> and many refinements),
and Alistair Moffat, Radford Neal and Ian Witten (for the
arithmetic coder in the original <i>bzip).</i> I am much
indebted for their help, support and advice. See the manual
in the source distribution for pointers to sources of
documentation. Christian von Roques encouraged me to look
for faster sorting algorithms, so as to speed up
compression. Bela Lubkin encouraged me to improve the
worst-case compression performance. Donna Robinson XMLised
the documentation. The bz* scripts are derived from those of
GNU gzip. Many people sent patches, helped with portability
problems, lent machines, gave advice and were generally
helpful.</p>
<hr>
</body>
</html>

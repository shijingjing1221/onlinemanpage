<!-- Creator     : groff version 1.22.2 -->
<!-- CreationDate: Fri Nov 11 21:54:01 2016 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title>LVCREATE</title>

</head>
<body>

<h1 align="center">LVCREATE</h1>

<a href="#NAME">NAME</a><br>
<a href="#SYNOPSIS">SYNOPSIS</a><br>
<a href="#DESCRIPTION">DESCRIPTION</a><br>
<a href="#OPTIONS">OPTIONS</a><br>
<a href="#Examples">Examples</a><br>
<a href="#SEE ALSO">SEE ALSO</a><br>

<hr>


<h2>NAME
<a name="NAME"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">lvcreate
&minus; create a logical volume in an existing volume
group</p>

<h2>SYNOPSIS
<a name="SYNOPSIS"></a>
</h2>



<p style="margin-left:11%; margin-top: 1em"><b>lvcreate</b>
[<b>&minus;a</b>|<b>&minus;&minus;activate</b>
[<b>a</b>][<b>e</b>|<b>l</b>|<b>s</b>]{<b>y</b>|<b>n</b>}]
[<b>&minus;&minus;addtag</b> <i>Tag</i>]
[<b>&minus;&minus;alloc</b> <i>AllocationPolicy</i>]
[<b>&minus;A</b>|<b>&minus;&minus;autobackup</b>
{<b>y</b>|<b>n</b>}]
[<b>&minus;H</b>|<b>&minus;&minus;cache</b>]
[<b>&minus;&minus;cachemode</b>
{<b>passthrough</b>|<b>writeback</b>|<b>writethrough</b>}]
[<b>&minus;&minus;cachepolicy</b> <i>Policy</i>]
[<b>&minus;&minus;cachepool</b>
<i>CachePoolLogicalVolume</i>]
[<b>&minus;&minus;cachesettings</b>
<i>Key</i><b>=</b><i>Value</i>]
[<b>&minus;c</b>|<b>&minus;&minus;chunksize</b>
<i>ChunkSize</i>] [<b>&minus;&minus;commandprofile</b>
<i>ProfileName</i>]
[<b>&minus;C</b>|<b>&minus;&minus;contiguous</b>
{<b>y</b>|<b>n</b>}]
[<b>&minus;d</b>|<b>&minus;&minus;debug</b>]
[<b>&minus;&minus;discards</b>
{<b>ignore</b>|<b>nopassdown</b>|<b>passdown</b>}]
[<b>&minus;&minus;errorwhenfull</b> {<b>y</b>|<b>n</b>}]
[{<b>&minus;l</b>|<b>&minus;&minus;extents</b>
<i>LogicalExtentsNumber</i>[<b>%</b>{<b>FREE</b>|<b>PVS</b>|<b>VG</b>}]
| <b>&minus;L</b>|<b>&minus;&minus;size</b>
<i>LogicalVolumeSize</i>}
[<b>&minus;i</b>|<b>&minus;&minus;stripes</b> <i>Stripes</i>
[<b>&minus;I</b>|<b>&minus;&minus;stripesize</b>
<i>StripeSize</i>]]]
[<b>&minus;h</b>|<b>&minus;?</b>|<b>&minus;&minus;help</b>]
[<b>&minus;K</b>|<b>&minus;&minus;ignoreactivationskip</b>]
[<b>&minus;&minus;ignoremonitoring</b>]
[<b>&minus;&minus;minor</b> <i>Minor</i>
[<b>&minus;j</b>|<b>&minus;&minus;major</b> <i>Major</i>]]
[<b>&minus;&minus;metadataprofile</b> <i>ProfileName</i>]
[<b>&minus;m</b>|<b>&minus;&minus;mirrors</b> <i>Mirrors</i>
[<b>&minus;&minus;corelog</b>|<b>&minus;&minus;mirrorlog</b>
{<b>disk</b>|<b>core</b>|<b>mirrored</b>}]
[<b>&minus;&minus;nosync</b>]
[<b>&minus;R</b>|<b>&minus;&minus;regionsize</b>
<i>MirrorLogRegionSize</i>]] [<b>&minus;&minus;monitor</b>
{<b>y</b>|<b>n</b>}]
[<b>&minus;n</b>|<b>&minus;&minus;name</b>
<i>LogicalVolume</i>] [<b>&minus;&minus;noudevsync</b>]
[<b>&minus;p</b>|<b>&minus;&minus;permission</b>
{<b>r</b>|<b>rw</b>}]
[<b>&minus;M</b>|<b>&minus;&minus;persistent</b>
{<b>y</b>|<b>n</b>}] [<b>&minus;&minus;poolmetadatasize</b>
<i>MetadataVolumeSize</i>]
[<b>&minus;&minus;poolmetadataspare</b> {<b>y</b>|<b>n</b>}]
[<b>&minus;&minus;</b>[<b>raid</b>]<b>maxrecoveryrate</b>
<i>Rate</i>]
[<b>&minus;&minus;</b>[<b>raid</b>]<b>minrecoveryrate</b>
<i>Rate</i>] [<b>&minus;r</b>|<b>&minus;&minus;readahead</b>
{<i>ReadAheadSectors</i>|<b>auto</b>|<b>none</b>}]
[<b>&minus;&minus;reportformat</b> {basic<b>|</b>json}]
[<b>&minus;k</b>|<b>&minus;&minus;setactivationskip</b>
{<b>y</b>|<b>n</b>}]
[<b>&minus;s</b>|<b>&minus;&minus;snapshot</b>]
[<b>&minus;V</b>|<b>&minus;&minus;virtualsize</b>
<i>VirtualSize</i>]
[<b>&minus;t</b>|<b>&minus;&minus;test</b>]
[<b>&minus;T</b>|<b>&minus;&minus;thin</b>]
[<b>&minus;&minus;thinpool</b> <i>ThinPoolLogicalVolume</i>]
[<b>&minus;&minus;type</b> <i>SegmentType</i>]
[<b>&minus;v</b>|<b>&minus;&minus;verbose</b>]
[<b>&minus;W</b>|<b>&minus;&minus;wipesignatures</b>
{<b>y</b>|<b>n</b>}]
[<b>&minus;Z</b>|<b>&minus;&minus;zero</b>
{<b>y</b>|<b>n</b>}] [<i>VolumeGroup</i> |
{<i>ExternalOrigin</i>|<i>Origin</i>|<i>Pool</i>}<i>LogicalVolume</i>
[<i>PhysicalVolumePath</i>[<b>:</b><i>PE</i>[<b>&minus;</b><i>PE</i>]]...]]</p>


<p style="margin-left:11%; margin-top: 1em"><b>lvcreate</b>
[<b>&minus;l</b>|<b>&minus;&minus;extents</b>
<i>LogicalExtentsNumber</i>[<b>%</b>{<b>FREE</b>|<b>ORIGIN</b>|<b>PVS</b>|<b>VG</b>}]
| <b>&minus;L</b>|<b>&minus;&minus;size</b>
<i>LogicalVolumeSize</i>]
[<b>&minus;c</b>|<b>&minus;&minus;chunksize</b>
<i>ChunkSize</i>] [<b>&minus;&minus;commandprofile</b>
<i>ProfileName</i>] [<b>&minus;&minus;noudevsync</b>]
[<b>&minus;&minus;ignoremonitoring</b>]
[<b>&minus;&minus;metadataprofile</b> <i>ProfileName</i>]
[<b>&minus;&minus;monitor</b> {<b>y</b>|<b>n</b>}]
[<b>&minus;n</b>|<b>&minus;&minus;name</b>
<i>SnapshotLogicalVolumeName</i>]
[<b>&minus;&minus;reportformat</b> {basic<b>|</b>json}]
<b>&minus;s</b>|<b>&minus;&minus;snapshot</b>|<b>&minus;H</b>|<b>&minus;&minus;cache</b>
{[<i>VolumeGroup</i><b>/</b>]<i>OriginalLogicalVolume</i>
[<b>&minus;V</b>|<b>&minus;&minus;virtualsize</b>
<i>VirtualSize</i>]}</p>

<h2>DESCRIPTION
<a name="DESCRIPTION"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">lvcreate
creates a new logical volume in a volume group (see
<b>vgcreate</b>(8), <b>vgchange</b>(8)) by allocating
logical extents from the free physical extent pool of that
volume group. If there are not enough free physical extents
then the volume group can be extended (see
<b>vgextend</b>(8)) with other physical volumes or by
reducing existing logical volumes of this volume group in
size (see <b>lvreduce</b>(8)). If you specify one or more
PhysicalVolumes, allocation of physical extents will be
restricted to these volumes. <br>
The second form supports the creation of snapshot logical
volumes which keep the contents of the original logical
volume for backup purposes.</p>

<h2>OPTIONS
<a name="OPTIONS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">See
<b>lvm</b>(8) for common options.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="44%">



<p style="margin-top: 1em"><b>&minus;a</b>|<b>&minus;&minus;activate</b>
[<b>a</b>][<b>l</b>|<b>e</b>|<b>s</b>]{<b>y</b>|<b>n</b>}</p> </td>
<td width="45%">
</td></tr>
</table>

<p style="margin-left:22%;">Controls the availability of
the Logical Volumes for immediate use after the command
finishes running. By default, new Logical Volumes are
activated (<b>&minus;ay</b>). If it is possible technically,
<b>&minus;an</b> will leave the new Logical Volume inactive.
But for example, snapshots of active origin can only be
created in the active state so <b>&minus;an</b> cannot be
used with <b>-&minus;type snapshot</b>. This does not apply
to thin volume snapshots, which are by default created with
flag to skip their activation (<b>-ky</b>). Normally the
<b>&minus;&minus;zero n</b> argument has to be supplied too
because zeroing (the default behaviour) also requires
activation. If autoactivation option is used
(<b>&minus;aay</b>), the logical volume is activated only if
it matches an item in the
<b>activation/auto_activation_volume_list</b> set in
<b>lvm.conf</b>(5). For autoactivated logical volumes,
<b>&minus;&minus;zero n</b> and
<b>&minus;&minus;wipesignatures n</b> is always assumed and
it can&rsquo;t be overridden. If the clustered locking is
enabled, <b>&minus;aey</b> will activate exclusively on one
node and <b>&minus;a</b>{<b>a</b>|<b>l</b>}<b>y</b> will
activate only on the local node.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="15%">



<p style="margin-top: 1em"><b>&minus;H</b>|<b>&minus;&minus;cache</b></p> </td>
<td width="74%">
</td></tr>
</table>

<p style="margin-left:22%;">Creates cache or cache pool
logical volume. Specifying the optional argument
<b>&minus;&minus;extents</b> or <b>&minus;&minus;size</b>
will cause the creation of the cache logical volume. When
the Volume group name is specified together with existing
logical volume name which is NOT a cache pool name, such
volume is treated as cache origin volume and cache pool is
created. In this case the <b>&minus;&minus;extents</b> or
<b>&minus;&minus;size</b> is used to specify size of cache
pool volume. See <b>lvmcache</b>(7) for more info about
caching support. Note that the cache segment type requires a
dm-cache kernel module version 1.3.0 or greater.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="74%">


<p style="margin-top: 1em"><b>&minus;&minus;cachemode</b>
{<b>passthrough</b>|<b>writeback</b>|<b>writethrough</b>}</p> </td>
<td width="15%">
</td></tr>
</table>

<p style="margin-left:22%;">Specifying a cache mode
determines when the writes to a cache LV are considered
complete. When <b>writeback</b> is specified, a write is
considered complete as soon as it is stored in the cache
pool LV. If <b>writethough</b> is specified, a write is
considered complete only when it has been stored in the
cache pool LV and on the origin LV. While
<b>writethrough</b> may be slower for writes, it is more
resilient if something should happen to a device associated
with the cache pool LV. With <b>passthrough</b> mode, all
reads are served from origin LV (all reads miss the cache)
and all writes are forwarded to the origin LV; additionally,
write hits cause cache block invalidates. See
<b>lvmcache(7)</b> for more details.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="31%">



<p style="margin-top: 1em"><b>&minus;&minus;cachepolicy</b>
<i>Policy</i></p> </td>
<td width="58%">
</td></tr>
</table>

<p style="margin-left:22%;">Only applicable to cached LVs;
see also <b>lvmcache(7)</b>. Sets the cache policy.
<b>mq</b> is the basic policy name. <b>smq</b> is more
advanced version available in newer kernels.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="69%">


<p style="margin-top: 1em"><b>&minus;&minus;cachepool</b>
<i>CachePoolLogicalVolume</i>{<i>Name</i>|<i>Path</i>}</p> </td>
<td width="20%">
</td></tr>
</table>

<p style="margin-left:22%;">Specifies the name of cache
pool volume name. The other way to specify pool name is to
append name to Volume group name argument.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="38%">



<p style="margin-top: 1em"><b>&minus;&minus;cachesettings</b>
<i>Key</i><b>=</b><i>Value</i></p> </td>
<td width="51%">
</td></tr>
</table>

<p style="margin-left:22%;">Only applicable to cached LVs;
see also <b>lvmcache(7)</b>. Sets the cache tunable
settings. In most use-cases, default values should be
adequate. Special string value <b>default</b> switches
setting back to its default kernel value and removes it from
the list of settings stored in lvm2 metadata.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="69%">



<p style="margin-top: 1em"><b>&minus;c</b>|<b>&minus;&minus;chunksize</b>
<i>ChunkSize</i>[<b>b</b>|<b>B</b>|<b>s</b>|<b>S</b>|<b>k</b>|<b>K</b>|<b>m</b>|<b>M</b>|<b>g</b>|<b>G</b>]</p> </td>
<td width="20%">
</td></tr>
</table>

<p style="margin-left:22%;">Gives the size of chunk for
snapshot, cache pool and thin pool logical volumes. Default
unit is in kilobytes. <br>
For snapshots the value must be power of 2 between 4KiB and
512KiB and the default value is 4KiB. <br>
For cache pools the value must a multiple of 32KiB between
32KiB and 1GiB. The default is 64KiB. When the size is
specified with volume caching, it may not be smaller than
cache pool creation chunk size was. <br>
For thin pools the value must be a multiple of 64KiB between
64KiB and 1GiB. Default value starts with 64KiB and grows up
to fit the pool metadata size within 128MiB, if the pool
metadata size is not specified. See <b>lvm.conf</b>(5)
setting <b>allocation/thin_pool_chunk_size_policy</b> to
select different calculation policy. Thin pool target
version &lt;1.4 requires this value to be a power of 2. For
target version &lt;1.5 discard is not supported for non
power of 2 values.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="32%">



<p style="margin-top: 1em"><b>&minus;C</b>|<b>&minus;&minus;contiguous</b>
{<b>y</b>|<b>n</b>}</p> </td>
<td width="57%">
</td></tr>
</table>

<p style="margin-left:22%;">Sets or resets the contiguous
allocation policy for logical volumes. Default is no
contiguous allocation based on a next free principle.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="14%">



<p style="margin-top: 1em"><b>&minus;&minus;corelog</b></p> </td>
<td width="75%">
</td></tr>
</table>

<p style="margin-left:22%;">This is shortcut for option
<b>&minus;&minus;mirrorlog core</b>.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="60%">


<p style="margin-top: 1em"><b>&minus;&minus;discards</b>
{<b>ignore</b>|<b>nopassdown</b>|<b>passdown</b>}</p> </td>
<td width="29%">
</td></tr>
</table>

<p style="margin-left:22%;">Sets discards behavior for thin
pool. Default is <b>passdown</b>.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="32%">



<p style="margin-top: 1em"><b>&minus;&minus;errorwhenfull</b>
{<b>y</b>|<b>n</b>}</p> </td>
<td width="57%">
</td></tr>
</table>

<p style="margin-left:22%;">Configures thin pool behaviour
when data space is exhausted. Default is <b>n</b>o. Device
will queue I/O operations until target timeout (see
dm-thin-pool kernel module option <b>no_space_timeout</b>)
expires. Thus configured system has a time to i.e. extend
the size of thin pool data device. When set to <b>y</b>es,
the I/O operation is immeditelly errored.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="38%">



<p style="margin-top: 1em"><b>&minus;K</b>|<b>&minus;&minus;ignoreactivationskip</b></p> </td>
<td width="51%">
</td></tr>
</table>

<p style="margin-left:22%;">Ignore the flag to skip Logical
Volumes during activation. Use
<b>&minus;&minus;setactivationskip</b> option to set or
reset activation skipping flag persistently for logical
volume.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="27%">



<p style="margin-top: 1em"><b>&minus;&minus;ignoremonitoring</b></p> </td>
<td width="62%">
</td></tr>
</table>

<p style="margin-left:22%;">Make no attempt to interact
with dmeventd unless <b>&minus;&minus;monitor</b> is
specified.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="86%">



<p style="margin-top: 1em"><b>-l</b>|<b>&minus;&minus;extents</b>
<i>LogicalExtentsNumber</i>[<b>%</b>{<b>VG</b>|<b>PVS</b>|<b>FREE</b>|<b>ORIGIN</b>}]</p> </td>
<td width="3%">
</td></tr>
</table>

<p style="margin-left:22%;">Specifies the size of the new
LV in logical extents. The number of physical extents
allocated may be different, and depends on the LV type.
Certain LV types require more physical extents for data
redundancy or metadata. An alternate syntax allows the size
to be determined indirectly as a percentage of the size of a
related VG, LV, or set of PVs. The suffix <b>%VG</b> denotes
the total size of the VG, the suffix <b>%FREE</b> the
remaining free space in the VG, and the suffix <b>%PVS</b>
the free space in the specified Physical Volumes. For a
snapshot, the size can be expressed as a percentage of the
total size of the Origin Logical Volume with the suffix
<b>%ORIGIN</b> (<b>100%ORIGIN</b> provides space for the
whole origin). When expressed as a percentage, the size
defines an upper limit for the number of logical extents in
the new LV. The precise number of logical extents in the new
LV is not determined until the command has completed.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="24%">



<p style="margin-top: 1em"><b>&minus;j</b>|<b>&minus;&minus;major</b>
<i>Major</i></p> </td>
<td width="65%">
</td></tr>
</table>

<p style="margin-left:22%;">Sets the major number. Major
numbers are not supported with pool volumes. This option is
supported only on older systems (kernel version 2.4) and is
ignored on modern Linux systems where major numbers are
dynamically assigned.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="44%">



<p style="margin-top: 1em"><b>&minus;&minus;metadataprofile</b>
<i>ProfileName</i></p> </td>
<td width="45%">
</td></tr>
</table>

<p style="margin-left:22%;">Uses and attaches the
<i>ProfileName</i> configuration profile to the logical
volume metadata. Whenever the logical volume is processed
next time, the profile is automatically applied. If the
volume group has another profile attached, the logical
volume profile is preferred. See <b>lvm.conf</b>(5) for more
information about <b>metadata profiles</b>.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="20%">


<p style="margin-top: 1em"><b>&minus;&minus;minor</b>
<i>Minor</i></p> </td>
<td width="69%">
</td></tr>
</table>

<p style="margin-left:22%;">Sets the minor number. Minor
numbers are not supported with pool volumes.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="31%">



<p style="margin-top: 1em"><b>&minus;m</b>|<b>&minus;&minus;mirrors</b>
<i>mirrors</i></p> </td>
<td width="58%">
</td></tr>
</table>

<p style="margin-left:22%;">Creates a mirrored logical
volume with <i>mirrors</i> copies. For example, specifying
<b>&minus;m 1</b> would result in a mirror with two-sides;
that is, a linear volume plus one copy.</p>

<p style="margin-left:22%; margin-top: 1em">Specifying the
optional argument <b>&minus;&minus;nosync</b> will cause the
creation of the mirror LV to skip the initial
resynchronization. Any data written afterwards will be
mirrored, but the original contents will not be copied.</p>

<p style="margin-left:22%; margin-top: 1em">This is useful
for skipping a potentially long and resource intensive
initial sync of an empty mirrored RaidLV.</p>

<p style="margin-left:22%; margin-top: 1em">There are two
implementations of mirroring which can be used and
correspond to the &quot;<i>raid1</i>&quot; and
&quot;<i>mirror</i>&quot; segment types. The default is
&quot;<i>raid1</i>&quot;. See the <b>&minus;&minus;type</b>
option for more information if you would like to use the
legacy &quot;<i>mirror</i>&quot; segment type. See
<b>lvm.conf</b>(5) settings
<b>global/mirror_segtype_default</b> and
<b>global/raid10_segtype_default</b> to configure default
mirror segment type. The options
<b>&minus;&minus;mirrorlog</b> and
<b>&minus;&minus;corelog</b> apply to the legacy
&quot;<i>mirror</i>&quot; segment type only.</p>

<p style="margin-left:22%; margin-top: 1em">Note the
current maxima for mirrors are 7 for &quot;mirror&quot;
providing 8 mirror legs and 9 for &quot;raid1&quot;
providing 10 legs.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="49%">


<p style="margin-top: 1em"><b>&minus;&minus;mirrorlog</b>
{<b>disk</b>|<b>core</b>|<b>mirrored</b>}</p> </td>
<td width="40%">
</td></tr>
</table>

<p style="margin-left:22%;">Specifies the type of log to be
used for logical volumes utilizing the legacy
&quot;<i>mirror</i>&quot; segment type. <br>
The default is <b>disk</b>, which is persistent and requires
a small amount of storage space, usually on a separate
device from the data being mirrored. <br>
Using <b>core</b> means the mirror is regenerated by copying
the data from the first device each time the logical volume
is activated, like after every reboot. <br>
Using <b>mirrored</b> will create a persistent log that is
itself mirrored.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="23%">


<p style="margin-top: 1em"><b>&minus;&minus;monitor</b>
{<b>y</b>|<b>n</b>}</p> </td>
<td width="66%">
</td></tr>
</table>

<p style="margin-left:22%;">Starts or avoids monitoring a
mirrored, snapshot or thin pool logical volume with
dmeventd, if it is installed. If a device used by a
monitored mirror reports an I/O error, the failure is
handled according to
<b>activation/mirror_image_fault_policy</b> and
<b>activation/mirror_log_fault_policy</b> set in
<b>lvm.conf</b>(5).</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="52%">



<p style="margin-top: 1em"><b>&minus;n</b>|<b>&minus;&minus;name</b>
<i>LogicalVolume</i>{<i>Name</i>|<i>Path</i>}</p> </td>
<td width="37%">
</td></tr>
</table>

<p style="margin-left:22%;">Sets the name for the new
logical volume. <br>
Without this option a default name of &quot;lvol#&quot; will
be generated where # is the LVM internal number of the
logical volume.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p style="margin-top: 1em"><b>&minus;&minus;nosync</b></p></td>
<td width="77%">
</td></tr>
</table>

<p style="margin-left:22%;">Causes the creation of mirror,
raid1, raid4, raid5 and raid10 to skip the initial
resynchronization. In case of mirror, raid1 and raid10, any
data written afterwards will be mirrored, but the original
contents will not be copied. In case of raid4 and raid5, no
parity blocks will be written, though any data written
afterwards will cause parity blocks to be stored. <br>
This is useful for skipping a potentially long and resource
intensive initial sync of an empty mirror/raid1/raid4/raid5
and raid10 LV. <br>
This option is not valid for raid6, because raid6 relies on
proper parity (P and Q Syndromes) being created during
initial synchronization in order to reconstruct proper user
date in case of device failures.</p>

<p style="margin-left:22%; margin-top: 1em">raid0 and
raid0_meta don&rsquo;t provide any data copies or parity
support and thus don&rsquo;t support initial
resynchronization.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="18%">



<p style="margin-top: 1em"><b>&minus;&minus;noudevsync</b></p> </td>
<td width="71%">
</td></tr>
</table>

<p style="margin-left:22%;">Disables udev synchronisation.
The process will not wait for notification from udev. It
will continue irrespective of any possible udev processing
in the background. You should only use this if udev is not
running or has rules that ignore the devices LVM2
creates.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="34%">



<p style="margin-top: 1em"><b>&minus;p</b>|<b>&minus;&minus;permission</b>
{<b>r</b>|<b>rw</b>}</p> </td>
<td width="55%">
</td></tr>
</table>

<p style="margin-left:22%;">Sets access permissions to read
only (<b>r</b>) or read and write (<b>rw</b>). <br>
Default is read and write.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="32%">



<p style="margin-top: 1em"><b>&minus;M</b>|<b>&minus;&minus;persistent</b>
{<b>y</b>|<b>n</b>}</p> </td>
<td width="57%">
</td></tr>
</table>

<p style="margin-left:22%;">Set to <b>y</b> to make the
minor number specified persistent. Pool volumes cannot have
persistent major and minor numbers. Defaults to <b>y</b>es
only when major or minor number is specified. Otherwise it
is <b>n</b>o.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="89%">



<p style="margin-top: 1em"><b>&minus;&minus;poolmetadatasize</b>
<i>MetadataVolumeSize</i>[<b>b</b>|<b>B</b>|<b>s</b>|<b>S</b>|<b>k</b>|<b>K</b>|<b>m</b>|<b>M</b>|<b>g</b>|<b>G</b>]</p> </td></tr>
</table>

<p style="margin-left:22%;">Sets the size of pool&rsquo;s
metadata logical volume. Supported values are in range
between 2MiB and 16GiB for thin pool, and upto 16GiB for
cache pool. The minimum value is computed from pool&rsquo;s
data size. Default value for thin pool is (Pool_LV_size /
Pool_LV_chunk_size * 64b). To work with a thin pool, there
should be at least 25% of free space when the size of
metadata is smaller then 16MiB, or at least 4MiB of free
space otherwise. Default unit is megabytes.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="38%">



<p style="margin-top: 1em"><b>&minus;&minus;poolmetadataspare</b>
{<b>y</b>|<b>n</b>}</p> </td>
<td width="51%">
</td></tr>
</table>

<p style="margin-left:22%;">Controls creation and
maintanence of pool metadata spare logical volume that will
be used for automated pool recovery. Only one such volume is
maintained within a volume group with the size of the
biggest pool metadata volume. Default is <b>y</b>es.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="75%">



<p style="margin-top: 1em"><b>&minus;&minus;</b>[<b>raid</b>]<b>maxrecoveryrate</b>
<i>Rate</i>[<b>b</b>|<b>B</b>|<b>s</b>|<b>S</b>|<b>k</b>|<b>K</b>|<b>m</b>|<b>M</b>|<b>g</b>|<b>G</b>]</p> </td>
<td width="14%">
</td></tr>
</table>

<p style="margin-left:22%;">Sets the maximum recovery rate
for a RAID logical volume. <i>Rate</i> is specified as an
amount per second for each device in the array. If no suffix
is given, then KiB/sec/device is assumed. Setting the
recovery rate to 0 means it will be unbounded.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="75%">



<p style="margin-top: 1em"><b>&minus;&minus;</b>[<b>raid</b>]<b>minrecoveryrate</b>
<i>Rate</i>[<b>b</b>|<b>B</b>|<b>s</b>|<b>S</b>|<b>k</b>|<b>K</b>|<b>m</b>|<b>M</b>|<b>g</b>|<b>G</b>]</p> </td>
<td width="14%">
</td></tr>
</table>

<p style="margin-left:22%;">Sets the minimum recovery rate
for a RAID logical volume. <i>Rate</i> is specified as an
amount per second for each device in the array. If no suffix
is given, then KiB/sec/device is assumed. Setting the
recovery rate to 0 means it will be unbounded.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="66%">



<p style="margin-top: 1em"><b>&minus;r</b>|<b>&minus;&minus;readahead</b>
{<i>ReadAheadSectors</i>|<b>auto</b>|<b>none</b>}</p> </td>
<td width="23%">
</td></tr>
</table>

<p style="margin-left:22%;">Sets read ahead sector count of
this logical volume. For volume groups with metadata in lvm1
format, this must be a value between 2 and 120. The default
value is <b>auto</b> which allows the kernel to choose a
suitable value automatically. <b>none</b> is equivalent to
specifying zero.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="86%">



<p style="margin-top: 1em"><b>&minus;R</b>|<b>&minus;&minus;regionsize</b>
<i>MirrorLogRegionSize</i>[<b>b</b>|<b>B</b>|<b>s</b>|<b>S</b>|<b>k</b>|<b>K</b>|<b>m</b>|<b>M</b>|<b>g</b>|<b>G</b>]</p> </td>
<td width="3%">
</td></tr>
</table>

<p style="margin-left:22%;">A mirror is divided into
regions of this size (in MiB), and the mirror log uses this
granularity to track which regions are in sync.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="43%">



<p style="margin-top: 1em"><b>&minus;k</b>|<b>&minus;&minus;setactivationskip</b>
{<b>y</b>|<b>n</b>}</p> </td>
<td width="46%">
</td></tr>
</table>

<p style="margin-left:22%;">Controls whether Logical
Volumes are persistently flagged to be skipped during
activation. By default, thin snapshot volumes are flagged
for activation skip. See <b>lvm.conf</b>(5)
<b>activation/auto_set_activation_skip</b> how to change its
default behaviour. To activate such volumes, an extra
<b>&minus;&minus;ignoreactivationskip</b> option must be
used. The flag is not applied during deactivation. Use
<b>lvchange &minus;&minus;setactivationskip</b> command to
change the skip flag for existing volumes. To see whether
the flag is attached, use <b>lvs</b> command where the state
of the flag is reported within <b>lv_attr</b> bits.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="89%">



<p style="margin-top: 1em"><b>&minus;L</b>|<b>&minus;&minus;size</b>
<i>LogicalVolumeSize</i>[<b>b</b>|<b>B</b>|<b>s</b>|<b>S</b>|<b>k</b>|<b>K</b>|<b>m</b>|<b>M</b>|<b>g</b>|<b>G</b>|<b>t</b>|<b>T</b>|<b>p</b>|<b>P</b>|<b>e</b>|<b>E</b>]</p> </td></tr>
</table>

<p style="margin-left:22%;">Gives the size to allocate for
the new logical volume. A size suffix of <b>B</b> for bytes,
<b>S</b> for sectors as 512 bytes, <b>K</b> for kilobytes,
<b>M</b> for megabytes, <b>G</b> for gigabytes, <b>T</b> for
terabytes, <b>P</b> for petabytes or <b>E</b> for exabytes
is optional. <br>
Default unit is megabytes.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="71%">



<p style="margin-top: 1em"><b>&minus;s</b>|<b>&minus;&minus;snapshot</b>
<i>OriginalLogicalVolume</i>{<i>Name</i>|<i>Path</i>}</p> </td>
<td width="18%">
</td></tr>
</table>

<p style="margin-left:22%;">Creates a snapshot logical
volume (or snapshot) for an existing, so called original
logical volume (or origin). Snapshots provide a
&rsquo;frozen image&rsquo; of the contents of the origin
while the origin can still be updated. They enable
consistent backups and online recovery of
removed/overwritten data/files. <br>
Thin snapshot is created when the origin is a thin volume
and the size IS NOT specified. Thin snapshot shares same
blocks within the thin pool volume. The non thin volume
snapshot with the specified size does not need the same
amount of storage the origin has. In a typical scenario,
15-20% might be enough. In case the snapshot runs out of
storage, use <b>lvextend</b>(8) to grow it. Shrinking a
snapshot is supported by <b>lvreduce</b>(8) as well. Run
<b>lvs</b>(8) on the snapshot in order to check how much
data is allocated to it. Note: a small amount of the space
you allocate to the snapshot is used to track the locations
of the chunks of data, so you should allocate slightly more
space than you actually need and monitor
(<b>&minus;&minus;monitor</b>) the rate at which the
snapshot data is growing so you can <b>avoid</b> running out
of space. If <b>&minus;&minus;thinpool</b> is specified,
thin volume is created that will use given original logical
volume as an external origin that serves unprovisioned
blocks. Only read-only volumes can be used as external
origins. To make the volume external origin, lvm expects the
volume to be inactive. External origin volume can be
used/shared for many thin volumes even from different thin
pools. See <b>lvconvert</b>(8) for online conversion to thin
volumes with external origin.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="31%">



<p style="margin-top: 1em"><b>&minus;i</b>|<b>&minus;&minus;stripes</b>
<i>Stripes</i></p> </td>
<td width="58%">
</td></tr>
</table>

<p style="margin-left:22%;">Gives the number of stripes.
This is equal to the number of physical volumes to scatter
the logical volume data. When creating a RAID 4/5/6 logical
volume, the extra devices which are necessary for parity are
internally accounted for. Specifying <b>&minus;i 3</b> would
cause 3 devices for striped and RAID 0 logical volumes, 4
devices for RAID 4/5, 5 devices for RAID 6 and 6 devices for
RAID 10. Alternatively, RAID 0 will stripe across 2 devices,
RAID 4/5 across 3 PVs, RAID 6 across 5 PVs and RAID 10
across 4 PVs in the volume group if the <b>&minus;i</b>
argument is omitted. In order to stripe across all PVs of
the VG if the <b>&minus;i</b> argument is omitted, set
raid_stripe_all_devices=1 in the allocation section of
<b>lvm.conf (5)</b> or add <b><br>
&minus;&minus;config
allocation/raid_stripe_all_devices=1</b> <br>
to the command.</p>

<p style="margin-left:22%; margin-top: 1em">Note the
current maxima for stripes depend on the created RAID type.
For raid10, the maximum of stripes is 32, for raid0, it is
64, for raid4/5, it is 63 and for raid6 it is 62.</p>

<p style="margin-left:22%; margin-top: 1em">See the
<b>&minus;&minus;nosync</b> option to optionally avoid
initial syncrhonization of RaidLVs.</p>

<p style="margin-left:22%; margin-top: 1em">Two
implementations of basic striping are available in the
kernel. The original device-mapper implementation is the
default and should normally be used. The alternative
implementation using MD, available since version 1.7 of the
RAID device-mapper kernel target (kernel version 4.2) is
provided to facilitate the development of new RAID features.
It may be accessed with <b>--type raid0[_meta]</b>, but is
best avoided at present because of assorted restrictions on
resizing and converting such devices.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="40%">



<p style="margin-top: 1em"><b>&minus;I</b>|<b>&minus;&minus;stripesize</b>
<i>StripeSize</i></p> </td>
<td width="49%">
</td></tr>
</table>

<p style="margin-left:22%;">Gives the number of kilobytes
for the granularity of the stripes. <br>
StripeSize must be 2^n (n = 2 to 9) for metadata in LVM1
format. For metadata in LVM2 format, the stripe size may be
a larger power of 2 but must not exceed the physical extent
size.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="14%">



<p style="margin-top: 1em"><b>&minus;T</b>|<b>&minus;&minus;thin</b></p> </td>
<td width="75%">
</td></tr>
</table>

<p style="margin-left:22%;">Creates thin pool or thin
logical volume or both. Specifying the optional argument
<b>&minus;&minus;size</b> or <b>&minus;&minus;extents</b>
will cause the creation of the thin pool logical volume.
Specifying the optional argument
<b>&minus;&minus;virtualsize</b> will cause the creation of
the thin logical volume from given thin pool volume.
Specifying both arguments will cause the creation of both
thin pool and thin volume using this pool. See
<b>lvmthin</b>(7) for more info about thin provisioning
support. Thin provisioning requires device mapper kernel
driver from kernel 3.2 or greater.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="66%">


<p style="margin-top: 1em"><b>&minus;&minus;thinpool</b>
<i>ThinPoolLogicalVolume</i>{<i>Name</i>|<i>Path</i>}</p> </td>
<td width="23%">
</td></tr>
</table>

<p style="margin-left:22%;">Specifies the name of thin pool
volume name. The other way to specify pool name is to append
name to Volume group name argument.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="27%">


<p style="margin-top: 1em"><b>&minus;&minus;type</b>
<i>SegmentType</i></p> </td>
<td width="62%">
</td></tr>
</table>

<p style="margin-left:22%;">Creates a logical volume with
the specified segment type. Supported types are:
<b>cache</b>, <b>cache-pool</b>, <b>error</b>,
<b>linear</b>, <b>mirror, raid0</b>, <b>raid1</b>,
<b>raid4</b>, <b>raid5_la</b>, <b>raid5_ls</b> (=
<b>raid5</b>), <b>raid5_ra</b>, <b>raid5_rs</b>,
<b>raid6_nc</b>, <b>raid6_nr</b>, <b>raid6_zr</b> (=
<b>raid6</b>), <b>raid10</b>, <b>snapshot</b>, <b>striped,
thin</b>, <b>thin-pool</b> or <b>zero</b>. Segment type may
have a commandline switch alias that will enable its use.
When the type is not explicitly specified an implicit type
is selected from combination of options:
<b>&minus;H</b>|<b>&minus;&minus;cache</b>|<b>&minus;&minus;cachepool</b>
(cache or cachepool),
<b>&minus;T</b>|<b>&minus;&minus;thin</b>|<b>&minus;&minus;thinpool</b>
(thin or thinpool),
<b>&minus;m</b>|<b>&minus;&minus;mirrors</b> (raid1 or
mirror),
<b>&minus;s</b>|<b>&minus;&minus;snapshot</b>|<b>&minus;V</b>|<b>&minus;&minus;virtualsize</b>
(snapshot or thin),
<b>&minus;i</b>|<b>&minus;&minus;stripes</b> (striped). The
default segment type is <b>linear</b>.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="89%">



<p style="margin-top: 1em"><b>&minus;V</b>|<b>&minus;&minus;virtualsize</b>
<i>VirtualSize</i>[<b>b</b>|<b>B</b>|<b>s</b>|<b>S</b>|<b>k</b>|<b>K</b>|<b>m</b>|<b>M</b>|<b>g</b>|<b>G</b>|<b>t</b>|<b>T</b>|<b>p</b>|<b>P</b>|<b>e</b>|<b>E</b>]</p> </td></tr>
</table>

<p style="margin-left:22%;">Creates a thinly provisioned
device or a sparse device of the given size (in MiB by
default). See <b>lvm.conf</b>(5) settings
<b>global/sparse_segtype_default</b> to configure default
sparse segment type. See <b>lvmthin</b>(7) for more info
about thin provisioning support. Anything written to a
sparse snapshot will be returned when reading from it.
Reading from other areas of the device will return blocks of
zeros. Virtual snapshot (sparse snapshot) is implemented by
creating a hidden virtual device of the requested size using
the zero target. A suffix of _vorigin is used for this
device. Note: using sparse snapshots is not efficient for
larger device sizes (GiB), thin provisioning should be used
for this case.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="38%">



<p style="margin-top: 1em"><b>&minus;W</b>|<b>&minus;&minus;wipesignatures</b>
{<b>y</b>|<b>n</b>}</p> </td>
<td width="51%">
</td></tr>
</table>

<p style="margin-left:22%;">Controls detection and
subsequent wiping of signatures on newly created Logical
Volume. There&rsquo;s a prompt for each signature detected
to confirm its wiping (unless <b>--yes</b> is used where LVM
assumes &rsquo;yes&rsquo; answer for each prompt
automatically). If this option is not specified, then by
default <b>-W</b> | <b>--wipesignatures y</b> is assumed
each time the zeroing is done (<b>&minus;Z</b> |
<b>&minus;&minus;zero y</b>). This default behaviour can be
controlled by
<b>allocation/wipe_signatures_when_zeroing_new_lvs</b>
setting found in <b>lvm.conf</b>(5). <br>
If blkid wiping is used (<b>allocation/use_blkid_wiping</b>
setting in <b>lvm.conf</b>(5)) and LVM2 is compiled with
blkid wiping support, then <b>blkid</b>(8) library is used
to detect the signatures (use <b>blkid &minus;k</b> command
to list the signatures that are recognized). Otherwise,
native LVM2 code is used to detect signatures (MD RAID, swap
and LUKS signatures are detected only in this case). <br>
Logical volume is not wiped if the read only flag is
set.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="23%">



<p style="margin-top: 1em"><b>&minus;Z</b>|<b>&minus;&minus;zero</b>
{<b>y</b>|<b>n</b>}</p> </td>
<td width="66%">
</td></tr>
</table>

<p style="margin-left:22%;">Controls zeroing of the first
4KiB of data in the new logical volume. Default is
<b>y</b>es. Snapshot COW volumes are always zeroed. Logical
volume is not zeroed if the read only flag is set. <br>
Warning: trying to mount an unzeroed logical volume can
cause the system to hang.</p>

<h2>Examples
<a name="Examples"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Creates a
striped logical volume with 3 stripes, a stripe size of 8KiB
and a size of 100MiB in the volume group named vg00. The
logical volume name will be chosen by lvcreate:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;i 3 &minus;I 8 &minus;L 100M vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
mirror logical volume with 2 sides with a useable size of
500 MiB. This operation would require 3 devices (or option
<b>&minus;&minus;alloc anywhere</b>) - two for the mirror
devices and one for the disk log:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;m1 &minus;L 500M vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
mirror logical volume with 2 sides with a useable size of
500 MiB. This operation would require 2 devices - the log is
&quot;in-memory&quot;:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;m1 &minus;&minus;mirrorlog core &minus;L 500M
vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
snapshot logical volume named &quot;vg00/snap&quot; which
has access to the contents of the original logical volume
named &quot;vg00/lvol1&quot; at snapshot logical volume
creation time. If the original logical volume contains a
file system, you can mount the snapshot logical volume on an
arbitrary directory in order to access the contents of the
filesystem to run a backup while the original filesystem
continues to get updated:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;size 100m &minus;&minus;snapshot
&minus;&minus;name snap /dev/vg00/lvol1</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
snapshot logical volume named &quot;vg00/snap&quot; with
size for overwriting 20% of the original logical volume
named &quot;vg00/lvol1&quot;.:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;s &minus;l 20%ORIGIN &minus;&minus;name snap
vg00/lvol1</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
sparse device named /dev/vg1/sparse of size 1TiB with space
for just under 100MiB of actual data on it:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;virtualsize 1T &minus;&minus;size 100M
&minus;&minus;snapshot &minus;&minus;name sparse vg1</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a
linear logical volume &quot;vg00/lvol1&quot; using physical
extents /dev/sda:0&minus;7 and /dev/sdb:0&minus;7 for
allocation of extents:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;L 64M &minus;n lvol1 vg00 /dev/sda:0&minus;7
/dev/sdb:0&minus;7</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a 5GiB
RAID5 logical volume &quot;vg00/my_lv&quot;, with 3 stripes
(plus a parity drive for a total of 4 devices) and a
stripesize of 64KiB:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;type raid5 &minus;L 5G &minus;i 3 &minus;I 64
&minus;n my_lv vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a RAID5
logical volume &quot;vg00/my_lv&quot;, using all of the free
space in the VG and spanning all the PVs in the VG (note
that the command will fail if there&rsquo;s more than 8 PVs
in the VG in which case <b>&minus;i 7</b> has to be used to
get to the currently possible maximum of 8 devices including
parity for RaidLVs):</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;config allocation/raid_stripe_all_devices=1
&minus;&minus;type raid5 &minus;l 100%FREE &minus;n my_lv
vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a 5GiB
RAID10 logical volume &quot;vg00/my_lv&quot;, with 2 stripes
on 2 2-way mirrors. Note that the <b>-i</b> and <b>-m</b>
arguments behave differently. The <b>-i</b> specifies the
number of stripes. The <b>-m</b> specifies the number of
<b>additional</b> copies:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;type raid10 &minus;L 5G &minus;i 2 &minus;m 1
&minus;n my_lv vg00</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates 100MiB
pool logical volume for thin provisioning build with 2
stripes 64KiB and chunk size 256KiB together with 1TiB thin
provisioned logical volume &quot;vg00/thin_lv&quot;:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;i 2 &minus;I 64 &minus;c 256 &minus;L100M &minus;T
vg00/pool &minus;V 1T &minus;&minus;name thin_lv</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a thin
snapshot volume &quot;thinsnap&quot; of thin volume
&quot;thinvol&quot; that will share the same blocks within
the thin pool. Note: the size MUST NOT be specified,
otherwise the non-thin snapshot is created instead:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;s vg00/thinvol &minus;&minus;name thinsnap</b></p>

<p style="margin-left:11%; margin-top: 1em">Creates a thin
snapshot volume of read-only inactive volume
&quot;origin&quot; which then becomes the thin external
origin for the thin snapshot volume in vg00 that will use an
existing thin pool &quot;vg00/pool&quot;:</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;s &minus;&minus;thinpool vg00/pool origin</b></p>

<p style="margin-left:11%; margin-top: 1em">Create a cache
pool LV that can later be used to cache one logical
volume.</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;type cache-pool &minus;L 1G &minus;n
my_lv_cachepool vg /dev/fast1</b></p>

<p style="margin-left:11%; margin-top: 1em">If there is an
existing cache pool LV, create the large slow device (i.e.
the origin LV) and link it to the supplied cache pool LV,
creating a cache LV.</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;cache &minus;L 100G &minus;n my_lv
vg/my_lv_cachepool /dev/slow1</b></p>

<p style="margin-left:11%; margin-top: 1em">If there is an
existing logical volume, create the small and fast cache
pool LV and link it to the supplied existing logical volume
(i.e. the origin LV), creating a cache LV.</p>

<p style="margin-left:11%; margin-top: 1em"><b>lvcreate
&minus;&minus;type cache &minus;L 1G &minus;n
my_lv_cachepool vg/my_lv /dev/fast1</b></p>

<h2>SEE ALSO
<a name="SEE ALSO"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><b>lvm</b>(8),
<b>lvm.conf</b>(5), <b>lvmcache</b>(7), <b>lvmthin</b>(7),
<b>lvconvert</b>(8), <b>lvchange</b>(8), <b>lvextend</b>(8),
<b>lvreduce</b>(8), <b>lvremove</b>(8), <b>lvrename</b>(8)
<b>lvs</b>(8), <b>lvscan</b>(8), <b>vgcreate</b>(8),
<b>blkid</b>(8)</p>
<hr>
</body>
</html>

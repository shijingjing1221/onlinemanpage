<!-- Creator     : groff version 1.22.2 -->
<!-- CreationDate: Fri Nov 11 01:39:00 2016 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title>gfs2</title>

</head>
<body>

<h1 align="center">gfs2</h1>

<a href="#NAME">NAME</a><br>
<a href="#SYNOPSIS">SYNOPSIS</a><br>
<a href="#DESCRIPTION">DESCRIPTION</a><br>
<a href="#MOUNT OPTIONS">MOUNT OPTIONS</a><br>
<a href="#BUGS">BUGS</a><br>
<a href="#SEE ALSO">SEE ALSO</a><br>
<a href="#SETUP">SETUP</a><br>

<hr>


<h2>NAME
<a name="NAME"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">gfs2 &minus;
GFS2 reference guide</p>

<h2>SYNOPSIS
<a name="SYNOPSIS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Overview of the
GFS2 filesystem</p>

<h2>DESCRIPTION
<a name="DESCRIPTION"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">GFS2 is a
clustered filesystem, designed for sharing data between
multiple nodes connected to a common shared storage device.
It can also be used as a local filesystem on a single node,
however since the design is aimed at clusters, that will
usually result in lower performance than using a filesystem
designed specifically for single node use.</p>

<p style="margin-left:11%; margin-top: 1em">GFS2 is a
journaling filesystem and one journal is required for each
node that will mount the filesystem. The one exception to
that is spectator mounts which are equivalent to mounting a
read-only block device and as such can neither recover a
journal or write to the filesystem, so do not require a
journal assigned to them.</p>

<h2>MOUNT OPTIONS
<a name="MOUNT OPTIONS"></a>
</h2>



<p style="margin-left:11%; margin-top: 1em"><b>lockproto=</b><i>LockProtoName</i></p>

<p style="margin-left:22%;">This specifies which inter-node
lock protocol is used by the GFS2 filesystem for this mount,
overriding the default lock protocol name stored in the
filesystem&rsquo;s on-disk superblock.</p>

<p style="margin-left:22%; margin-top: 1em">The
<i>LockProtoName</i> must be one of the supported locking
protocols, currently these are <i>lock_nolock</i> and
<i>lock_dlm</i>.</p>

<p style="margin-left:22%; margin-top: 1em">The default
lock protocol name is written to disk initially when
creating the filesystem with <b>mkfs.gfs2</b>(8), -p option.
It can be changed on-disk by using the <b>gfs2_tool</b>(8)
utility&rsquo;s <b>sb proto</b> command.</p>

<p style="margin-left:22%; margin-top: 1em">The
<b>lockproto</b> mount option should be used only under
special circumstances in which you want to temporarily use a
different lock protocol without changing the on-disk
default. Using the incorrect lock protocol on a cluster
filesystem mounted from more than one node will almost
certainly result in filesystem corruption.</p>


<p style="margin-left:11%;"><b>locktable=</b><i>LockTableName</i></p>

<p style="margin-left:22%;">This specifies the identity of
the cluster and of the filesystem for this mount, overriding
the default cluster/filesystem identify stored in the
filesystem&rsquo;s on-disk superblock. The
cluster/filesystem name is recognized globally throughout
the cluster, and establishes a unique namespace for the
inter-node locking system, enabling the mounting of multiple
GFS2 filesystems.</p>

<p style="margin-left:22%; margin-top: 1em">The format of
<i>LockTableName</i> is lock-module-specific. For
<i>lock_dlm</i>, the format is <i>clustername:fsname</i>.
For <i>lock_nolock</i>, the field is ignored.</p>

<p style="margin-left:22%; margin-top: 1em">The default
cluster/filesystem name is written to disk initially when
creating the filesystem with <b>mkfs.gfs2</b>(8), -t option.
It can be changed on-disk by using the <b>gfs2_tool</b>(8)
utility&rsquo;s <b>sb table</b> command.</p>

<p style="margin-left:22%; margin-top: 1em">The
<b>locktable</b> mount option should be used only under
special circumstances in which you want to mount the
filesystem in a different cluster, or mount it as a
different filesystem name, without changing the on-disk
default.</p>

<p style="margin-left:11%;"><b>localflocks</b></p>

<p style="margin-left:22%;">This flag tells GFS2 that it is
running as a local (not clustered) filesystem, so it can
allow the kernel VFS layer to do all flock and fcntl file
locking. When running in cluster mode, these file locks
require inter-node locks, and require the support of GFS2.
When running locally, better performance is achieved by
letting VFS handle the whole job.</p>

<p style="margin-left:22%; margin-top: 1em">This is turned
on automatically by the lock_nolock module.</p>


<p style="margin-left:11%;"><b>errors=</b><i>[panic|withdraw]</i></p>

<p style="margin-left:22%;">Setting errors=panic causes
GFS2 to oops when encountering an error that would otherwise
cause the mount to withdraw or print an assertion warning.
The default setting is errors=withdraw. This option should
not be used in a production system. It replaces the earlier
<b>debug</b> option on kernel versions 2.6.31 and above.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p><b>acl</b></p></td>
<td width="7%"></td>
<td width="78%">


<p>Enables POSIX Access Control List <b>acl</b>(5) support
within GFS2.</p></td></tr>
</table>

<p style="margin-left:11%;"><b>spectator</b></p>

<p style="margin-left:22%;">Mount this filesystem using a
special form of read-only mount. The mount does not use one
of the filesystem&rsquo;s journals. The node is unable to
recover journals for other nodes.</p>

<p style="margin-left:11%;"><b>norecovery</b></p>

<p style="margin-left:22%;">A synonym for spectator</p>

<p style="margin-left:11%;"><b>suiddir</b></p>

<p style="margin-left:22%;">Sets owner of any newly created
file or directory to be that of parent directory, if parent
directory has S_ISUID permission attribute bit set. Sets
S_ISUID in any new directory, if its parent
directory&rsquo;s S_ISUID is set. Strips all execution bits
on a new file, if parent directory owner is different from
owner of process creating the file. Set this option only if
you know why you are setting it.</p>


<p style="margin-left:11%;"><b>quota=</b><i>[off/account/on]</i></p>

<p style="margin-left:22%;">Turns quotas on or off for a
filesystem. Setting the quotas to be in the
&quot;account&quot; state causes the per UID/GID usage
statistics to be correctly maintained by the filesystem,
limit and warn values are ignored. The default value is
&quot;off&quot;.</p>

<p style="margin-left:11%;"><b>discard</b></p>

<p style="margin-left:22%;">Causes GFS2 to generate
&quot;discard&quot; I/O requests for blocks which have been
freed. These can be used by suitable hardware to implement
thin-provisioning and similar schemes. This feature is
supported in kernel version 2.6.30 and above.</p>

<p style="margin-left:11%;"><b>barrier</b></p>

<p style="margin-left:22%;">This option, which defaults to
on, causes GFS2 to send I/O barriers when flushing the
journal. The option is automatically turned off if the
underlying device does not support I/O barriers. We highly
recommend the use of I/O barriers with GFS2 at all times
unless the block device is designed so that it cannot lose
its write cache content (e.g. its on a UPS, or it
doesn&rsquo;t have a write cache)</p>

<p style="margin-left:11%;"><b>commit=</b><i>secs</i></p>

<p style="margin-left:22%;">This is similar to the ext3
<b>commit=</b> option in that it sets the maximum number of
seconds between journal commits if there is dirty data in
the journal. The default is 60 seconds. This option is only
provided in kernel versions 2.6.31 and above.</p>


<p style="margin-left:11%;"><b>data=</b><i>[ordered|writeback]</i></p>

<p style="margin-left:22%;">When data=ordered is set, the
user data modified by a transaction is flushed to the disk
before the transaction is committed to disk. This should
prevent the user from seeing uninitialized blocks in a file
after a crash. Data=writeback mode writes the user data to
the disk at any time after it&rsquo;s dirtied. This
doesn&rsquo;t provide the same consistency guarantee as
ordered mode, but it should be slightly faster for some
workloads. The default is ordered mode.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="6%">


<p><b>meta</b></p></td>
<td width="5%"></td>
<td width="78%">


<p>This option results in selecting the meta filesystem
root rather than the normal filesystem root. This option is
normally only used by the GFS2 utility functions. Altering
any file on the GFS2 meta filesystem may render the
filesystem unusable, so only experts in the GFS2 on-disk
layout should use this option.</p></td></tr>
</table>


<p style="margin-left:11%;"><b>quota_quantum=</b><i>secs</i></p>

<p style="margin-left:22%;">This sets the number of seconds
for which a change in the quota information may sit on one
node before being written to the quota file. This is the
preferred way to set this parameter. The value is an integer
number of seconds greater than zero. The default is 60
seconds. Shorter settings result in faster updates of the
lazy quota information and less likelihood of someone
exceeding their quota. Longer settings make filesystem
operations involving quotas faster and more efficient.</p>


<p style="margin-left:11%;"><b>statfs_quantum=</b><i>secs</i></p>

<p style="margin-left:22%;">Setting statfs_quantum to 0 is
the preferred way to set the slow version of statfs. The
default value is 30 secs which sets the maximum time period
before statfs changes will be syned to the master statfs
file. This can be adjusted to allow for faster, less
accurate statfs values or slower more accurate values. When
set to 0, statfs will always report the true values.</p>


<p style="margin-left:11%;"><b>statfs_percent=</b><i>value</i></p>

<p style="margin-left:22%;">This setting provides a bound
on the maximum percentage change in the statfs information
on a local basis before it is synced back to the master
statfs file, even if the time period has not expired. If the
setting of statfs_quantum is 0, then this setting is
ignored.</p>

<h2>BUGS
<a name="BUGS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">GFS2
doesn&rsquo;t support <b>errors=</b><i>remount-ro</i> or
<b>data=</b><i>journal</i>. It is not possible to switch
support for user and group quotas on and off independently
of each other. Some of the error messages are rather
cryptic, if you encounter one of these messages check
firstly that gfs_controld is running and secondly that you
have enough journals on the filesystem for the number of
nodes in use.</p>

<h2>SEE ALSO
<a name="SEE ALSO"></a>
</h2>



<p style="margin-left:11%; margin-top: 1em"><b>mount</b>(8)
for general mount options, <b>chmod</b>(1) and
<b>chmod</b>(2) for access permission flags, <b>acl</b>(5)
for access control lists, <b>lvm</b>(8) for volume
management, <b>ccs</b>(7) for cluster management,
<b>umount</b>(8), <b>initrd</b>(4).</p>

<p style="margin-left:11%; margin-top: 1em">The GFS2
documentation has been split into a number of sections:</p>


<p style="margin-left:11%; margin-top: 1em"><b>gfs2_edit</b>(8)
A GFS2 debug tool (use with caution) <b>fsck.gfs2</b>(8) The
GFS2 file system checker <b>gfs2_grow</b>(8) Growing a GFS2
file system <b>gfs2_jadd</b>(8) Adding a journal to a GFS2
file system <b>mkfs.gfs2</b>(8) Make a GFS2 file system
<b>gfs2_quota</b>(8) Manipulate GFS2 disk quotas
<b>gfs2_tool</b>(8) Tool to manipulate a GFS2 file system
(obsolete) <b>tunegfs2</b>(8) Tool to manipulate GFS2
superblocks</p>

<h2>SETUP
<a name="SETUP"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">GFS2 clustering
is driven by the dlm, which depends on dlm_controld to
provide clustering from userspace. dlm_controld clustering
is built on corosync cluster/group membership and
messaging.</p>

<p style="margin-left:11%; margin-top: 1em">Follow these
steps to manually configure and run gfs2/dlm/corosync.</p>

<p style="margin-left:11%; margin-top: 1em"><b>1. create
/etc/corosync/corosync.conf and copy to all nodes</b></p>

<p style="margin-left:11%; margin-top: 1em">In this sample,
replace cluster_name and IP addresses, and add nodes as
needed. If using only two nodes, uncomment the two_node
line. See corosync.conf(5) for more information.</p>

<p style="margin-left:11%; margin-top: 1em">totem { <br>
version: 2 <br>
secauth: off <br>
cluster_name: abc <br>
}</p>

<p style="margin-left:11%; margin-top: 1em">nodelist { <br>
node { <br>
ring0_addr: 10.10.10.1 <br>
nodeid: 1 <br>
} <br>
node { <br>
ring0_addr: 10.10.10.2 <br>
nodeid: 2 <br>
} <br>
node { <br>
ring0_addr: 10.10.10.3 <br>
nodeid: 3 <br>
} <br>
}</p>

<p style="margin-left:11%; margin-top: 1em">quorum { <br>
provider: corosync_votequorum <br>
# two_node: 1 <br>
}</p>

<p style="margin-left:11%; margin-top: 1em">logging { <br>
to_syslog: yes <br>
}</p>

<p style="margin-left:11%; margin-top: 1em"><b>2. start
corosync on all nodes</b></p>

<p style="margin-left:11%; margin-top: 1em">systemctl start
corosync</p>

<p style="margin-left:11%; margin-top: 1em">Run
corosync-quorumtool to verify that all nodes are listed.</p>

<p style="margin-left:11%; margin-top: 1em"><b>3. create
/etc/dlm/dlm.conf and copy to all nodes</b></p>

<p style="margin-left:11%; margin-top: 1em"><b>*</b> To use
no fencing, use this line:</p>


<p style="margin-left:11%; margin-top: 1em">enable_fencing=0</p>

<p style="margin-left:11%; margin-top: 1em"><b>*</b> To use
no fencing, but exercise fencing functions, use this
line:</p>

<p style="margin-left:11%; margin-top: 1em">fence_all
/bin/true</p>

<p style="margin-left:11%; margin-top: 1em">The
&quot;true&quot; binary will be executed for all nodes and
will succeed (exit 0) immediately.</p>

<p style="margin-left:11%; margin-top: 1em"><b>*</b> To use
manual fencing, use this line:</p>

<p style="margin-left:11%; margin-top: 1em">fence_all
/bin/false</p>

<p style="margin-left:11%; margin-top: 1em">The
&quot;false&quot; binary will be executed for all nodes and
will fail (exit 1) immediately.</p>

<p style="margin-left:11%; margin-top: 1em">When a node
fails, manually run: dlm_tool fence_ack &lt;nodeid&gt;</p>

<p style="margin-left:11%; margin-top: 1em"><b>*</b> To use
stonith/pacemaker for fencing, use this line:</p>

<p style="margin-left:11%; margin-top: 1em">fence_all
/usr/sbin/dlm_stonith</p>

<p style="margin-left:11%; margin-top: 1em">The
&quot;dlm_stonith&quot; binary will be executed for all
nodes. If stonith/pacemaker systems are not available,
dlm_stonith will fail and this config becomes the equivalent
of the previous /bin/false config.</p>

<p style="margin-left:11%; margin-top: 1em"><b>*</b> To use
an APC power switch, use these lines:</p>

<p style="margin-left:11%; margin-top: 1em">device apc
/usr/sbin/fence_apc ipaddr=1.1.1.1 login=admin password=pw
<br>
connect apc node=1 port=1 <br>
connect apc node=2 port=2 <br>
connect apc node=3 port=3</p>

<p style="margin-left:11%; margin-top: 1em">Other network
switch based agents are configured similarly.</p>

<p style="margin-left:11%; margin-top: 1em"><b>*</b> To use
sanlock/watchdog fencing, use these lines:</p>

<p style="margin-left:11%; margin-top: 1em">device wd
/usr/sbin/fence_sanlock path=/dev/fence/leases <br>
connect wd node=1 host_id=1 <br>
connect wd node=2 host_id=2 <br>
unfence wd</p>

<p style="margin-left:11%; margin-top: 1em">See
fence_sanlock(8) for more information.</p>

<p style="margin-left:11%; margin-top: 1em"><b>*</b> For
other fencing configurations see dlm.conf(5) man page.</p>

<p style="margin-left:11%; margin-top: 1em"><b>4. start
dlm_controld on all nodes</b></p>

<p style="margin-left:11%; margin-top: 1em">systemctl start
dlm</p>

<p style="margin-left:11%; margin-top: 1em">Run
&quot;dlm_tool status&quot; to verify that all nodes are
listed.</p>

<p style="margin-left:11%; margin-top: 1em"><b>5. if using
clvm, start clvmd on all nodes</b></p>

<p style="margin-left:11%; margin-top: 1em">systemctl clvmd
start</p>

<p style="margin-left:11%; margin-top: 1em"><b>6. make new
gfs2 file systems</b></p>

<p style="margin-left:11%; margin-top: 1em">mkfs.gfs2 -p
lock_dlm -t cluster_name:fs_name -j num /path/to/storage</p>

<p style="margin-left:11%; margin-top: 1em">The
cluster_name must match the name used in step 1 above. The
fs_name must be a unique name in the cluster. The -j option
is the number of journals to create, there must be one for
each node that will mount the fs.</p>

<p style="margin-left:11%; margin-top: 1em"><b>7. mount
gfs2 file systems</b></p>

<p style="margin-left:11%; margin-top: 1em">mount
/path/to/storage /mountpoint</p>

<p style="margin-left:11%; margin-top: 1em">Run
&quot;dlm_tool ls&quot; to verify the nodes that have each
fs mounted.</p>

<p style="margin-left:11%; margin-top: 1em"><b>8. shut
down</b></p>

<p style="margin-left:11%; margin-top: 1em">umount -a -t
gfs2 <br>
systemctl clvmd stop <br>
systemctl dlm stop <br>
systemctl corosync stop</p>

<p style="margin-left:11%; margin-top: 1em"><b>More setup
information: <br>
dlm_controld</b>(8), <b><br>
dlm_tool</b>(8), <b><br>
dlm.conf</b>(5), <b><br>
corosync</b>(8), <b><br>
 corosync.conf</b>(5)</p>
<hr>
</body>
</html>

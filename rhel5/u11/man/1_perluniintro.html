<!-- Creator     : groff version 1.18.1.1 -->
<!-- CreationDate: Sat Nov 12 05:18:50 2016 -->
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta name="Content-Style" content="text/css">
<title></title>
</head>
<body>

<hr>

<p>PERLUNIINTRO(1) Perl Programmers Reference Guide
PERLUNIINTRO(1)</p>

<p>NAME perluniintro - Perl Unicode introduction</p>

<p>DESCRIPTION This document gives a general idea of
Unicode and how to use Unicode in Perl.</p>

<p>Unicode</p>

<p>Unicode is a character set standard which plans to
codify all of the writing systems of the world, plus many
other symbols.</p>

<p>Unicode and ISO/IEC 10646 are coordinated standards that
provide code points for characters in almost all modern
character set standards, covering more than 30 writing
systems and hundreds of languages, including all
commercially-important modern languages. All characters in
the largest Chinese, Japanese, and Korean dictionaries are
also encoded. The standards will eventually cover almost all
characters in more than 250 writing systems and thousands of
languages. Unicode 1.0 was released in October 1991, and 4.0
in April 2003.</p>

<p>A Unicode character is an abstract entity. It is not
bound to any par- ticular integer width, especially not to
the C language &quot;char&quot;. Uni- code is
language-neutral and display-neutral: it does not encode the
language of the text and it does not define fonts or other
graphical layout details. Unicode operates on characters and
on text built from those characters.</p>

<p>Unicode defines characters like &quot;LATIN CAPITAL
LETTER A&quot; or &quot;GREEK SMALL LETTER ALPHA&quot; and
unique numbers for the characters, in this case 0x0041 and
0x03B1, respectively. These unique numbers are called code
points.</p>

<p>The Unicode standard prefers using hexadecimal notation
for the code points. If numbers like 0x0041 are unfamiliar
to you, take a peek at a later section, &quot;Hexadecimal
Notation&quot;. The Unicode standard uses the notation
&quot;U+0041 LATIN CAPITAL LETTER A&quot;, to give the
hexadecimal code point and the normative name of the
character.</p>

<p>Unicode also defines various properties for the
characters, like &quot;uppercase&quot; or
&quot;lowercase&quot;, &quot;decimal digit&quot;, or
&quot;punctuation&quot;; these properties are independent of
the names of the characters. Further- more, various
operations on the characters like uppercasing, lowercas-
ing, and collating (sorting) are defined.</p>

<p>A Unicode character consists either of a single code
point, or a base character (like &quot;LATIN CAPITAL LETTER
A&quot;), followed by one or more mod- ifiers (like
&quot;COMBINING ACUTE ACCENT&quot;). This sequence of base
charac- ter and modifiers is called a combining character
sequence.</p>

<p>Whether to call these combining character sequences
&quot;characters&quot; depends on your point of view. If you
are a programmer, you probably would tend towards seeing
each element in the sequences as one unit, or
&quot;character&quot;. The whole sequence could be seen as
one &quot;character&quot;, how- ever, from the users point
of view, since thats probably what it looks like in the
context of the users language.</p>

<p>With this &quot;whole sequence&quot; view of characters,
the total number of characters is open-ended. But in the
programmers &quot;one unit is one character&quot; point of
view, the concept of &quot;characters&quot; is more
determin- istic. In this document, we take that second point
of view: one &quot;character&quot; is one Unicode code
point, be it a base character or a combining character.</p>

<p>For some combinations, there are precomposed characters.
&quot;LATIN CAPI- TAL LETTER A WITH ACUTE&quot;, for
example, is defined as a single code point. These
precomposed characters are, however, only available for some
combinations, and are mainly meant to support round-trip
conver- sions between Unicode and legacy standards (like the
ISO 8859). In the general case, the composing method is more
extensible. To support con- version between different
compositions of the characters, various nor- malization
forms to standardize representations are also defined.</p>

<p>Because of backward compatibility with legacy encodings,
the &quot;a unique number for every character&quot; idea
breaks down a bit: instead, there is &quot;at least one
number for every character&quot;. The same character could
be represented differently in several legacy encodings. The
converse is also not true: some code points do not have an
assigned character. Firstly, there are unallocated code
points within otherwise used blocks. Secondly, there are
special Unicode control characters that do not represent
true characters.</p>

<p>A common myth about Unicode is that it would be
&quot;16-bit&quot;, that is, Uni- code is only represented
as 0x10000 (or 65536) characters from 0x0000 to 0xFFFF. This
is untrue. Since Unicode 2.0 (July 1996), Unicode has been
defined all the way up to 21 bits (0x10FFFF), and since
Unicode 3.1 (March 2001), characters have been defined
beyond 0xFFFF. The first 0x10000 characters are called the
Plane 0, or the Basic Multilin- gual Plane (BMP). With
Unicode 3.1, 17 (yes, seventeen) planes in all were
defined--but they are nowhere near full of defined
characters, yet.</p>

<p>Another myth is that the 256-character blocks have
something to do with languages--that each block would define
the characters used by a lan- guage or a set of languages.
This is also untrue. The division into blocks exists, but it
is almost completely accidental--an artifact of how the
characters have been and still are allocated. Instead, there
is a concept called scripts, which is more useful: there is
&quot;Latin&quot; script, &quot;Greek&quot; script, and so
on. Scripts usually span varied parts of several blocks. For
further information see Unicode::UCD.</p>

<p>The Unicode code points are just abstract numbers. To
input and output these abstract numbers, the numbers must be
encoded or serialised some- how. Unicode defines several
character encoding forms, of which UTF-8 is perhaps the most
popular. UTF-8 is a variable length encoding that encodes
Unicode characters as 1 to 6 bytes (only 4 with the
currently defined characters). Other encodings include
UTF-16 and UTF-32 and their big- and little-endian variants
(UTF-8 is byte-order independent) The ISO/IEC 10646 defines
the UCS-2 and UCS-4 encoding forms.</p>

<p>For more information about encodings--for instance, to
learn what sur- rogates and byte order marks (BOMs) are--see
perlunicode.</p>

<p>Pers Unicode Support</p>

<p>Starting from Perl 5.6.0, Perl has had the capacity to
handle Unicode natively. Perl 5.8.0, however, is the first
recommended release for serious Unicode work. The
maintenance release 5.6.1 fixed many of the problems of the
initial Unicode implementation, but for example regular
expressions still do not work with Unicode in 5.6.1.</p>

<p>Starting from Perl 5.8.0, the use of &quot;use
utf8&quot; is no longer necessary. In earlier releases the
&quot;utf8&quot; pragma was used to declare that opera-
tions in the current block or file would be Unicode-aware.
This model was found to be wrong, or at least clumsy: the
&quot;Unicodeness&quot; is now carried with the data,
instead of being attached to the operations. Only one case
remains where an explicit &quot;use utf8&quot; is needed: if
your Perl script itself is encoded in UTF-8, you can use
UTF-8 in your identifier names, and in string and regular
expression literals, by saying &quot;use utf8&quot;. This is
not the default because scripts with legacy 8-bit data in
them would break. See utf8.</p>

<p>Pers Unicode Model</p>

<p>Perl supports both pre-5.6 strings of eight-bit native
bytes, and strings of Unicode characters. The principle is
that Perl tries to keep its data as eight-bit bytes for as
long as possible, but as soon as Unicodeness cannot be
avoided, the data is transparently upgraded to Unicode.</p>

<p>Internally, Perl currently uses either whatever the
native eight-bit character set of the platform (for example
Latin-1) is, defaulting to UTF-8, to encode Unicode strings.
Specifically, if all code points in the string are 0xFF or
less, Perl uses the native eight-bit character set.
Otherwise, it uses UTF-8.</p>

<p>A user of Perl does not normally need to know nor care
how Perl happens to encode its internal strings, but it
becomes relevant when outputting Unicode strings to a stream
without a PerlIO layer -- one with the &quot;default&quot;
encoding. In such a case, the raw bytes used internally (the
native character set or UTF-8, as appropriate for each
string) will be used, and a &quot;Wide character&quot;
warning will be issued if those strings contain a character
beyond 0x00FF.</p>

<p>For example,</p>

<p>perl -e print &quot;F}0, &quot;F}0</p>

<p>produces a fairly useless mixture of native bytes and
UTF-8, as well as a warning:</p>

<p>Wide character in print at ...</p>

<p>To output UTF-8, use the &quot;:utf8&quot; output layer.
Prepending</p>

<p>binmode(STDOUT, &quot;:utf8&quot;);</p>

<p>to this sample program ensures that the output is
completely UTF-8, and removes the programs warning.</p>

<p>You can enable automatic UTF-8-ification of your
standard file handles, default &quot;open()&quot; layer, and
@ARGV by using either the &quot;-C&quot; command line switch
or the &quot;PERL_UNICODE&quot; environment variable, see
perlrun for the documentation of the &quot;-C&quot;
switch.</p>

<p>Note that this means that Perl expects other software to
work, too: if Perl has been led to believe that STDIN should
be UTF-8, but then STDIN coming in from another command is
not UTF-8, Perl will complain about the malformed UTF-8.</p>

<p>All features that combine Unicode and I/O also require
using the new PerlIO feature. Almost all Perl 5.8 platforms
do use PerlIO, though: you can see whether yours is by
running &quot;perl -V&quot; and looking for
&quot;useperlio=define&quot;.</p>

<p>Unicode and EBCDIC</p>

<p>Perl 5.8.0 also supports Unicode on EBCDIC platforms.
There, Unicode support is somewhat more complex to implement
since additional conver- sions are needed at every step.
Some problems remain, see perlebcdic for details.</p>

<p>In any case, the Unicode support on EBCDIC platforms is
better than in the 5.6 series, which didnt work much at all
for EBCDIC platform. On EBCDIC platforms, the internal
Unicode encoding form is UTF-EBCDIC instead of UTF-8. The
difference is that as UTF-8 is &quot;ASCII-safe&quot; in
that ASCII characters encode to UTF-8 as-is, while
UTF-EBCDIC is &quot;EBCDIC-safe&quot;.</p>

<p>Creating Unicode</p>

<p>To create Unicode characters in literals for code points
above 0xFF, use the &quot;.}&quot; notation in double-quoted
strings:</p>

<p>my $smiley = &quot;}&quot;;</p>

<p>Similarly, it can be used in regular expression
literals</p>

<p>$smiley =~ /}/;</p>

<p>At run-time you can use &quot;chr()&quot;:</p>

<p>my $hebrew_alef = chr(0x05d0);</p>

<p>See &quot;Further Resources&quot; for how to find all
these numeric codes.</p>

<p>Naturally, &quot;ord()&quot; will do the reverse: it
turns a character into a code point.</p>

<p>Note that &quot;.&quot; (no &quot;{}&quot; and only two
hexadecimal digits), &quot;.}&quot;, and
&quot;chr(...)&quot; for arguments less than 0x100 (decimal
256) generate an eight-bit character for backward
compatibility with older Perls. For arguments of 0x100 or
more, Unicode characters are always produced. If you want to
force the production of Unicode characters regardless of the
numeric value, use &quot;pack(&quot;U&quot;, ...)&quot;
instead of &quot;.&quot;, &quot;.}&quot;, or
&quot;chr()&quot;.</p>

<p>You can also use the &quot;charnames&quot; pragma to
invoke characters by name in double-quoted strings:</p>

<p>use charnames :full; my $arabic_alef = &quot;RABIC
LETTER ALEF}&quot;;</p>

<p>And, as mentioned above, you can also &quot;pack()&quot;
numbers into Unicode characters:</p>

<p>my $georgian_an = pack(&quot;U&quot;, 0x10a0);</p>

<p>Note that both &quot;.}&quot; and &quot;.}&quot; are
compile-time string con- stants: you cannot use variables in
them. if you want similar run-time functionality, use
&quot;chr()&quot; and &quot;charnames::vianame()&quot;.</p>

<p>If you want to force the result to Unicode characters,
use the special &quot;U0&quot; prefix. It consumes no
arguments but forces the result to be in Unicode characters,
instead of bytes.</p>

<p>my $chars = pack(&quot;U0C*&quot;, 0x80, 0x42);</p>

<p>Likewise, you can force the result to be bytes by using
the special &quot;C0&quot; prefix.</p>

<p>Handling Unicode</p>

<p>Handling Unicode is for the most part transparent: just
use the strings as usual. Functions like
&quot;index()&quot;, &quot;length()&quot;, and
&quot;substr()&quot; will work on the Unicode characters;
regular expressions will work on the Unicode characters (see
perlunicode and perlretut).</p>

<p>Note that Perl considers combining character sequences
to be separate characters, so for example</p>

<p>use charnames :full; print length(&quot;ATIN CAPITAL
LETTER A}OMBINING ACUTE ACCENT}&quot;), &quot;0;</p>

<p>will print 2, not 1. The only exception is that regular
expressions have &quot;</p>

<p>Life is not quite so transparent, however, when working
with legacy encodings, I/O, and certain special cases:</p>

<p>Legacy Encodings</p>

<p>When you combine legacy data and Unicode the legacy data
needs to be upgraded to Unicode. Normally ISO 8859-1 (or
EBCDIC, if applicable) is assumed. You can override this
assumption by using the &quot;encoding&quot; pragma, for
example</p>

<p>use encoding latin2; # ISO 8859-2</p>

<p>in which case literals (string or regular expressions),
&quot;chr()&quot;, and &quot;ord()&quot; in your whole
script are assumed to produce Unicode characters from ISO
8859-2 code points. Note that the matching for encoding
names is forgiving: instead of &quot;latin2&quot; you could
have said &quot;Latin 2&quot;, or &quot;iso8859-2&quot;, or
other variations. With just</p>

<p>use encoding;</p>

<p>the environment variable &quot;PERL_ENCODING&quot; will
be consulted. If that variable isnt set, the encoding pragma
will fail.</p>

<p>The &quot;Encode&quot; module knows about many encodings
and has interfaces for doing conversions between those
encodings:</p>

<p>use Encode decode; $data =
decode(&quot;iso-8859-3&quot;, $data); # convert from legacy
to utf-8</p>

<p>Unicode I/O</p>

<p>Normally, writing out Unicode data</p>

<p>print FH $some_string_with_unicode, &quot;0;</p>

<p>produces raw bytes that Perl happens to use to
internally encode the Unicode string. Perls internal
encoding depends on the system as well as what characters
happen to be in the string at the time. If any of the
characters are at code points 0x100 or above, you will get a
warn- ing. To ensure that the output is explicitly rendered
in the encoding you desire--and to avoid the warning--open
the stream with the desired encoding. Some examples:</p>

<p>open FH, &quot;&gt;:utf8&quot;, &quot;file&quot;;</p>

<p>open FH, &quot;&gt;:encoding(ucs2)&quot;,
&quot;file&quot;; open FH, &quot;&gt;:encoding(UTF-8)&quot;,
&quot;file&quot;; open FH,
&quot;&gt;:encoding(shift_jis)&quot;, &quot;file&quot;;</p>

<p>and on already open streams, use
&quot;binmode()&quot;:</p>

<p>binmode(STDOUT, &quot;:utf8&quot;);</p>

<p>binmode(STDOUT, &quot;:encoding(ucs2)&quot;);
binmode(STDOUT, &quot;:encoding(UTF-8)&quot;);
binmode(STDOUT, &quot;:encoding(shift_jis)&quot;);</p>

<p>The matching of encoding names is loose: case does not
matter, and many encodings have several aliases. Note that
the &quot;:utf8&quot; layer must always be specified exactly
like that; it is not subject to the loose matching of
encoding names.</p>

<p>See PerlIO for the &quot;:utf8&quot; layer,
PerlIO::encoding and Encode::PerlIO for the
&quot;:encoding()&quot; layer, and Encode::Supported for
many encodings supported by the &quot;Encode&quot;
module.</p>

<p>Reading in a file that you know happens to be encoded in
one of the Unicode or legacy encodings does not magically
turn the data into Uni- code in Perls eyes. To do that,
specify the appropriate layer when opening files</p>

<p>open(my $fh,&lt;:utf8, anything); my $line_of_unicode =
&lt;$fh&gt;;</p>

<p>open(my $fh,&lt;:encoding(Big5), anything); my
$line_of_unicode = &lt;$fh&gt;;</p>

<p>The I/O layers can also be specified more flexibly with
the &quot;open&quot; pragma. See open, or look at the
following example.</p>

<p>use open :utf8; # input and output default layer will be
UTF-8 open X, &quot;&gt;file&quot;; print X chr(0x100),
&quot;0; close X; open Y, &quot;&lt;file&quot;; printf
&quot;%#x0, ord(&lt;Y&gt;); # this should print 0x100 close
Y;</p>

<p>With the &quot;open&quot; pragma you can use the
&quot;:locale&quot; layer</p>

<p>BEGIN { $ENV{LC_ALL} = $ENV{LANG} = ru_RU.KOI8-R } # the
:locale will probe the locale environment variables like
LC_ALL use open OUT =&gt; :locale; # russki parusski open(O,
&quot;&gt;koi8&quot;); print O chr(0x430); # Unicode
CYRILLIC SMALL LETTER A = KOI8-R 0xc1 close O; open(I,
&quot;&lt;koi8&quot;); printf &quot;%#x0, ord(&lt;I&gt;),
&quot;0; # this should print 0xc1 close I;</p>

<p>or you can also use the &rsquo;:encoding(...)&rsquo;
layer</p>

<p>open(my $epic,&lt;:encoding(iso-8859-7),iliad.greek); my
$line_of_unicode = &lt;$epic&gt;;</p>

<p>These methods install a transparent filter on the I/O
stream that con- verts data from the specified encoding when
it is read in from the stream. The result is always
Unicode.</p>

<p>The open pragma affects all the &quot;open()&quot; calls
after the pragma by set- ting default layers. If you want to
affect only certain streams, use explicit layers directly in
the &quot;open()&quot; call.</p>

<p>You can switch encodings on an already opened stream by
using &quot;bin- mode()&quot;; see &quot;binmode&quot; in
perlfunc.</p>

<p>The &quot;:locale&quot; does not currently (as of Perl
5.8.0) work with &quot;open()&quot; and
&quot;binmode()&quot;, only with the &quot;open&quot;
pragma. The &quot;:utf8&quot; and &quot;:encod-
ing(...)&quot; methods do work with all of
&quot;open()&quot;, &quot;binmode()&quot;, and the
&quot;open&quot; pragma.</p>

<p>Similarly, you may use these I/O layers on output
streams to automati- cally convert Unicode to the specified
encoding when it is written to the stream. For example, the
following snippet copies the contents of the file
&quot;text.jis&quot; (encoded as ISO-2022-JP, aka JIS) to
the file &quot;text.utf8&quot;, encoded as UTF-8:</p>

<p>open(my $nihongo, &lt;:encoding(iso-2022-jp), text.jis);
open(my $unicode, &gt;:utf8, text.utf8); while
(&lt;$nihongo&gt;) { print $unicode $_ }</p>

<p>The naming of encodings, both by the &quot;open()&quot;
and by the &quot;open&quot; pragma, is similar to the
&quot;encoding&quot; pragma in that it allows for flexible
names: &quot;koi8-r&quot; and &quot;KOI8R&quot; will both be
understood.</p>

<p>Common encodings recognized by ISO, MIME, IANA, and
various other stan- dardisation organisations are
recognised; for a more detailed list see
Encode::Supported.</p>

<p>&quot;read()&quot; reads characters and returns the
number of characters. &quot;seek()&quot; and
&quot;tell()&quot; operate on byte counts, as do
&quot;sysread()&quot; and &quot;sysseek()&quot;.</p>

<p>Notice that because of the default behaviour of not
doing any conver- sion upon input if there is no default
layer, it is easy to mistakenly write code that keeps on
expanding a file by repeatedly encoding the data:</p>

<p># BAD CODE WARNING open F, &quot;file&quot;; local $/;
## read in the whole file of 8-bit characters $t =
&lt;F&gt;; close F; open F, &quot;&gt;:utf8&quot;,
&quot;file&quot;; print F $t; ## convert to UTF-8 on output
close F;</p>

<p>If you run this code twice, the contents of the file
will be twice UTF-8 encoded. A &quot;use open
&rsquo;:utf8&rsquo;&quot; would have avoided the bug, or
explicitly opening also the file for input as UTF-8.</p>

<p>NOTE: the &quot;:utf8&quot; and &quot;:encoding&quot;
features work only if your Perl has been built with the new
PerlIO feature (which is the default on most systems).</p>

<p>Displaying Unicode As Text</p>

<p>Sometimes you might want to display Perl scalars
containing Unicode as simple ASCII (or EBCDIC) text. The
following subroutine converts its argument so that Unicode
characters with code points greater than 255 are displayed
as &quot;.}&quot;, control characters (like &quot;0) are
dis- played as &quot;.&quot;, and the rest of the characters
as themselves:</p>

<p>sub nice_string { join(&quot;&quot;, map { $_ &gt; 255 ?
# if wide character... sprintf(&quot;\x{%04X}&quot;, $_) : #
.} chr($_) =~ /[[:cntrl:]]/ ? # else if control character
... sprintf(&quot;\x%02X&quot;, $_) : # . quotemeta(chr($_))
# else quoted or as themselves } unpack(&quot;U*&quot;,
$_[0])); # unpack Unicode characters }</p>

<p>For example,</p>

<p>nice_string(&quot;foobar0)</p>

<p>returns the string</p>

<p>foobarA</p>

<p>which is ready to be printed.</p>

<p>Special Cases</p>

<p>&middot; Bit Complement Operator ~ And vec()</p>

<p>The bit complement operator &quot;~&quot; may produce
surprising results if used on strings containing characters
with ordinal values above 255. In such a case, the results
are consistent with the internal encoding of the characters,
but not with much else. So dont do that. Similarly for
&quot;vec()&quot;: you will be operating on the inter-
nally-encoded bit patterns of the Unicode characters, not on
the code point values, which is very probably not what you
want.</p>

<p>&middot; Peeking At Perls Internal Encoding</p>

<p>Normal users of Perl should never care how Perl encodes
any partic- ular Unicode string (because the normal ways to
get at the contents of a string with Unicode--via input and
output--should always be via explicitly-defined I/O layers).
But if you must, there are two ways of looking behind the
scenes.</p>

<p>One way of peeking inside the internal encoding of
Unicode charac- ters is to use &quot;unpack(&quot;C*&quot;,
...&quot; to get the bytes or &quot;unpack(&quot;H*&quot;,
...)&quot; to display the bytes:</p>

<p># this prints c4 80 for the UTF-8 bytes 0xc4 0x80 print
join(&quot; &quot;, unpack(&quot;H*&quot;,
pack(&quot;U&quot;, 0x100))), &quot;0;</p>

<p>Yet another way would be to use the Devel::Peek
module:</p>

<p>perl -MDevel::Peek -e Dump(chr(0x100))</p>

<p>That shows the &quot;UTF8&quot; flag in FLAGS and both
the UTF-8 bytes and Unicode characters in &quot;PV&quot;.
See also later in this document the discussion about the
&quot;utf8::is_utf8()&quot; function.</p>

<p>Advanced Topics</p>

<p>&middot; String Equivalence</p>

<p>The question of string equivalence turns somewhat
complicated in Unicode: what do you mean by
&quot;equal&quot;?</p>

<p>(Is &quot;LATIN CAPITAL LETTER A WITH ACUTE&quot; equal
to &quot;LATIN CAPITAL LETTER A&quot;?)</p>

<p>The short answer is that by default Perl compares
equivalence (&quot;eq&quot;, &quot;ne&quot;) based only on
code points of the characters. In the above case, the answer
is no (because 0x00C1 != 0x0041). But some- times, any
CAPITAL LETTER As should be considered equal, or even As of
any case.</p>

<p>The long answer is that you need to consider character
normaliza- tion and casing issues: see Unicode::Normalize,
Unicode Technical Reports #15 and #21, Unicode Normalization
Forms and Case Mappings,
http://www.unicode.org/unicode/reports/tr15/ and
http://www.uni- code.org/unicode/reports/tr21/</p>

<p>As of Perl 5.8.0, the &quot;Full&quot; case-folding of
Case Mappings/Special- Casing is implemented.</p>

<p>&middot; String Collation</p>

<p>People like to see their strings nicely sorted--or as
Unicode par- lance goes, collated. But again, what do you
mean by collate?</p>

<p>(Does &quot;LATIN CAPITAL LETTER A WITH ACUTE&quot; come
before or after &quot;LATIN CAPITAL LETTER A WITH
GRAVE&quot;?)</p>

<p>The short answer is that by default, Perl compares
strings (&quot;lt&quot;, &quot;le&quot;, &quot;cmp&quot;,
&quot;ge&quot;, &quot;gt&quot;) based only on the code
points of the char- acters. In the above case, the answer is
&quot;after&quot;, since 0x00C1 &gt; 0x00C0.</p>

<p>The long answer is that &quot;it depends&quot;, and a
good answer cannot be given without knowing (at the very
least) the language context. See Unicode::Collate, and
Unicode Collation Algorithm
http://www.unicode.org/unicode/reports/tr10/</p>

<p>Miscellaneous</p>

<p>&middot; Character Ranges and Classes</p>

<p>Character ranges in regular expression character classes
(&quot;/[a-z]/&quot;) and in the &quot;tr///&quot; (also
known as &quot;y///&quot;) operator are not magically
Unicode-aware. What this means that &quot;[A-Za-z]&quot;
will not magically start to mean &quot;all alphabetic
letters&quot;; not that it does mean that even for 8-bit
characters, you should be using &quot;/[[:alpha:]]/&quot; in
that case.</p>

<p>For specifying character classes like that in regular
expressions, you can use the various Unicode
properties--&quot;L&quot;, or perhaps
&quot;{Alphabetic}&quot;, in this particular case. You can
use Unicode code points as the end points of character
ranges, but there is no magic associated with specifying a
certain range. For further information--there are dozens of
Unicode character classes--see perlunicode.</p>

<p>&middot; String-To-Number Conversions</p>

<p>Unicode does define several other decimal--and
numeric--characters besides the familiar 0 to 9, such as the
Arabic and Indic digits. Perl does not support
string-to-number conversion for digits other than ASCII 0 to
9 (and ASCII a to f for hexadecimal).</p>

<p>Questions With Answers</p>

<p>&middot; Will My Old Scripts Break?</p>

<p>Very probably not. Unless you are generating Unicode
characters somehow, old behaviour should be preserved. About
the only behaviour that has changed and which could start
generating Unicode is the old behaviour of &quot;chr()&quot;
where supplying an argument more than 255 produced a
character modulo 255. &quot;chr(300)&quot;, for example, was
equal to &quot;chr(45)&quot; or &quot;-&quot; (in ASCII),
now it is LATIN CAPITAL LETTER I WITH BREVE.</p>

<p>&middot; How Do I Make My Scripts Work With Unicode?</p>

<p>Very little work should be needed since nothing changes
until you generate Unicode data. The most important thing is
getting input as Unicode; for that, see the earlier I/O
discussion.</p>

<p>&middot; How Do I Know Whether My String Is In
Unicode?</p>

<p>You shouldnt care. No, you really shouldn t. No, really.
If you have to care--beyond the cases described above--it
means that we didnt get the transparency of Unicode quite
right.</p>

<p>Okay, if you insist:</p>

<p>print utf8::is_utf8($string) ? 1 : 0, &quot;0;</p>

<p>But note that this doesn t mean that any of the
characters in the string are necessary UTF-8 encoded, or
that any of the characters have code points greater than
0xFF (255) or even 0x80 (128), or that the string has any
characters at all. All the &quot;is_utf8()&quot; does is to
return the value of the internal &quot;utf8ness&quot; flag
attached to the $string. If the flag is off, the bytes in
the scalar are interpreted as a single byte encoding. If the
flag is on, the bytes in the scalar are interpreted as the
(multi-byte, variable-length) UTF-8 encoded code points of
the characters. Bytes added to an UTF-8 encoded string are
automatically upgraded to UTF-8. If mixed non-UTF-8 and
UTF-8 scalars are merged (dou- ble-quoted interpolation,
explicit concatenation, and printf/sprintf parameter
substitution), the result will be UTF-8 encoded as if copies
of the byte strings were upgraded to UTF-8: for example,</p>

<p>$a = &quot;ab0c&quot;; $b = &quot;&quot;; print &quot;$a
= $b0;</p>

<p>the output string will be UTF-8-encoded &quot;ab0c = 0,
but $a will stay byte-encoded.</p>

<p>Sometimes you might really need to know the byte length
of a string instead of the character length. For that use
either the &quot;Encode::encode_utf8()&quot; function or the
&quot;bytes&quot; pragma and its only defined function
&quot;length()&quot;:</p>

<p>my $unicode = chr(0x100); print length($unicode),
&quot;0; # will print 1 require Encode; print
length(Encode::encode_utf8($unicode)), &quot;0; # will print
2 use bytes; print length($unicode), &quot;0; # will also
print 2 # (the 0xC4 0x80 of the UTF-8)</p>

<p>&middot; How Do I Detect Data Thats Not Valid In a
Particular Encoding?</p>

<p>Use the &quot;Encode&quot; package to try converting it.
For example,</p>

<p>use Encode decode_utf8; if
(decode_utf8($string_of_bytes_that_I_think_is_utf8)) { #
valid } else { # invalid }</p>

<p>For UTF-8 only, you can use:</p>

<p>use warnings; @chars = unpack(&quot;U0U*&quot;,
$string_of_bytes_that_I_think_is_utf8);</p>

<p>If invalid, a &quot;Malformed UTF-8 character (byte
0x##) in unpack&quot; warning is produced. The
&quot;U0&quot; means &quot;expect strictly UTF-8 encoded
Unicode&quot;. Without that the &quot;unpack(&quot;U*&quot;,
...)&quot; would accept also data like
&quot;chr(0xFF&quot;), similarly to the &quot;pack&quot; as
we saw earlier.</p>

<p>&middot; How Do I Convert Binary Data Into a Particular
Encoding, Or Vice Versa?</p>

<p>This probably isnt as useful as you might think.
Normally, you shouldnt need to.</p>

<p>In one sense, what you are asking doesnt make much
sense: encod- ings are for characters, and binary data are
not &quot;characters&quot;, so converting &quot;data&quot;
into some encoding isnt meaningful unless you know in what
character set and encoding the binary data is in, in which
case its not just binary data, now is it?</p>

<p>If you have a raw sequence of bytes that you know should
be inter- preted via a particular encoding, you can use
&quot;Encode&quot;:</p>

<p>use Encode from_to; from_to($data,
&quot;iso-8859-1&quot;, &quot;utf-8&quot;); # from latin-1
to utf-8</p>

<p>The call to &quot;from_to()&quot; changes the bytes in
$data, but nothing material about the nature of the string
has changed as far as Perl is concerned. Both before and
after the call, the string $data contains just a bunch of
8-bit bytes. As far as Perl is concerned, the encoding of
the string remains as &quot;system-native 8-bit
bytes&quot;.</p>

<p>You might relate this to a fictional Translate
module:</p>

<p>use Translate; my $phrase = &quot;Yes&quot;;
Translate::from_to($phrase, english, deutsch); ## phrase now
contains &quot;Ja&quot;</p>

<p>The contents of the string changes, but not the nature
of the string. Perl doesnt know any more after the call than
before that the contents of the string indicates the
affirmative.</p>

<p>Back to converting data. If you have (or want) data in
your sys- tems native 8-bit encoding (e.g. Latin-1, EBCDIC,
etc.), you can use pack/unpack to convert to/from
Unicode.</p>

<p>$native_string = pack(&quot;C*&quot;,
unpack(&quot;U*&quot;, $Unicode_string)); $Unicode_string =
pack(&quot;U*&quot;, unpack(&quot;C*&quot;,
$native_string));</p>

<p>If you have a sequence of bytes you know is valid UTF-8,
but Perl doesnt know it yet, you can make Perl a believer,
too:</p>

<p>use Encode decode_utf8; $Unicode =
decode_utf8($bytes);</p>

<p>You can convert well-formed UTF-8 to a sequence of
bytes, but if you just want to convert random binary data
into UTF-8, you cant. Any random collection of bytes ist
well-formed UTF-8. You can use &quot;unpack(&quot;C*&quot;,
$string)&quot; for the former, and you can create
well-formed Unicode data by &quot;pack(&quot;U*&quot;, 0xff,
...)&quot;.</p>

<p>&middot; How Do I Display Unicode? How Do I Input
Unicode?</p>

<p>See http://www.alanwood.net/unicode/ and
http://www.cl.cam.ac.uk/~mgk25/unicode.html</p>

<p>&middot; How Does Unicode Work With Traditional
Locales?</p>

<p>In Perl, not very well. Avoid using locales through the
&quot;locale&quot; pragma. Use only one or the other. But
see perlrun for the description of the &quot;-C&quot; switch
and its environment counterpart, $ENV{PERL_UNICODE} to see
how to enable various Unicode features, for example by using
locale settings.</p>

<p>Hexadecimal Notation</p>

<p>The Unicode standard prefers using hexadecimal notation
because that more clearly shows the division of Unicode into
blocks of 256 charac- ters. Hexadecimal is also simply
shorter than decimal. You can use decimal notation, too, but
learning to use hexadecimal just makes life easier with the
Unicode standard. The &quot;U+HHHH&quot; notation uses
hexadeci- mal, for example.</p>

<p>The &quot;0x&quot; prefix means a hexadecimal number,
the digits are 0-9 and a-f (or A-F, case doesn t matter).
Each hexadecimal digit represents four bits, or half a byte.
&quot;print 0x..., &quot;0&quot; will show a hexadecimal
num- ber in decimal, and &quot;printf &quot;%x0,
$decimal&quot; will show a decimal num- ber in hexadecimal.
If you have just the &quot;hex digits&quot; of a hexadecimal
number, you can use the &quot;hex()&quot; function.</p>

<p>print 0x0009, &quot;0; # 9 print 0x000a, &quot;0; # 10
print 0x000f, &quot;0; # 15 print 0x0010, &quot;0; # 16
print 0x0011, &quot;0; # 17 print 0x0100, &quot;0; # 256</p>

<p>print 0x0041, &quot;0; # 65</p>

<p>printf &quot;%x0, 65; # 41 printf &quot;%#x0, 65; #
0x41</p>

<p>print hex(&quot;41&quot;), &quot;0; # 65</p>

<p>Further Resources</p>

<p>&middot; Unicode Consortium</p>

<p>http://www.unicode.org/</p>

<p>&middot; Unicode FAQ</p>

<p>http://www.unicode.org/unicode/faq/</p>

<p>&middot; Unicode Glossary</p>

<p>http://www.unicode.org/glossary/</p>

<p>&middot; Unicode Useful Resources</p>


<p>http://www.unicode.org/unicode/onlinedat/resources.html</p>

<p>&middot; Unicode and Multilingual Support in HTML,
Fonts, Web Browsers and Other Applications</p>

<p>http://www.alanwood.net/unicode/</p>

<p>&middot; UTF-8 and Unicode FAQ for Unix/Linux</p>

<p>http://www.cl.cam.ac.uk/~mgk25/unicode.html</p>

<p>&middot; Legacy Character Sets</p>

<p>http://www.czyborra.com/ http://www.eki.ee/letter/</p>

<p>&middot; The Unicode support files live within the Perl
installation in the directory</p>

<p>$Config{installprivlib}/unicore</p>

<p>in Perl 5.8.0 or newer, and</p>

<p>$Config{installprivlib}/unicode</p>

<p>in the Perl 5.6 series. (The renaming to lib/unicore was
done to avoid naming conflicts with lib/Unicode in
case-insensitive filesystems.) The main Unicode data file is
UnicodeData.txt (or Unicode.301 in Perl 5.6.1.) You can find
the $Config{install- privlib} by</p>

<p>perl &quot;-V:installprivlib&quot;</p>

<p>You can explore various information from the Unicode
data files using the &quot;Unicode::UCD&quot; module.</p>

<p>UNICODE IN OLDER PERLS If you cannot upgrade your Perl
to 5.8.0 or later, you can still do some Unicode processing
by using the modules &quot;Unicode::String&quot;, &quot;Uni-
code::Map8&quot;, and &quot;Unicode::Map&quot;, available
from CPAN. If you have the GNU recode installed, you can
also use the Perl front-end &quot;Con- vert::Recode&quot;
for character conversions.</p>

<p>The following are fast conversions from ISO 8859-1
(Latin-1) bytes to UTF-8 bytes and back, the code works even
with older Perl 5 versions.</p>

<p># ISO 8859-1 to UTF-8
s/([0-])/chr(0xC0ord($1)&gt;&gt;6).chr(0x80ord($1)&amp;0x3F)/eg;</p>

<p># UTF-8 to ISO 8859-1
s/([)([0-])/chr(ord($1)&lt;&lt;6&amp;0xC0ord($2)&amp;0x3F)/eg;</p>

<p>SEE ALSO perlunicode, Encode, encoding, open, utf8,
bytes, perlretut, perlrun, Unicode::Collate,
Unicode::Normalize, Unicode::UCD</p>

<p>ACKNOWLEDGMENTS Thanks to the kind readers of the
perl5-porters@perl.org, perl-uni- code@perl.org,
linux-utf8@nl.linux.org, and unicore@unicode.org mailing
lists for their valuable feedback.</p>

<p>AUTHOR, COPYRIGHT, AND LICENSE Copyright 2001-2002
Jarkko Hietaniemi &lt;jhi@iki.fi&gt;</p>

<p>This document may be distributed under the same terms as
Perl itself.</p>

<p>perl v5.8.8 2014-02-11 PERLUNIINTRO(1)</p>
<hr>
</body>
</html>
